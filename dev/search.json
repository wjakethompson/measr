[{"path":[]},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement wjakethompson@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to measr","title":"Contributing to measr","text":"outlines propose change measr.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to measr","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to measr","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). See tidyverse guide create great issue advice.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to measr","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"wjakethompson/measr\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to measr","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to measr","text":"Please note measr project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://measr.info/dev/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://measr.info/dev/articles/ecpe.html","id":"explore-the-data","dir":"Articles","previous_headings":"","what":"Explore the Data","title":"Examination for the Certificate of Proficiency in English","text":"ECPE data built measr can accessed loading package. complete description data can viewed using ?ecpe_data. can see data set one row respondent, 2,922 respondents completed section ECPE. also see data 29 columns. first column contains respondent identifiers, remaining 28 columns contain dichotomous item responses items. item responses coded 0 incorrect response 1 correct response. addition data, also Q-matrix define attributes measured item. Q-matrix 28 rows, corresponds total number items. first column Q-matrix contains item identifiers, column names ecpe_data contain item responses. remaining columns define attributes measured ECPE. value 0 indicates item measure attribute, whereas value 1 indicates attribute measured item. example, item E1 measures morphosyntactic rules cohesive rules, item E4 measures lexical rules. quick summary data, can calculate proportion respondents answered question correctly (.e., item p-values). can join item p-values Q-matrix get sense attributes difficult. Overall, items relatively high p-values, items p-value .6 .9. Note general, items measuring morphosyntactic rules tend difficult (.e., lower p-values), followed items measuring cohesive rules, finally items measuring lexical rules.","code":"library(measr)  ecpe_data #> # A tibble: 2,922 × 29 #>    resp_id    E1    E2    E3    E4    E5    E6    E7    E8    E9   E10   E11 #>      <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> #>  1       1     1     1     1     0     1     1     1     1     1     1     1 #>  2       2     1     1     1     1     1     1     1     1     1     1     1 #>  3       3     1     1     1     1     1     1     0     1     1     1     1 #>  4       4     1     1     1     1     1     1     1     1     1     1     1 #>  5       5     1     1     1     1     1     1     1     1     1     1     1 #>  6       6     1     1     1     1     1     1     1     1     1     1     1 #>  7       7     1     1     1     1     1     1     1     1     1     1     1 #>  8       8     0     1     1     1     1     1     0     1     1     1     0 #>  9       9     1     1     1     1     1     1     1     1     1     1     1 #> 10      10     1     1     1     1     0     0     1     1     1     1     1 #> # ℹ 2,912 more rows #> # ℹ 17 more variables: E12 <int>, E13 <int>, E14 <int>, E15 <int>, E16 <int>, #> #   E17 <int>, E18 <int>, E19 <int>, E20 <int>, E21 <int>, E22 <int>, #> #   E23 <int>, E24 <int>, E25 <int>, E26 <int>, E27 <int>, E28 <int> ecpe_qmatrix #> # A tibble: 28 × 4 #>    item_id morphosyntactic cohesive lexical #>    <chr>             <int>    <int>   <int> #>  1 E1                    1        1       0 #>  2 E2                    0        1       0 #>  3 E3                    1        0       1 #>  4 E4                    0        0       1 #>  5 E5                    0        0       1 #>  6 E6                    0        0       1 #>  7 E7                    1        0       1 #>  8 E8                    0        1       0 #>  9 E9                    0        0       1 #> 10 E10                   1        0       0 #> # ℹ 18 more rows library(tidyverse)  ecpe_data %>%   summarize(across(-resp_id, mean)) %>%   pivot_longer(everything(), names_to = \"item_id\", values_to = \"pvalue\") #> # A tibble: 28 × 2 #>    item_id pvalue #>    <chr>    <dbl> #>  1 E1       0.803 #>  2 E2       0.830 #>  3 E3       0.579 #>  4 E4       0.706 #>  5 E5       0.887 #>  6 E6       0.854 #>  7 E7       0.721 #>  8 E8       0.898 #>  9 E9       0.702 #> 10 E10      0.658 #> # ℹ 18 more rows ecpe_data %>%   summarize(across(-resp_id, mean)) %>%   pivot_longer(everything(), names_to = \"item_id\", values_to = \"pvalue\") %>%   left_join(ecpe_qmatrix, join_by(item_id)) %>%   pivot_longer(c(morphosyntactic, cohesive, lexical),                names_to = \"attribute\",                values_to = \"measured\") %>%   filter(measured == 1) %>%   summarize(measures = paste(str_to_title(attribute), collapse = \"/<br>\"),             .by = c(item_id, pvalue)) %>%   mutate(measures = fct_reorder(measures, pvalue, mean)) %>%   ggplot(aes(x = pvalue, y = measures)) +   geom_point(aes(color = measures),              position = position_jitter(height = 0.2, width = 0,                                         seed = 1213),              size = 4, show.legend = FALSE) +   scale_color_manual(values = c(\"#023047\", \"#D7263D\", \"#8ECAE6\", \"#219EBC\",                                 \"#F3D3BD\", \"#000000\")) +   expand_limits(x = c(0, 1)) +   scale_x_continuous(breaks = seq(0, 1, 0.2)) +   labs(x = \"Item *p*-value\", y = \"Measured attributes\")"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"dcm-estimation","dir":"Articles","previous_headings":"","what":"DCM Estimation","title":"Examination for the Certificate of Proficiency in English","text":"Now feel data, estimate DCM. Following original analysis ECPE data Templin & Hoffman (2013), ’ll estimate loglinear cognitive diagnostic model (LCDM). LCDM general diagnostic model allows different attribute relationships items (e.g., compensatory, non-compensatory) subsumes many types DCMs (Henson et al., 2009; Henson & Templin, 2019). following code estimate LCDM. first two lines, specify data, Q-matrix, respondent item identifiers. specify type DCM want estimate define model estimated. case, want estimate model using MCMC rstan package estimation engine. Finally, can customize MCMC process executed. example, specified 4 chains, 1,000 warmup iterations 500 retained iterations 1,500 iterations total. results total posterior distribution 2,000 samples parameter (.e., 500 iterations 4 chains). also specified file estimated model saved estimated. Now ’ve estimated model, let’s examine output. three types information ’ll examine: structural parameters, item parameters, respondent proficiency.","code":"ecpe_lcdm <- measr_dcm(data = ecpe_data, qmatrix = ecpe_qmatrix,                        resp_id = \"resp_id\", item_id = \"item_id\",                        type = \"lcdm\", method = \"mcmc\", backend = \"rstan\",                        chains = 4, iter = 1500, warmup = 1000,                        file = \"fits/ecpe-lcdm\")"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"structural-parameters","dir":"Articles","previous_headings":"DCM Estimation","what":"Structural Parameters","title":"Examination for the Certificate of Proficiency in English","text":"structural parameters define base rate membership attribute profiles. ECPE data consists 3 dichotomous attributes, total 23 = 8 possible profiles, classes. can view possible profiles using measr_extract(). function extracts different aspects model estimated measr. order attributes profiles corresponds order attributes listed Q-matrix used estimate model. means attributes 1, 2, 3 correspond morphosyntactic, cohesive, lexical rules, respectively. can extract structural parameters also using measr_extract(). structural parameters, see class, attribute profile, estimated proportion respondents class measure error (standard deviation posterior). example, nearly 30% respondents estimated proficient attributes (class 1), 17% estimated proficient just attributes 2 3 (class 7). looking structural parameters, can see respondents typically fall 4 8 possible profiles. Specifically, respondents typically proficient attributes, attribute 3 (lexical rules), attributes 2 3 (cohesive lexical rules), attributes. may indicate presence attribute hierarchy, suggested Templin & Bradshaw (2014), respondents must gain proficiency lexical rules can gain proficiency cohesive rules, finally morphosyntactic rules.  can also collapse across classes calculate base rate proficiency individual attribute. Overall, model estimates 38% respondents proficient morphosyntactic rules, 54% respondents proficient cohesive rules, 66% respondents proficient lexical rules. summary, profile- attribute-level base rates tell similar story. Respondents likely proficient lexical rules least likely proficient morphosyntactic rules. also mirrors analysis item p-values exploring data, showed items measuring morphosyntactic rules difficult items measuring lexical cohesive rules.","code":"ecpe_classes <- measr_extract(ecpe_lcdm, \"classes\") ecpe_classes #> # A tibble: 8 × 4 #>   class   morphosyntactic cohesive lexical #>   <chr>             <int>    <int>   <int> #> 1 [0,0,0]               0        0       0 #> 2 [1,0,0]               1        0       0 #> 3 [0,1,0]               0        1       0 #> 4 [0,0,1]               0        0       1 #> 5 [1,1,0]               1        1       0 #> 6 [1,0,1]               1        0       1 #> 7 [0,1,1]               0        1       1 #> 8 [1,1,1]               1        1       1 structural_parameters <- measr_extract(ecpe_lcdm, \"strc_param\") structural_parameters #> # A tibble: 8 × 2 #>   class           estimate #>   <chr>         <rvar[1d]> #> 1 [0,0,0]  0.2974 ± 0.0168 #> 2 [1,0,0]  0.0121 ± 0.0063 #> 3 [0,1,0]  0.0170 ± 0.0110 #> 4 [0,0,1]  0.1278 ± 0.0193 #> 5 [1,1,0]  0.0092 ± 0.0056 #> 6 [1,0,1]  0.0177 ± 0.0100 #> 7 [0,1,1]  0.1734 ± 0.0202 #> 8 [1,1,1]  0.3453 ± 0.0170 structural_parameters %>%   mutate(class = fct_inorder(class),          prob = map_dbl(estimate, mean)) %>%   ggplot(aes(x = class, y = prob)) +   geom_col(fill = msr_colors[2]) +   labs(x = \"Class\", y = \"Base rate\") ecpe_classes %>%   left_join(structural_parameters, join_by(class)) %>%   summarize(morphosyntactic = rvar_sum(estimate[which(morphosyntactic == 1)]),             cohesive = rvar_sum(estimate[which(cohesive == 1)]),             lexical = rvar_sum(estimate[which(lexical == 1)])) #> # A tibble: 1 × 3 #>   morphosyntactic      cohesive       lexical #>        <rvar[1d]>    <rvar[1d]>    <rvar[1d]> #> 1    0.38 ± 0.018  0.54 ± 0.029  0.66 ± 0.014"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"item-parameters","dir":"Articles","previous_headings":"DCM Estimation","what":"Item Parameters","title":"Examination for the Certificate of Proficiency in English","text":"item parameters define log-odds respondent class providing correct response. can extract estimated item parameters using measr_extract(). , estimate column reports estimated value parameter measure associated error (.e., standard deviation posterior distribution). example, item E1 four parameters, measures two attributes: intercept, represents log-odds providing correct response respondent proficient neither attributes item measures (.e., morphosyntactic rules cohesive rules). main effect morphosyntactic rules, represents increase log-odds providing correct response respondent proficient attribute. main effect cohesive rules, represents increase log-odds providing correct response respondent proficient attribute. interaction morphosyntactic cohesive rules, change log-odds respondent proficient attributes. can compare estimates Templin & Hoffman (2013) reported using different software estimate model. following figure, parameters fall close dashed line, represents perfect agreement.  parameters deviate line perfect agreement, expected. example, take item E7, measures morphosyntactic lexical rules. measr Templin & Hoffman (2013) report values approximately -0.09 intercept 0.93 main effect lexical rules. main effect morphosyntactic rules, measr estimated value 1.61, compared value 2.86 reported Templin & Hoffman (2013), difference -1.24. Similarly, interaction term estimated measr 0.34, compared value -0.95 reported Templin & Hoffman (2013), difference 1.29. indicates log-odds providing correct response individual mastered attributes approximately , regardless software. , measr, get log-odds -0.08 + 1.61 + 0.92 + 0.34 = 2.79, Templin & Hoffman (2013), get log-odds -0.11 + 2.86 + 0.95 + -0.95 = 2.75. true differences figure. change main effect morphosyntactic rules corresponding change interaction term “cancels ” difference. happening? Let’s revisit proportion respondents class. respondents proficient morphosyntactic rules without also proficient attributes (classes 2, 5, 6; less 4% respondents). Therefore, less information estimating morphosyntactic main effects, items measure multiple attributes, represent increase log-odds proficiency morphosyntactic rules conditional proficient attribute. less information available morphosyntactic main effects, prior influence parameters. Note figure main effect estimates diagonal less extreme using measr. example, triangle top right main effect estimated nearly 3 Templin & Hoffman (2013), just 1.5 model estimated measr. Thus, regularizing effect, prior pulling extreme values, intended outcome. discuss priors estimating model instead used default priors provided measr. information prior distributions, including information specify prior distributions model parameters, see ?prior model estimation vignette.","code":"item_parameters <- measr_extract(ecpe_lcdm, what = \"item_param\") item_parameters #> # A tibble: 74 × 5 #>    item_id class       attributes                coef         estimate #>    <fct>   <chr>       <chr>                     <glue>     <rvar[1d]> #>  1 E1      intercept   NA                        l1_0     0.82 ± 0.074 #>  2 E1      maineffect  morphosyntactic           l1_11    0.61 ± 0.360 #>  3 E1      maineffect  cohesive                  l1_12    0.64 ± 0.209 #>  4 E1      interaction morphosyntactic__cohesive l1_212   0.53 ± 0.477 #>  5 E2      intercept   NA                        l2_0     1.04 ± 0.078 #>  6 E2      maineffect  cohesive                  l2_12    1.23 ± 0.151 #>  7 E3      intercept   NA                        l3_0    -0.35 ± 0.075 #>  8 E3      maineffect  morphosyntactic           l3_11    0.73 ± 0.371 #>  9 E3      maineffect  lexical                   l3_13    0.36 ± 0.119 #> 10 E3      interaction morphosyntactic__lexical  l3_213   0.54 ± 0.393 #> # ℹ 64 more rows param_compare %>%   ggplot(aes(x = measr_est, y = mplus_est)) +   geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +   geom_point(aes(color = type, shape = type), size = 3) +   scale_color_manual(values = msr_colors) +   expand_limits(x = c(-2, 3), y = c(-2, 3)) +   coord_fixed() +   labs(x = \"measr\", y = \"Templin & Hoffman (2013)\",        color = \"Parameter Type\", shape = \"Parameter Type\") structural_parameters #> # A tibble: 8 × 2 #>   class           estimate #>   <chr>         <rvar[1d]> #> 1 [0,0,0]  0.2974 ± 0.0168 #> 2 [1,0,0]  0.0121 ± 0.0063 #> 3 [0,1,0]  0.0170 ± 0.0110 #> 4 [0,0,1]  0.1278 ± 0.0193 #> 5 [1,1,0]  0.0092 ± 0.0056 #> 6 [1,0,1]  0.0177 ± 0.0100 #> 7 [0,1,1]  0.1734 ± 0.0202 #> 8 [1,1,1]  0.3453 ± 0.0170"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"respondent-proficiency","dir":"Articles","previous_headings":"DCM Estimation","what":"Respondent Proficiency","title":"Examination for the Certificate of Proficiency in English","text":"final piece output model examine respondent probabilities. two types probabilities can calculate, returned predict() function. class_probabilites probabilities respondent belongs 8 possible classes (.e., profiles proficiency). attribute_probabilites probabilities respondent proficient individual attributes. better describe difference two probabilities, let’s look results respondent 73. looking class probabilities, likely profile [1,1,1], meaning respondent proficient attributes. However, 39% chance respondent belongs class. also greater 10% chance belonging [0,0,1] [0,1,1] classes. attribute probabilities respondent 73 show slightly different story. probabilities indicate 42% chance respondent proficient morphosyntactic rules, 76% chance respondent proficient cohesive rules, 93% chance respondent proficient lexical rules. , ’re fairly confident respondent 73 proficient lexical rules, somewhat confident proficient cohesive rules, confident whether student proficient morphosyntactic rules (.e., proficiency probability reasonably low 27% high 57%). probabilities can turned classifications setting proficiency thresholds. example, might decide probabilities greater .5 (.e., likely ) indicate proficiency (e.g., Bradshaw & Levy, 2019). hand, might want confident respondent proficient reporting , therefore might set higher threshold (e.g., .8, Thompson et al., 2019). respondent 73, thresholds .5 .8 result proficiency profiles [0,1,1] [0,0,1], respectively. Either way, profiles differ overall likely profile indicated class probabilities. Thus, important give careful consideration results determined reported. default, predict() returns summary posterior distribution probability (.e., mean 95% credible interval). many class attribute probabilities, therefore object containing full posterior distributions quite large. can change percentiles returned posterior summary setting probs argument quantiles default probs = c(0.025, 0.975). Alternatively, want full posterior distribution probability, can set summary = FALSE. return posterior::rvar() object (structural item parameter summaries) contains posterior draws probability, displayed mean posterior ±1 standard deviation. information rvar objects, see accompanying vignette (vignette(\"rvar\", package = \"posterior\")).","code":"resp_probs <- predict(ecpe_lcdm) resp_probs #> $class_probabilities #> # A tibble: 23,376 × 5 #>    resp_id class   probability       `2.5%`    `97.5%` #>    <fct>   <chr>         <dbl>        <dbl>      <dbl> #>  1 1       [0,0,0] 0.00000764  0.00000385   0.0000133  #>  2 1       [1,0,0] 0.000102    0.00000804   0.000349   #>  3 1       [0,1,0] 0.000000534 0.0000000284 0.00000161 #>  4 1       [0,0,1] 0.00131     0.000730     0.00209    #>  5 1       [1,1,0] 0.0000859   0.00000469   0.000255   #>  6 1       [1,0,1] 0.0421      0.00334      0.0978     #>  7 1       [0,1,1] 0.00207     0.00130      0.00310    #>  8 1       [1,1,1] 0.954       0.898        0.993      #>  9 2       [0,0,0] 0.00000577  0.00000287   0.0000106  #> 10 2       [1,0,0] 0.0000766   0.00000605   0.000263   #> # ℹ 23,366 more rows #>  #> $attribute_probabilities #> # A tibble: 8,766 × 5 #>    resp_id attribute       probability `2.5%` `97.5%` #>    <fct>   <chr>                 <dbl>  <dbl>   <dbl> #>  1 1       morphosyntactic       0.997  0.995   0.998 #>  2 1       cohesive              0.956  0.901   0.995 #>  3 1       lexical               1.00   0.999   1.00  #>  4 2       morphosyntactic       0.995  0.992   0.997 #>  5 2       cohesive              0.902  0.770   0.988 #>  6 2       lexical               1.00   1.00    1.00  #>  7 3       morphosyntactic       0.983  0.970   0.991 #>  8 3       cohesive              0.989  0.976   0.997 #>  9 3       lexical               1.00   1.00    1.00  #> 10 4       morphosyntactic       0.998  0.996   0.998 #> # ℹ 8,756 more rows resp_probs$class_probabilities %>%  filter(resp_id == 73) #> # A tibble: 8 × 5 #>   resp_id class   probability   `2.5%` `97.5%` #>   <fct>   <chr>         <dbl>    <dbl>   <dbl> #> 1 73      [0,0,0]     0.0491  0.0248    0.0864 #> 2 73      [1,0,0]     0.00603 0.000393  0.0222 #> 3 73      [0,1,0]     0.00460 0.000251  0.0137 #> 4 73      [0,0,1]     0.170   0.0972    0.260  #> 5 73      [1,1,0]     0.00752 0.000257  0.0271 #> 6 73      [1,0,1]     0.0130  0.00101   0.0337 #> 7 73      [0,1,1]     0.361   0.238     0.500  #> 8 73      [1,1,1]     0.389   0.256     0.538 resp_probs$attribute_probabilities %>%   filter(resp_id == 73) #> # A tibble: 3 × 5 #>   resp_id attribute       probability `2.5%` `97.5%` #>   <fct>   <chr>                 <dbl>  <dbl>   <dbl> #> 1 73      morphosyntactic       0.416  0.274   0.573 #> 2 73      cohesive              0.762  0.655   0.853 #> 3 73      lexical               0.933  0.882   0.966 predict(ecpe_lcdm, summary = FALSE) #> $class_probabilities #> # A tibble: 2,922 × 9 #>    resp_id          `[0,0,0]`              `[1,0,0]`          `[0,1,0]` #>    <fct>           <rvar[1d]>             <rvar[1d]>         <rvar[1d]> #>  1 1        7.6e-06 ± 2.5e-06  0.0001023 ± 0.0000869  5.3e-07 ± 4.2e-07 #>  2 2        5.8e-06 ± 2.0e-06  0.0000766 ± 0.0000642  2.0e-07 ± 1.7e-07 #>  3 3        5.6e-06 ± 2.0e-06  0.0000171 ± 0.0000191  1.8e-06 ± 1.4e-06 #>  4 4        3.2e-07 ± 9.9e-08  0.0000042 ± 0.0000035  1.0e-07 ± 7.6e-08 #>  5 5        1.2e-03 ± 3.5e-04  0.0086726 ± 0.0064559  3.7e-04 ± 2.7e-04 #>  6 6        3.0e-06 ± 9.8e-07  0.0000159 ± 0.0000145  9.4e-07 ± 7.1e-07 #>  7 7        3.0e-06 ± 9.8e-07  0.0000159 ± 0.0000145  9.4e-07 ± 7.1e-07 #>  8 8        3.7e-02 ± 1.1e-02  0.0000884 ± 0.0000977  1.4e-03 ± 1.1e-03 #>  9 9        6.5e-05 ± 1.9e-05  0.0002115 ± 0.0001476  2.1e-05 ± 1.5e-05 #> 10 10       4.0e-01 ± 1.3e-01  0.4230131 ± 0.1728004  3.7e-03 ± 3.1e-03 #> # ℹ 2,912 more rows #> # ℹ 5 more variables: `[0,0,1]` <rvar[1d]>, `[1,1,0]` <rvar[1d]>, #> #   `[1,0,1]` <rvar[1d]>, `[0,1,1]` <rvar[1d]>, `[1,1,1]` <rvar[1d]> #>  #> $attribute_probabilities #> # A tibble: 2,922 × 4 #>    resp_id   morphosyntactic       cohesive          lexical #>    <fct>          <rvar[1d]>     <rvar[1d]>       <rvar[1d]> #>  1 1        0.9966 ± 0.00068  0.96 ± 0.0247  1.00 ± 0.000117 #>  2 2        0.9950 ± 0.00135  0.90 ± 0.0575  1.00 ± 0.000073 #>  3 3        0.9827 ± 0.00541  0.99 ± 0.0056  1.00 ± 0.000077 #>  4 4        0.9976 ± 0.00050  0.99 ± 0.0056  1.00 ± 0.000013 #>  5 5        0.9880 ± 0.00238  0.98 ± 0.0087  0.95 ± 0.027143 #>  6 6        0.9924 ± 0.00214  0.99 ± 0.0056  1.00 ± 0.000062 #>  7 7        0.9924 ± 0.00214  0.99 ± 0.0056  1.00 ± 0.000062 #>  8 8        0.0044 ± 0.00199  0.45 ± 0.0796  0.96 ± 0.011479 #>  9 9        0.9452 ± 0.01306  0.98 ± 0.0059  1.00 ± 0.000776 #> 10 10       0.5503 ± 0.14600  0.12 ± 0.0601  0.11 ± 0.047091 #> # ℹ 2,912 more rows"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"dcm-evaluation","dir":"Articles","previous_headings":"","what":"DCM Evaluation","title":"Examination for the Certificate of Proficiency in English","text":"several ways might evaluate estimate model. case study, ’ll focus two: absolute model fit classification reliability.","code":""},{"path":"https://measr.info/dev/articles/ecpe.html","id":"absolute-model-fit","dir":"Articles","previous_headings":"DCM Evaluation","what":"Absolute Model Fit","title":"Examination for the Certificate of Proficiency in English","text":"One common measures model fit DCMs M2 statistic. index limited information goodness--fit measure originally described Maydeu-Olivares & Joe (2005, 2006) adapted DCMs Y. Liu et al. (2016). can calculate M2 model estimated measr fit_m2(). addition calculated M2 statistic, fit_m2() also returns root mean square error approximation (RMSEA) associated confidence interval standardized root mean square residual (SRMSR). estimated LCDM, see M2 value 513.1, corresponding p-value <.01. interpreting M2 p-value, null hypothesis model fits. Thus, p-value represents probability observing M2 value large model fits. estimated LCDM, p-value extremely small, indicating model poor fit. described model evaluation vignette, fully Bayesian estimation allows us evaluate model fit using posterior predictive model checks (PPMCs). Specifically, measr supports PPMC overall raw score distribution described Park et al. (2015) Thompson (2019). replicated data sets, calculate number students raw score (.e., number correct responses). can done using fit_ppmc(). Note can also calculate item-level PPMCs. However, case study interested overall model fit, ’ll set item_fit = NULL save computation time. output, posterior predictive p-value (ppp) small, indicating poor fit. unpack really means, let’s visualize PPMC. following figure, blue bars show credible intervals number respondents expect see raw score point, given estimated model parameters. red dots line indicate number respondents observed raw score point observed data (ecpe_data). example, model expects 110 160 respondents total score 14. observed data, 92 respondents total score 14. general, model tends overestimate number respondents raw score 14–16 23–25. hand, model underestimates number respondents raw score 6–10 27–28.  can quantify different observed raw score distribution replicated data sets calculating χ2-like statistic. , first calculate expected number students raw score taking mean posterior distribution score point. , replicated data set, calculate χ2-like statistic \\[ \\chi^2_{rep} = \\sum_{s=0}^S \\frac{[n_s - E(n_s)]^2}{E(n_s)}, \\] s represents raw score, ns number respondents score point s, E(ns) expected number respondents score point s (.e., mean posterior distribution). calculation completed replicated data sets, creating posterior distribution χ2rep represents plausible values χ2-like statistic model correct. distribution summarized fit_ppmc() output. Specifically, expect χ2-like statistic observed data 12 58, shown following figure. However, calculate statistic observed data, get value 937, way beyond expected range. represented ppp value, proportion χ2rep values larger observed value. case, values χ2rep larger observed value, leading ppp 0.  summary, M2 raw score PPMC indicate poor fit estimated LCDM observed data. unexpected, given classes small. Recall discussion estimated structural parameters three classes combine include less 4% respondents. classes small, parameter estimates can unstable, leading poor model fit (e.g., Hu & Templin, 2020; Ma et al., 2023; Martinez & Templin, 2023; Templin & Bradshaw, 2014; Wang & Lu, 2021).","code":"fit_m2(ecpe_lcdm) #> # A tibble: 1 × 8 #>      m2    df     pval  rmsea ci_lower ci_upper `90% CI`          srmsr #>   <dbl> <int>    <dbl>  <dbl>    <dbl>    <dbl> <chr>             <dbl> #> 1  513.   325 1.28e-10 0.0141   0.0117   0.0163 [0.0117, 0.0163] 0.0320 rawscore_ppmc <- fit_ppmc(ecpe_lcdm, model_fit = \"raw_score\",                           item_fit = NULL, return_draws = 1) rawscore_ppmc #> $model_fit #> $model_fit$raw_score #> # A tibble: 1 × 7 #>   obs_chisq ppmc_mean `2.5%` `97.5%` rawscore_samples     chisq_samples   ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <list>               <list>        <dbl> #> 1      937.      27.5   12.3    58.2 <tibble [2,000 × 1]> <dbl [2,000]>     0 library(ggdist)  obs_scores <- ecpe_data %>%   pivot_longer(cols = -\"resp_id\") %>%   summarize(raw_score = sum(value), .by = resp_id) %>%   count(raw_score) %>%   complete(raw_score = 0:28, fill = list(n = 0L))  rawscore_ppmc$model_fit$raw_score %>%   dplyr::select(rawscore_samples) %>%   unnest(rawscore_samples) %>%   unnest(raw_scores) %>%   ggplot() +   stat_interval(aes(x = raw_score, y = n, color_ramp = after_stat(level)),                 point_interval = \"mean_qi\",                 color = msr_colors[2], linewidth = 5,                 show.legend = c(color = FALSE)) +   geom_line(data = obs_scores,             aes(x = raw_score, y = n),             color = msr_colors[3]) +   geom_point(data = obs_scores,              aes(x = raw_score, y = n, fill = \"Observed Data\"),              shape = 21, color = msr_colors[3], size = 2) +   scale_color_ramp_discrete(from = \"white\", range = c(0.2, 1),                             breaks = c(0.5, 0.8, 0.95),                             labels = ~sprintf(\"%0.2f\", as.numeric(.x))) +   scale_fill_manual(values = c(msr_colors[3])) +   scale_x_continuous(breaks = seq(0, 28, 2), expand = c(0, 0)) +   scale_y_comma() +   labs(x = \"Raw score\", y = \"Respondents\",        color_ramp = \"Credible Interval\", fill = NULL) +   guides(fill = guide_legend(override.aes = list(size = 3))) rawscore_ppmc$model_fit$raw_score %>%   dplyr::select(chisq_samples) %>%   unnest(chisq_samples) %>%   ggplot(aes(x = chisq_samples)) +   stat_dots(quantiles = 500, layout = \"hex\", stackratio = 0.9,             color = msr_colors[2], fill = msr_colors[2],             na.rm = TRUE) +   scale_x_continuous(limits = c(0, 100)) +   labs(y = NULL, x = \"&chi;^2^<sub>rep<\/sub>\") +   theme(axis.text.y = element_blank(),         axis.ticks.y = element_blank())"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"classification-reliability","dir":"Articles","previous_headings":"DCM Evaluation","what":"Classification Reliability","title":"Examination for the Certificate of Proficiency in English","text":"Depending intended uses assessment, may less concerned overall model fit concerned consistency accuracy classifications. words, may focused reliability classifications produced model. several ways evaluate reliability evidence DCMs. comprehensive summary methods, see Sinharay & Johnson (2019). Using measr, can easily calculate wide variety reliability metrics estimated LCDM using reliability(). default, reliability() returns several different types reliability evidence. types evidence, indices range 0–1, values close 1 indicating high accuracy consistency. information relevant depend scores determined reported. example, determine respondent’s scores choosing overall profile consistent observed responses (.e., class probabilities returned predict()). type classification want look pattern reliability, classifying responding overall pattern proficiency attributes. values p_a p_c described Cui et al. (2012). Pa probability classifying random respondent correct class, Pc probability consistently classifying random respondent class across two test administrations. hand, rather basing results overall likely profile, score attribute individually (.e., attribute probabilities returned predict()). accomplished calculating probability proficiency attribute creating classifications based given threshold (usually .5). result known maximum posteriori (MAP) represents likely latent state respondent attribute. pattern-level classifications, attribute level classifications can evaluated accuracy consistency. Johnson & Sinharay (2018) developed accuracy (acc) consistency (consist) metrics attribute level classifications, also examined agreement measures based contingency tables Goodman & Kruskal’s λ, Cohen’s κ, Youden’s J, true positive rate, true negative rate. Using cutoffs recommended Johnson & Sinharay (2018), cohesive rules attribute fair accuracy morphosyntactic lexical rules attributes good accuracy. attributes fair classification consistency. Finally, results reported probabilities proficiency attribute, rather categorical classification. instance, probabilities reported, want report reliability precision probability estimate. type result known expected posteriori (EAP) estimate expected value classification. Johnson & Sinharay (2020) described four metrics evaluating reliability EAP estimates: (1) biserial, (2) informational, (3) parallel forms, (4) constrained parallel forms originally proposed Templin & Bradshaw (2013). paper, Johnson & Sinharay (2020) note types parallel form reliability tend estimate reliability, therefore recommend using biserial informational reliability metrics. metrics available reliability output rho_bs rho_i. Using cutoffs suggested Johnson & Sinharay (2020), three attributes poor EAP reliability. ’s surprising EAP reliability lower MAP reliability, harder place respondents specific point scale (.e., probability scale) place respondents category. example, let’s return example respondent 73. estimated 93% chance respondent proficient lexical rules. However, credible interval tells us probability anywhere 88% 97%. ’s nine percentage point range plausible. don’t great deal certainty specific probability respondent proficient lexical rules; however, entire plausible range high, make classification “proficient” regardless range true probability proficiency . , consistently make classification decision, regardless uncertainty probability .","code":"ecpe_reliability <- reliability(ecpe_lcdm) ecpe_reliability #> $pattern_reliability #>       p_a       p_c  #> 0.7387722 0.6633943  #>  #> $map_reliability #> $map_reliability$accuracy #> # A tibble: 3 × 8 #>   attribute         acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>           <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 morphosyntactic 0.896    0.729   0.787    0.775   0.942 0.851 0.924 #> 2 cohesive        0.852    0.674   0.703    0.698   0.892 0.876 0.822 #> 3 lexical         0.916    0.750   0.610    0.802   0.959 0.947 0.854 #>  #> $map_reliability$consistency #> # A tibble: 3 × 10 #>   attribute       consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>             <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 morphosyntactic   0.835    0.557   0.684    0.647   0.854 0.779 0.868  0.852 #> 2 cohesive          0.807    0.563   0.680    0.609   0.818 0.827 0.782  0.789 #> 3 lexical           0.857    0.554   0.625    0.671   0.876 0.894 0.777  0.880 #> # ℹ 1 more variable: pc_prime <dbl> #>  #>  #> $eap_reliability #> # A tibble: 3 × 5 #>   attribute       rho_pf rho_bs rho_i rho_tb #>   <chr>            <dbl>  <dbl> <dbl>  <dbl> #> 1 morphosyntactic  0.736  0.687 0.573  0.884 #> 2 cohesive         0.730  0.574 0.505  0.785 #> 3 lexical          0.760  0.730 0.587  0.915 ecpe_reliability$pattern_reliability #>       p_a       p_c  #> 0.7387722 0.6633943 ecpe_reliability$map_reliability #> $accuracy #> # A tibble: 3 × 8 #>   attribute         acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>           <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 morphosyntactic 0.896    0.729   0.787    0.775   0.942 0.851 0.924 #> 2 cohesive        0.852    0.674   0.703    0.698   0.892 0.876 0.822 #> 3 lexical         0.916    0.750   0.610    0.802   0.959 0.947 0.854 #>  #> $consistency #> # A tibble: 3 × 10 #>   attribute       consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>             <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 morphosyntactic   0.835    0.557   0.684    0.647   0.854 0.779 0.868  0.852 #> 2 cohesive          0.807    0.563   0.680    0.609   0.818 0.827 0.782  0.789 #> 3 lexical           0.857    0.554   0.625    0.671   0.876 0.894 0.777  0.880 #> # ℹ 1 more variable: pc_prime <dbl> ecpe_reliability$eap_reliability #> # A tibble: 3 × 5 #>   attribute       rho_pf rho_bs rho_i rho_tb #>   <chr>            <dbl>  <dbl> <dbl>  <dbl> #> 1 morphosyntactic  0.736  0.687 0.573  0.884 #> 2 cohesive         0.730  0.574 0.505  0.785 #> 3 lexical          0.760  0.730 0.587  0.915 resp_probs$attribute_probabilities %>%   filter(resp_id == 73) #> # A tibble: 3 × 5 #>   resp_id attribute       probability `2.5%` `97.5%` #>   <fct>   <chr>                 <dbl>  <dbl>   <dbl> #> 1 73      morphosyntactic       0.416  0.274   0.573 #> 2 73      cohesive              0.762  0.655   0.853 #> 3 73      lexical               0.933  0.882   0.966"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Examination for the Certificate of Proficiency in English","text":"case study, estimated LCDM analyze ECPE data. model estimation, saw estimates provided measr highly consistent previously reported parameters estimates ECPE. However, model fit indices indicated LCDM great job represented observed data. likely due dependencies among attributes. analyze data, might consider model different attribute structure, hierarchical diagnostic classification model (Templin & Bradshaw, 2014). Despite poor model fit, reliability indices showed classification consistency accuracy generally fair good range, therefore, depending intended uses, model may sufficient reporting respondent proficiency three attributes.","code":""},{"path":[]},{"path":"https://measr.info/dev/articles/measr.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting started with measr","text":"measr uses Stan backend estimating DCMs, installation rstan cmdstanr required.","code":""},{"path":"https://measr.info/dev/articles/measr.html","id":"rstan","dir":"Articles","previous_headings":"Installation","what":"rstan","title":"Getting started with measr","text":"installing rstan, system must configured compile C++ code. can find instructions RStan Getting Started guide Windows, Mac, Linux. rstan package can installed directly CRAN: verify installation successful, can run test model. everything set correctly, model compile sample. additional troubleshooting help, see RStan Getting Started guide.","code":"install.packages(\"rstan\") library(rstan)  example(stan_model, package = \"rstan\", run.dontrun = TRUE)"},{"path":"https://measr.info/dev/articles/measr.html","id":"cmdstanr","dir":"Articles","previous_headings":"Installation","what":"cmdstanr","title":"Getting started with measr","text":"cmdstanr package yet available CRAN. beta release can installed Stan R package repository: development version can installed GitHub: cmdstanr package requires suitable C++ toolchain. Requirements instructions ensuring toolchain properly set described CmdStan User Guide. can verify C++ toolchain set correctly : Finally, cmdstanr requires CmdStan (shell interface Stan). toolchain properly set , CmdStan can installed : additional installation help, getting Getting Started CmdStanR vignette.","code":"install.packages(\"cmdstanr\",                  repos = c(\"https://mc-stan.org/r-packages/\",                            getOption(\"repos\"))) # install.packages(\"remotes\") remotes::install_github(\"stan-dev/cmdstanr\") library(cmdstanr)  check_cmdstan_toolchain() install_cmdstan(cores = 2)"},{"path":"https://measr.info/dev/articles/measr.html","id":"measr","dir":"Articles","previous_headings":"Installation","what":"measr","title":"Getting started with measr","text":"rstan /cmdstanr installed, ready install measr. released version measr can installed directly CRAN: , development version can installed GitHub: everything installed, ’re ready start estimating evaluating DCMs.","code":"install.packages(\"measr\") # install.packages(\"remotes\") remotes::install_github(\"wjakethompson/measr\") library(measr)"},{"path":"https://measr.info/dev/articles/measr.html","id":"model-estimation","dir":"Articles","previous_headings":"","what":"Model Estimation","title":"Getting started with measr","text":"illustrate, ’ll fit loglinear cognitive diagnostic model (LCDM) assessment English language proficiency (see Templin & Hoffman, 2013). many different subtypes DCMs make different assumptions attributes relate . LCDM general model makes assumptions compensatory nature relationships attributes. details LCDM, see Henson & Templin (2019). data set ’re using contains 29 items together measure three attributes: morphosyntactic rules, cohesive rules, lexical rules. Q-matrix defines attributes measured item. example, item E1 measures morphosyntactic cohesive rules. data described ?ecpe. can estimate LCDM using measr_dcm() function. specify data set, Q-matrix, column names respondent item identifiers (exist). Finally, add two additional arguments. method defines model estimated. computational efficiency, ’ve selected \"optim\", uses Stan’s optimizer estimate model. fully Bayesian estimation, can change method = \"mcmc\". Finally, specify type DCM estimate. previously discussed, ’re estimating LCDM example. details options customizing model specification estimation, see model estimation article measr website. model estimated, can use measr_extract() pull probability respondent proficient attributes. example, first respondent probabilities near 1 attributes, indicating high degree confidence proficient attributes. hand, respondent 8 relatively low probabilities morphosyntactic cohesive attributes, likely proficient lexical rules.","code":"ecpe_data #> # A tibble: 2,922 × 29 #>    resp_id    E1    E2    E3    E4    E5    E6    E7    E8    E9   E10   E11 #>      <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> #>  1       1     1     1     1     0     1     1     1     1     1     1     1 #>  2       2     1     1     1     1     1     1     1     1     1     1     1 #>  3       3     1     1     1     1     1     1     0     1     1     1     1 #>  4       4     1     1     1     1     1     1     1     1     1     1     1 #>  5       5     1     1     1     1     1     1     1     1     1     1     1 #>  6       6     1     1     1     1     1     1     1     1     1     1     1 #>  7       7     1     1     1     1     1     1     1     1     1     1     1 #>  8       8     0     1     1     1     1     1     0     1     1     1     0 #>  9       9     1     1     1     1     1     1     1     1     1     1     1 #> 10      10     1     1     1     1     0     0     1     1     1     1     1 #> # ℹ 2,912 more rows #> # ℹ 17 more variables: E12 <int>, E13 <int>, E14 <int>, E15 <int>, E16 <int>, #> #   E17 <int>, E18 <int>, E19 <int>, E20 <int>, E21 <int>, E22 <int>, #> #   E23 <int>, E24 <int>, E25 <int>, E26 <int>, E27 <int>, E28 <int>  ecpe_qmatrix #> # A tibble: 28 × 4 #>    item_id morphosyntactic cohesive lexical #>    <chr>             <int>    <int>   <int> #>  1 E1                    1        1       0 #>  2 E2                    0        1       0 #>  3 E3                    1        0       1 #>  4 E4                    0        0       1 #>  5 E5                    0        0       1 #>  6 E6                    0        0       1 #>  7 E7                    1        0       1 #>  8 E8                    0        1       0 #>  9 E9                    0        0       1 #> 10 E10                   1        0       0 #> # ℹ 18 more rows ecpe_lcdm <- measr_dcm(data = ecpe_data, qmatrix = ecpe_qmatrix,                        resp_id = \"resp_id\", item_id = \"item_id\",                        method = \"optim\", type = \"lcdm\") ecpe_lcdm <- add_respondent_estimates(ecpe_lcdm) measr_extract(ecpe_lcdm, \"attribute_prob\") #> # A tibble: 2,922 × 4 #>    resp_id morphosyntactic cohesive lexical #>    <fct>             <dbl>    <dbl>   <dbl> #>  1 1               0.997      0.962   1.00  #>  2 2               0.995      0.900   1.00  #>  3 3               0.985      0.990   1.00  #>  4 4               0.998      0.991   1.00  #>  5 5               0.989      0.985   0.965 #>  6 6               0.993      0.991   1.00  #>  7 7               0.993      0.991   1.00  #>  8 8               0.00411    0.471   0.964 #>  9 9               0.949      0.986   0.999 #> 10 10              0.552      0.142   0.111 #> # ℹ 2,912 more rows"},{"path":"https://measr.info/dev/articles/measr.html","id":"model-evaluation","dir":"Articles","previous_headings":"","what":"Model Evaluation","title":"Getting started with measr","text":"many ways evaluate estimated model including model fit, model comparisons, reliability. complete listing available options, see ?model_evaluation. illustrate functions work, ’ll look classification accuracy consistency metrics described Johnson & Sinharay (2018). start adding reliability information estimated model using add_reliability(). can extract information, using measr_extract(). indices, numbers close 1 indicate high level classification accuracy consistency. numbers amazing, overall look pretty good. guidance cutoff values “good,” “fair,” etc. reliability, see Johnson & Sinharay (2018).","code":"ecpe_lcdm <- add_reliability(ecpe_lcdm) measr_extract(ecpe_lcdm, \"classification_reliability\") #> # A tibble: 3 × 3 #>   attribute       accuracy consistency #>   <chr>              <dbl>       <dbl> #> 1 morphosyntactic    0.897       0.835 #> 2 cohesive           0.858       0.809 #> 3 lexical            0.918       0.858"},{"path":[]},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Estimating diagnostic classification models","text":"demonstrate model estimation functionality measr, ’ll examine simulated data set. data set contains 2,000 respondents 20 items measure total 4 attributes, item measures 2 attributes. data generated loglinear cognitive diagnostic model (LCDM), general model subsumes many DCM subtypes (Henson et al., 2009). using simulated data set, can compare parameter estimates measr true data generating parameters.","code":"library(tidyverse)  sim_data <- read_rds(\"data/simulated-data.rds\")  sim_data$data #> # A tibble: 2,000 × 21 #>    resp_id    A1    A2    A3    A4    A5    A6    A7    A8    A9   A10   A11 #>      <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> #>  1       1     1     1     0     1     0     0     0     0     1     0     1 #>  2       2     1     1     1     0     0     1     0     1     1     0     1 #>  3       3     1     1     1     1     1     0     1     1     0     1     1 #>  4       4     1     0     1     0     0     1     0     1     1     0     1 #>  5       5     1     1     0     0     0     0     0     1     1     0     1 #>  6       6     1     1     1     0     1     0     0     1     1     0     1 #>  7       7     1     0     1     0     0     1     0     1     1     0     1 #>  8       8     0     1     1     0     0     1     0     1     1     0     0 #>  9       9     1     1     1     0     0     1     1     1     1     0     1 #> 10      10     1     1     1     0     1     1     0     1     1     1     1 #> # ℹ 1,990 more rows #> # ℹ 9 more variables: A12 <int>, A13 <int>, A14 <int>, A15 <int>, A16 <int>, #> #   A17 <int>, A18 <int>, A19 <int>, A20 <int>  sim_data$q_matrix #> # A tibble: 20 × 5 #>    item_id  att1  att2  att3  att4 #>    <chr>   <int> <int> <int> <int> #>  1 A1          0     1     0     1 #>  2 A2          0     0     1     1 #>  3 A3          1     1     0     0 #>  4 A4          1     0     0     0 #>  5 A5          1     0     0     1 #>  6 A6          0     1     0     0 #>  7 A7          1     0     0     0 #>  8 A8          0     1     0     1 #>  9 A9          0     1     0     1 #> 10 A10         1     0     0     1 #> 11 A11         1     0     0     1 #> 12 A12         0     0     1     1 #> 13 A13         0     0     1     1 #> 14 A14         0     0     1     0 #> 15 A15         0     1     0     1 #> 16 A16         0     1     0     0 #> 17 A17         0     0     0     1 #> 18 A18         1     0     1     0 #> 19 A19         0     1     0     1 #> 20 A20         0     0     0     1"},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"specifying-a-dcm-for-estimation","dir":"Articles","previous_headings":"","what":"Specifying a DCM for Estimation","title":"Estimating diagnostic classification models","text":"measr, DCMs specified estimated using measr_dcm() function. ’ll start estimating loglinear cognitive diagnostic model (LCDM). LCDM general DCM subsumes many DCM subtypes (Henson et al., 2009). First, specify data (data) Q-matrix (qmatrix) used estimate model. Note required arguments measr_dcm() function. arguments provided, sensible defaults (described ) take care rest specification estimation. Next, can specify columns, , data qmatrix contain respondent identifiers item identifiers , respectively. one variables present data, arguments can omitted, measr assign identifiers based row number (.e., row 1 qmatrix becomes item 1). can specify type DCM want estimate. current options \"lcdm\" (default) \"dina\", \"dino\" (see Estimating DCM Sub-Types ). also option choose estimation engine use, via \"backend\" argument. default backend backend = \"rstan\", use rstan package estimate model. Alternatively, can use cmdstanr package estimate model specifying backend = \"cmdstanr\". cmdstanr package works using local installation Stan estimate models, rather version pre-compiled rstan. backend chosen, can supply additional arguments specific estimating functions. example , specify 500 warm-iterations per chain, 500 post-warm-iterations per chain, 4 cores run chains parallel. full set options available rstan cmdstanr can found looking help pages rstan::sampling() cmdstanr::`model-method-sample`, respectively. Finally, estimating models can time intensive, can specify file. file specified, R object fitted model automatically saved specified file. specified file already exists, fitted model read back R, eliminating need re-estimate model.","code":"lcdm <- measr_dcm(data = sim_data$data, qmatrix = sim_data$q_matrix,                   resp_id = \"resp_id\", item_id = \"item_id\",                   type = \"lcdm\", method = \"mcmc\", backend = \"cmdstanr\",                   iter_warmup = 1000, iter_sampling = 500,                   chains = 4, parallel_chains = 4,                   file = \"fits/sim-lcdm\")"},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"examining-parameter-estimates","dir":"Articles","previous_headings":"Specifying a DCM for Estimation","what":"Examining Parameter Estimates","title":"Estimating diagnostic classification models","text":"Now ’ve estimated model, let’s compare parameter estimates true values used generate data. can start looking estimates using measr_extract(). function extracts different aspects model estimated measr. , estimate column reports estimated value parameter measure associated error (.e., standard deviation posterior distribution). example, item A1 measures two attributes therefore four parameters: intercept, represents log-odds providing correct response respondent proficient neither attributes item measures (.e., att2 att4). main effect second attribute, represents increase log-odds providing correct response respondent proficient attribute. main effect fourth attribute, represents increase log-odds providing correct response respondent proficient attribute. interaction second fourth attributes, change log-odds respondent proficient attributes. can compare estimates used generate data. figure , parameters fall close dashed line, represents perfect agreement, indicating estimated model accurately estimating parameter values.  can also examine structural parameters, represent overall proportion respondents class. , see relatively strong agreement estimates model true generating values.","code":"item_parameters <- measr_extract(lcdm, what = \"item_param\") item_parameters #> # A tibble: 66 × 5 #>    item_id class       attributes coef         estimate #>    <fct>   <chr>       <chr>      <glue>     <rvar[1d]> #>  1 A1      intercept   NA         l1_0    -0.98 ± 0.098 #>  2 A1      maineffect  att2       l1_12    2.46 ± 0.158 #>  3 A1      maineffect  att4       l1_14    4.46 ± 0.314 #>  4 A1      interaction att2__att4 l1_224   0.15 ± 1.331 #>  5 A2      intercept   NA         l2_0    -2.40 ± 0.301 #>  6 A2      maineffect  att3       l2_13    3.99 ± 0.323 #>  7 A2      maineffect  att4       l2_14    3.81 ± 0.339 #>  8 A2      interaction att3__att4 l2_234  -3.58 ± 0.381 #>  9 A3      intercept   NA         l3_0    -2.01 ± 0.160 #> 10 A3      maineffect  att1       l3_11    2.22 ± 0.195 #> # ℹ 56 more rows"},{"path":[]},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"prior-distributions","dir":"Articles","previous_headings":"Customizing the Model Estimation Process","what":"Prior Distributions","title":"Estimating diagnostic classification models","text":"code estimate LCDM , specify prior distributions call measr_dcm(). default, measr uses following prior distributions LCDM: can see, main effect parameters get lognormal(0, 1) prior default. Different prior distributions can specified prior() function. example, can specify normal(0, 10) prior main effects : default, prior applied parameters class (.e., main effects). However, can also apply prior specific parameter. example, specify χ2 distribution 2 degrees freedom default prior main effects, exponential distribution rate 2 main effect attribute 1 just item 7. see parameters (including class coef) can specified, can use get_parameters(). distribution supported Stan language can used prior. list distributions available Stan documentation, linked ?prior() help page. Priors can defined estimating function, created time model estimated. example, following equivalent. set prior main effects truncated normal distribution lower bound 0. done main effects LCDM constrained positive ensure monotonicity model. Additionally note ’ve set method = \"optim\". means estimate model using Stan’s optimizer, rather using full Markov Chain Monte Carlo. Note prior still influences model using method = \"optim\", just using method = \"mcmc\" (default). priors used estimate model saved returned model object, can always go back see priors used unsure. can see new_lcdm model, specified normal prior used main effects, default priors still applied parameters explicitly state prior distribution.","code":"default_dcm_priors(type = \"lcdm\") #> # A tibble: 4 × 3 #>   class       coef  prior_def                   #>   <chr>       <chr> <chr>                       #> 1 intercept   NA    normal(0, 2)                #> 2 maineffect  NA    lognormal(0, 1)             #> 3 interaction NA    normal(0, 2)                #> 4 structural  Vc    dirichlet(rep_vector(1, C)) prior(normal(0, 10), class = \"maineffect\") #> # A tibble: 1 × 3 #>   class      coef  prior_def     #>   <chr>      <chr> <chr>         #> 1 maineffect NA    normal(0, 10) c(prior(chi_square(2), class = \"maineffect\"),   prior(exponential(2), class = \"maineffect\", coef = \"l7_11\")) #> # A tibble: 2 × 3 #>   class      coef  prior_def      #>   <chr>      <chr> <chr>          #> 1 maineffect NA    chi_square(2)  #> 2 maineffect l7_11 exponential(2)  get_parameters(sim_data$q_matrix, item_id = \"item_id\", type = \"lcdm\") #> # A tibble: 67 × 4 #>    item_id class       attributes coef   #>    <fct>   <chr>       <chr>      <glue> #>  1 A1      intercept   NA         l1_0   #>  2 A1      maineffect  att2       l1_12  #>  3 A1      maineffect  att4       l1_14  #>  4 A1      interaction att2__att4 l1_224 #>  5 A2      intercept   NA         l2_0   #>  6 A2      maineffect  att3       l2_13  #>  7 A2      maineffect  att4       l2_14  #>  8 A2      interaction att3__att4 l2_234 #>  9 A3      intercept   NA         l3_0   #> 10 A3      maineffect  att1       l3_11  #> # ℹ 57 more rows new_prior <- prior(normal(0, 15), class = \"maineffect\", lb = 0) new_lcdm <- measr_dcm(data = sim_data$data, qmatrix = sim_data$q_matrix,                       resp_id = \"resp_id\", item_id = \"item_id\",                       type = \"lcdm\", method = \"optim\", backend = \"cmdstanr\",                       prior = new_prior,                       file = \"fits/sim-lcdm-optim\")  new_lcdm <- measr_dcm(data = sim_data$data, qmatrix = sim_data$q_matrix,                       resp_id = \"resp_id\", item_id = \"item_id\",                       type = \"lcdm\", method = \"optim\", backend = \"cmdstanr\",                       prior = c(prior(normal(0, 15), class = \"maineffect\",                                       lb = 0)),                       file = \"fits/sim-lcdm-optim\") measr_extract(new_lcdm, \"prior\") #> # A tibble: 4 × 3 #>   class       coef  prior_def                   #>   <chr>       <chr> <chr>                       #> 1 maineffect  NA    normal(0, 15)T[0,]          #> 2 intercept   NA    normal(0, 2)                #> 3 interaction NA    normal(0, 2)                #> 4 structural  Vc    dirichlet(rep_vector(1, C))"},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"subtype","dir":"Articles","previous_headings":"Customizing the Model Estimation Process","what":"Other DCM Sub-Types","title":"Estimating diagnostic classification models","text":"Although primary motivation measr provide researchers software makes LCDM readily accessible, popular DCM subtypes also supported. example, can estimate deterministic inputs, noisy “” gate (DINA, Junker & Sijtsma, 2001) deterministic inputs, noisy “” gate (DINO, Templin & Henson, 2006) models specifying different type measr_dcm() function. Future development work continue add functionality DCM subtypes. specific subtype interested , like see supported, please open issue GitHub repository.","code":""},{"path":[]},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Evaluating diagnostic classification models","text":"demonstrate model fit functionality measr, ’ll use simulated data set used illustrate model estimation functionality. data set contains 2,000 respondents 20 items measure total 4 attributes, item measures 2 attributes. data generated loglinear cognitive diagnostic model (LCDM), general model subsumes many DCM subtypes (Henson et al., 2009). demonstrate model fit functionality, ’ll first fit LCDM deterministic-input, noisy “” gate (DINA) model (de la Torre & Douglas, 2004) data set order compare fit indices. LCDM used generate fake data, expect estimated LCDM model perform well. hand, DINA model places heavy constraints LCDM, therefore expect worse performance DINA model. details model estimation, see Estimating diagnostic classification models.","code":"library(tidyverse)  sim_data <- read_rds(\"data/simulated-data.rds\")  lcdm <- measr_dcm(data = sim_data$data, qmatrix = sim_data$q_matrix,                   resp_id = \"resp_id\", item_id = \"item_id\",                   type = \"lcdm\", method = \"mcmc\", backend = \"cmdstanr\",                   iter_warmup = 1000, iter_sampling = 500,                   chains = 4, parallel_chains = 4,                   file = \"fits/sim-lcdm\")  dina <- measr_dcm(data = sim_data$data, qmatrix = sim_data$q_matrix,                   resp_id = \"resp_id\", item_id = \"item_id\",                   type = \"dina\", method = \"mcmc\", backend = \"cmdstanr\",                   iter_warmup = 1000, iter_sampling = 500,                   chains = 4, parallel_chains = 4,                   file = \"fits/sim-dina.rds\")"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"model-evaluation","dir":"Articles","previous_headings":"","what":"Model Evaluation","title":"Evaluating diagnostic classification models","text":"three major types evaluations supported measr. Absolute model fit Relative model fit (.e., model comparisons) Reliability discussed turn.","code":""},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"absolute-model-fit","dir":"Articles","previous_headings":"Model Evaluation","what":"Absolute Model Fit","title":"Evaluating diagnostic classification models","text":"Absolute model fit measures well estimated model fits observed data. One popular methods evaluating absolute model fit DCMs M2 statistic (Hansen et al., 2016; Liu et al., 2016). can calculate M2 statistics fit_m2() function. function returns data frame M2 statistic (m2), degrees freedom p-value associated M2 (df pval, respectively). p-value less .05 typically indicate poor model fit. expected example, estimated LCDM shows adequate model fit data (p > .05). fit_m2() also return information RMSEA SRMSR fit statistics. M2, RMSEA, SRMSR considered limited-information fit indices. example, M2 based univariate item statistics bivariate relationships items. Thus, capture aspects model fit higher-order relationships (e.g., triplets items). used fully Bayesian estimation models, can use posterior distributions provide another evaluation model fit can incorporate information. method known posterior predictive model check (PPMC). general process PPMCs follows: draw posterior distribution, generate synthetic data set using parameters values draw. synthetic data set calculate summary data. process creates posterior distribution summary. synthetic data sets generated parameter values posterior distribution, distribution data summary represents expect summary look like, estimated model correct true. Calculate data summary observed data set. Compare summary observed data posterior distribution. observed value falls within posterior distribution summary, evidence estimated model consistent observed data. hand, discrepancies observed value posteriors indicates inconsistencies. PPMCs can used evaluate model- item-level fit. model level, fit evaluated expected raw score distribution, described Park et al. (2015) Thompson (2019). item level, can evaluate fit examining expected conditional probabilities members class providing correct response (Sinharay & Almond, 2007; Thompson, 2019), well expected odds ratio pair items (Park et al., 2015; Sinharay et al., 2006). measr, PPMCs can calculated fit_ppmc(). Using fit_ppmc() can specify PPMCs calculate. example, estimate just model-level raw score check setting item_fit = NULL. fit_ppmc() returns list, element different PPMC. , specified one PPMC, get raw_score element back. obs_chisq raw score χ2 values observed data. see mean posterior distribution χ2, quantiles posterior distribution, posterior predictive p-value (ppp). ppp proportion posterior draws greater observed value. Values close 0 indicate poor fit. Values close 1 may indicate overfitting. LCDM used generate data, ’s surprising ppp approaching 1 estimated model, model perfectly capturing data generating process. can also specify posterior quantiles returned. example, can calculate item-level odds ratios request quantiles result 90% credible interval. see similar output item-level indices: observed odds ratio item pair (obs_or), mean posterior distribution item pair (ppmc_mean), quantiles posterior specified, ppp. raw score distribution, ppp represents proportion posterior draws odds ratio greater observed value.","code":"fit_m2(lcdm) #> # A tibble: 1 × 8 #>      m2    df  pval rmsea ci_lower ci_upper `90% CI`     srmsr #>   <dbl> <int> <dbl> <dbl>    <dbl>    <dbl> <chr>        <dbl> #> 1  121.   129 0.670     0        0   0.0091 [0, 0.0091] 0.0166 fit_ppmc(lcdm, model_fit = \"raw_score\", item_fit = NULL) #> $model_fit #> $model_fit$raw_score #> # A tibble: 1 × 5 #>   obs_chisq ppmc_mean `2.5%` `97.5%`   ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <dbl> #> 1      24.2      23.3   11.1    39.7 0.402 fit_ppmc(lcdm, model_fit = NULL, item_fit = \"odds_ratio\",          probs = c(0.05, 0.95)) #> $item_fit #> $item_fit$odds_ratio #> # A tibble: 190 × 7 #>    item_1 item_2 obs_or ppmc_mean `2.5%` `97.5%`   ppp #>    <fct>  <fct>   <dbl>     <dbl>  <dbl>   <dbl> <dbl> #>  1 A1     A2      2.61       2.73  2.13     3.49 0.614 #>  2 A1     A3      2.04       1.97  1.56     2.49 0.346 #>  3 A1     A4      0.904      1.07  0.841    1.34 0.914 #>  4 A1     A5      1.99       2.13  1.65     2.70 0.660 #>  5 A1     A6      3.27       3.23  2.47     4.26 0.421 #>  6 A1     A7      0.966      1.05  0.826    1.31 0.762 #>  7 A1     A8      6.78       6.58  4.84     8.90 0.390 #>  8 A1     A9     10.1        9.75  7.27    13.1  0.364 #>  9 A1     A10     2.98       2.86  2.14     3.77 0.364 #> 10 A1     A11     2.98       3.08  2.42     3.89 0.579 #> # ℹ 180 more rows"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"relative-model-fit","dir":"Articles","previous_headings":"","what":"Relative Model Fit","title":"Evaluating diagnostic classification models","text":"Relative fit measures used compare multiple competing models. case, estimate LCDM DINA model want compare model performs better. first note “better” necessarily mean “good.” Evidence one model performs better another evidence “good” fit absolute sense. absolute model fit indices can provide evidence adequate fit data. However, multiple models show adequate absolute fit, relative fit indices can used, along understanding constructs, select preferred model. Currently, Stan ecosystem supports two information criteria loo package can used relative fit indices: leave-one-(LOO) cross validation Pareto-smoothed importance sampling (Vehtari et al., 2017, 2022) widely applicable information criterion (WAIC) described Watanabe (2010). information criteria can calculated using associated functions loo package (.e., loo() waic()). , calculate LOO LCDM DINA models. isolation, output useful, indices meant facilitate model comparisons. can conduct model comparisons using loo_compare(), used comparing LOO WAIC estimates. output, model first row preferred model. subsequent rows, epld_diff column reports difference information criteria (case LOO) model row preferred model. se_diff column standard error difference model preferred model. Bengio & Grandvalet (2004) recommended cutoff 2.5 standard errors identifying preferred model. example, absolute value elpd_diff greater 49.2 × 2.5 = 123, conclude LCDM fits significantly better DINA model. expected outcome case, given data generation process results absolute model fit analysis. difference less 2.5 standard errors, conclude models fit equally well.","code":"lcdm_loo <- loo(lcdm) lcdm_loo #>  #> Computed from 2000 by 2000 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -21731.8 102.7 #> p_loo        78.1   1.2 #> looic     43463.6 205.3 #> ------ #> Monte Carlo SE of elpd_loo is 0.2. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  dina_loo <- loo(dina) dina_loo #>  #> Computed from 2000 by 2000 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -23579.8  83.2 #> p_loo       831.0  18.7 #> looic     47159.7 166.4 #> ------ #> Monte Carlo SE of elpd_loo is 0.6. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details. loo_compare(list(lcdm = lcdm_loo, dina = dina_loo)) #>      elpd_diff se_diff #> lcdm     0.0       0.0 #> dina -1848.1      49.2 loo_comp <- loo_compare(list(lcdm = lcdm_loo, dina = dina_loo))"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"reliability","dir":"Articles","previous_headings":"","what":"Reliability","title":"Evaluating diagnostic classification models","text":"can also evaluate DCMs reliability. , ’s important understand accuracy consistency classifications made model. models estimated measr, estimates reliability can calculated using reliability(). several types reliability evidence provided output. indices reported, values can range 0 1, 1 represents perfect accuracy consistency. first type reliability output pattern-level reliability, described Cui et al. (2012). reliability describes accuracy (p_a) consistency (p_c) classification respondents overall profile proficiency assessed skills. example, 3-attribute assessment 8 possible profiles: [0,0,0], [1,0,0], [0,1,0], [0,0,1], [1,1,0], [1,0,1], [0,1,1], [1,1,1]. One option reporting results DCM-based assessment select profile likely respondent. pattern-level reliability metrics provide measure accuracy consistency type classification. hand, rather reporting results based overall likely profile, can assign proficiency individual attribute, build overall profile attribute-level decisions. type reporting may may result profile overall likely profile. scenario classifications made attribute level, need examine classification accuracy consistency individual attribute. models estimated measr, referred maximum posteriori (MAP) reliability, classifications based likely category attribute respondent. MAP values reported output described Johnson & Sinharay (2018). acc consist variables map_reliability$accuracy map_reliability_consistency tables, respectively, classification accuracy consistency metrics described Johnson & Sinharay (2018). paper, also compared metrics measures agreement (e.g., Cohen’s κ, Goodman Kruskal’s λ), also included output. Johnson & Sinharay (2018) also provide recommendations threshold values metric represent poor, fair, good, good, excellent reliability. Finally, rather reporting results classifications (e.g., proficient/proficient), results can also reported simply probability respondent proficient attribute. Thus, rather reporting accuracy consistency classification, report precision reported probability. referred expected posteriori (EAP) reliability, probability represents expected value attribute respondent. EAP values reported output (eap_reliability) described Johnson & Sinharay (2020) Templin & Bradshaw (2013). Templin & Bradshaw (2013) describe reliability index based restrictive assumption parallel forms (rho_tb). Johnson & Sinharay (2020) described generalized parallel forms reliability (rho_pf), along additional biserial (rho_bs), informational (rho_i) reliability indices. proficiency probabilities provided attribute level, EAP reliability estimates also provided attribute measured assessment. classification reliability indices, Johnson & Sinharay (2020) provide recommendations thresholds representing poor, fair, good, good, excellent reliability four EAP reliability indices.","code":"reliability(lcdm) #> $pattern_reliability #>       p_a       p_c  #> 0.7441110 0.6093565  #>  #> $map_reliability #> $map_reliability$accuracy #> # A tibble: 4 × 8 #>   attribute   acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>     <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 att1      0.931    0.857   0.245    0.862   0.976 0.929 0.933 #> 2 att2      0.980    0.955   0.944    0.960   0.998 0.981 0.979 #> 3 att3      0.835    0.633   0.650    0.659   0.868 0.882 0.777 #> 4 att4      0.966    0.931   0.396    0.932   0.994 0.968 0.964 #>  #> $map_reliability$consistency #> # A tibble: 4 × 10 #>   attribute consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>       <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 att1        0.873    0.738   0.860    0.746   0.922 0.869 0.877  0.898 #> 2 att2        0.960    0.909   0.935    0.918   0.992 0.955 0.964  0.970 #> 3 att3        0.761    0.422   0.622    0.507   0.717 0.796 0.711  0.771 #> 4 att4        0.936    0.870   0.932    0.871   0.980 0.935 0.936  0.948 #> # ℹ 1 more variable: pc_prime <dbl> #>  #>  #> $eap_reliability #> # A tibble: 4 × 5 #>   attribute rho_pf rho_bs rho_i rho_tb #>   <chr>      <dbl>  <dbl> <dbl>  <dbl> #> 1 att1       0.800  0.796 0.647  0.949 #> 2 att2       0.936  0.938 0.717  0.995 #> 3 att3       0.619  0.537 0.480  0.748 #> 4 att4       0.902  0.897 0.700  0.987"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"storing-model-evaluations","dir":"Articles","previous_headings":"","what":"Storing Model Evaluations","title":"Evaluating diagnostic classification models","text":"followed along running code vignette, noticed model evaluations take significant amount computation time. means repeating calculations (e.g., didn’t assign output new new object, opened new R session) can time-consuming process. make analysis efficient, measr offers several functions can used add model evaluation metrics described vignette directly model object. specified file model estimated, updated model object model evaluation components automatically resave, ensuring don’t rerun computationally intensive tasks. three functions adding model evaluation components model object, correspond three types evaluation described vignette: add_fit(): Adds absolute model fit indices (.e., M2, PPMCs) add_criterion(): Adds relative model fit indices (.e., LOO, WAIC) add_reliability(): Adds reliability metrics three functions several arguments common. x: model add evaluation components . save: Whether resave model object file specified estimating model. default TRUE. overwrite: Whether overwrite existing evaluations. example, attempt add reliability metrics add_reliability(), metrics already added, reliability metrics recalculated overwrite existing metrics? default FALSE. Additionally, three functions ... argument passing additional arguments along relevant functions. example, want add PPMC absolute model fit indices, can specify types model- item-level fit indices calculate, just using fit_ppmc(). components added model, helper function, measr_extract(), can used pull relevant pieces output. example, can extract PPMC raw score results. addition, can also extract elements model, priors used estimation, estimated parameters like base rate membership class. complete list can extract measr_extract(), see ?measr_extract.","code":"lcdm <- add_fit(lcdm, method = \"ppmc\",                 model_fit = \"raw_score\",                 item_fit = \"odds_ratio\") measr_extract(lcdm, what = \"ppmc_raw_score\") #> # A tibble: 1 × 5 #>   obs_chisq ppmc_mean `2.5%` `97.5%`   ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <dbl> #> 1      24.2      23.3   11.1    39.7 0.402 measr_extract(lcdm, what = \"prior\") #> # A tibble: 4 × 3 #>   class       coef  prior_def                   #>   <chr>       <chr> <chr>                       #> 1 intercept   NA    normal(0, 2)                #> 2 maineffect  NA    lognormal(0, 1)             #> 3 interaction NA    normal(0, 2)                #> 4 structural  Vc    dirichlet(rep_vector(1, C))  measr_extract(lcdm, what = \"strc_param\") #> # A tibble: 16 × 2 #>    class            estimate #>    <chr>          <rvar[1d]> #>  1 [0,0,0,0]  0.059 ± 0.0068 #>  2 [1,0,0,0]  0.080 ± 0.0078 #>  3 [0,1,0,0]  0.063 ± 0.0064 #>  4 [0,0,1,0]  0.083 ± 0.0078 #>  5 [0,0,0,1]  0.052 ± 0.0087 #>  6 [1,1,0,0]  0.044 ± 0.0058 #>  7 [1,0,1,0]  0.051 ± 0.0067 #>  8 [1,0,0,1]  0.060 ± 0.0105 #>  9 [0,1,1,0]  0.083 ± 0.0080 #> 10 [0,1,0,1]  0.049 ± 0.0078 #> 11 [0,0,1,1]  0.081 ± 0.0094 #> 12 [1,1,1,0]  0.043 ± 0.0067 #> 13 [1,1,0,1]  0.043 ± 0.0092 #> 14 [1,0,1,1]  0.092 ± 0.0114 #> 15 [0,1,1,1]  0.047 ± 0.0083 #> 16 [1,1,1,1]  0.068 ± 0.0095"},{"path":[]},{"path":"https://measr.info/dev/articles/paper.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"measr: Bayesian psychometric measurement using Stan","text":"educational psychological research, often interested discrete latent states individuals responding assessment (e.g., proficiency non-proficiency educational standards, presence absence psychological disorder). Diagnostic classification models (DCMs; also called cognitive diagnostic models [CDMs]) type psychometric model facilitates inferences (Rupp et al., 2010; von Davier & Lee, 2019). DCMs multi-dimensional, meaning can classify respondents multiple latent attributes within profile skills. Q-matrix used define items assessment measure attribute. Using pre-defined latent profiles Q-matrix, DCMs estimate probability respondents profile, corresponding pattern proficiency, presence, attributes. means DCMs able provide fine-grained feedback specific skills may need additional instruction educational context, particular symptoms may contributing diagnosis psychological context. Finally, DCMs classifying respondents rather placing along performance continuum, models able achieve reliable results shorter test lengths (Templin & Bradshaw, 2013), reducing burden respondents. Given benefits, goal measr make DCMs accessible applied researchers practitioners providing simple interface estimating evaluating DCMs.","code":""},{"path":"https://measr.info/dev/articles/paper.html","id":"statement-of-need","dir":"Articles","previous_headings":"","what":"Statement of need","title":"measr: Bayesian psychometric measurement using Stan","text":"measr R package developed easily estimate evaluate DCMs applied settings. Despite ability DCMs provide reliable, fine-grained feedback specific skills, models widely used research operational programs. due large part limitations existing software estimating evaluating DCMs (Ravand & Baghaei, 2020; Sessoms & Henson, 2018). Typically, DCMs estimated maximum likelihood estimator evaluated using limited-information fit indices (e.g., Liu et al., 2016). approach taken using Mplus (e.g., Templin & Hoffman, 2013) popular R packages GDINA (Ma & de la Torre, 2020) CDM (George et al., 2016). However, name “limited-information” implies, methods look limited relationships items, univariate bivariate relationships. means higher-level relationships items evaluated (e.g., relationships triplets items). Bayesian estimation methods offer robust methods evaluating model fit posterior predictive checks (Park et al., 2015; Thompson, 2019). date, three R packages offer Bayesian estimation DCMs: dina (Culpepper, 2015), hmcdm (Zhang et al., 2023), blatent (Templin, 2020). However, packages estimate single type DCM, severely limiting generalizability wide range applications. measr package seeks overcome limitations existing software options serving interface Stan probabilistic programming language (Carpenter et al., 2017). Stan backend, measr can estimate wide variety DCMs. Primarily, measr supports estimation loglinear cognitive diagnostic model (LCDM). However, LCDM general DCM subsumes many subtypes (Henson et al., 2008), measr also supports DCMs deterministic inputs, noisy “” gate (DINA) model (de la Torre & Douglas, 2004) deterministic inputs, noisy “” gate (DINO) model (Templin & Henson, 2006). estimation, measr provides model evaluations using limited-information indices posterior predictive checks. providing straightforward estimation evaluation DCMs, measr makes models accessible practitioners applied researchers. Thus, measr, users get power Bayesian methods model evaluation, compatibility packages larger Stan ecosystem, user-friendly interface knowledge Stan language required. However, models estimated measr also include fitted Stan object, users can access familiar Stan prefer work object. Additionally, Stan code used estimate model also returned users familiar Stan language can use code starting point writing customized models.","code":""},{"path":"https://measr.info/dev/articles/paper.html","id":"acknowledgments","dir":"Articles","previous_headings":"","what":"Acknowledgments","title":"measr: Bayesian psychometric measurement using Stan","text":"research reported supported Institute Education Sciences, U.S. Department Education, Grant R305D210045 University Kansas. opinions expressed authors represent views Institute U.S. Department Education. grateful project advisory committee members provided feedback development R package: Russell Almond, Claudia Flowers, Robert Henson, Matthew Madison.","code":""},{"path":[]},{"path":"https://measr.info/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"W. Jake Thompson. Author, maintainer. Nathan Jones. Contributor. Matthew Johnson. Copyright holder.            Provided code adapted reliability.measrdcm() Paul-Christian Bürkner. Copyright holder.            Author eval_silent() University Kansas. Copyright holder. Institute Education Sciences. Funder.","code":""},{"path":"https://measr.info/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Thompson WJ (2023). “measr: Bayesian psychometric measurement using Stan.” Journal Open Source Software, 8(91), 5742. doi:10.21105/joss.05742.","code":"@Article{,   title = {{measr}: {Bayesian} psychometric measurement using {Stan}},   author = {W. Jake Thompson},   year = {2023},   journal = {Journal of Open Source Software},   volume = {8},   number = {91},   pages = {5742},   doi = {10.21105/joss.05742}, }"},{"path":"https://measr.info/dev/index.html","id":"measr-","dir":"","previous_headings":"","what":"Estimate Diagnostic Classification Models with Stan","title":"Estimate Diagnostic Classification Models with Stan","text":"Diagnostic classification models (DCMs) class psychometric models estimate respondent abilities profile proficiency pre-defined set skills, attributes. Despite utility DCMs providing fine-grained actionable feedback shorter assessments, widely used applied settings, part due lack user-friendly software. Using R Stan, measr (said: “measure”) simplifies process estimating evaluating DCMs. Users can specify different DCM subtypes, define prior distributions, estimate model using rstan cmdstanr interface Stan. can easily examine model parameters, calculate model fit metrics, compare competing models, evaluate reliability attributes.","code":""},{"path":"https://measr.info/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimate Diagnostic Classification Models with Stan","text":"can install released version measr CRAN : install development version measr GitHub use: measr based Stan, C++ compiler required. Windows, Rtools program comes C++ compiler. Mac, ’s recommended install Xcode. additional instructions help setting compilers, see RStan installation help page.","code":"install.packages(\"measr\") # install.packages(\"remotes\") remotes::install_github(\"wjakethompson/measr\")"},{"path":"https://measr.info/dev/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Estimate Diagnostic Classification Models with Stan","text":"can estimate DCM using measr_dcm(). function requires data set item responses Q-matrix defining attributes measured item. also identify respondent item identifier columns. arguments can specified customize type model estimates (see ?measr_dcm()). demonstrate measr’s functionality, example data sets included. use Examination Certificate Proficiency English (ECPE; Templin & Hoffman, 2013) data (see ?ecpe details). Note default, measr uses full Markov chain Monte Carlo (MCMC) estimation Stan, can time computationally intensive. quicker estimation, can use Stan’s optimizer instead MCMC adding method = \"optim\" function call. However, please functionality lost using optimizer (e.g., calculation relative fit criteria requires use MCMC). model estimated, can add evaluate model fit. can done absolute model fit, relative model fit (information criteria), reliability indices. Model parameters, respondent classifications, results model fit analyses can extracted using measr_extract(). Contributions welcome. ensure smooth process, please review Contributing Guide. Please note measr project released Contributor Code Conduct. contributing project, agree abide terms.","code":"library(measr)  model <- measr_dcm(data = ecpe_data, resp_id = \"resp_id\",                    qmatrix = ecpe_qmatrix, item_id = \"item_id\") model <- add_fit(model, method = \"m2\") model <- add_criterion(model, criterion = \"loo\") model <- add_reliability(model)  measr_extract(model, \"m2\") #> # A tibble: 1 × 3 #>      m2    df     pval #>   <dbl> <int>    <dbl> #> 1  506.   325 4.37e-10"},{"path":"https://measr.info/dev/reference/c.measrprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple measrprior objects into one measrprior — c.measrprior","title":"Combine multiple measrprior objects into one measrprior — c.measrprior","text":"Combine multiple measrprior objects one measrprior","code":""},{"path":"https://measr.info/dev/reference/c.measrprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple measrprior objects into one measrprior — c.measrprior","text":"","code":"# S3 method for measrprior c(x, ..., replace = FALSE)"},{"path":"https://measr.info/dev/reference/c.measrprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple measrprior objects into one measrprior — c.measrprior","text":"x measrprior object. ... Additional measrprior objects combined. replace unique priors kept? TRUE, first prior specified kept.","code":""},{"path":"https://measr.info/dev/reference/c.measrprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple measrprior objects into one measrprior — c.measrprior","text":"measrprior object.","code":""},{"path":"https://measr.info/dev/reference/create_profiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate mastery profiles — create_profiles","title":"Generate mastery profiles — create_profiles","text":"Given number attributes, generate possible patterns attribute mastery.","code":""},{"path":"https://measr.info/dev/reference/create_profiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate mastery profiles — create_profiles","text":"","code":"create_profiles(attributes)"},{"path":"https://measr.info/dev/reference/create_profiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate mastery profiles — create_profiles","text":"attributes Positive integer. number attributes measured.","code":""},{"path":"https://measr.info/dev/reference/create_profiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate mastery profiles — create_profiles","text":"tibble possible attribute mastery profiles. row profile, column indicates whether attribute column mastered (1) mastered (0). Thus, tibble 2^attributes rows, attributes columns.","code":""},{"path":"https://measr.info/dev/reference/create_profiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate mastery profiles — create_profiles","text":"","code":"create_profiles(3L) #> # A tibble: 8 × 3 #>    att1  att2  att3 #>   <int> <int> <int> #> 1     0     0     0 #> 2     1     0     0 #> 3     0     1     0 #> 4     0     0     1 #> 5     1     1     0 #> 6     1     0     1 #> 7     0     1     1 #> 8     1     1     1 create_profiles(5) #> # A tibble: 32 × 5 #>     att1  att2  att3  att4  att5 #>    <int> <int> <int> <int> <int> #>  1     0     0     0     0     0 #>  2     1     0     0     0     0 #>  3     0     1     0     0     0 #>  4     0     0     1     0     0 #>  5     0     0     0     1     0 #>  6     0     0     0     0     1 #>  7     1     1     0     0     0 #>  8     1     0     1     0     0 #>  9     1     0     0     1     0 #> 10     1     0     0     0     1 #> # ℹ 22 more rows"},{"path":"https://measr.info/dev/reference/default_dcm_priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Default priors for diagnostic classification models — default_dcm_priors","title":"Default priors for diagnostic classification models — default_dcm_priors","text":"Default priors diagnostic classification models","code":""},{"path":"https://measr.info/dev/reference/default_dcm_priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default priors for diagnostic classification models — default_dcm_priors","text":"","code":"default_dcm_priors(type = \"lcdm\", attribute_structure = \"unconstrained\")"},{"path":"https://measr.info/dev/reference/default_dcm_priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default priors for diagnostic classification models — default_dcm_priors","text":"type Type DCM estimate. Must one lcdm, dina, dino, crum. attribute_structure Structural model specification. Must one unconstrained, independent. unconstrained makes assumptions relationships attributes, whereas independent assumes proficiency statuses attributes independent .","code":""},{"path":"https://measr.info/dev/reference/default_dcm_priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default priors for diagnostic classification models — default_dcm_priors","text":"measrprior object.","code":""},{"path":"https://measr.info/dev/reference/default_dcm_priors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default priors for diagnostic classification models — default_dcm_priors","text":"","code":"default_dcm_priors(type = \"lcdm\") #> # A tibble: 4 × 3 #>   class       coef  prior_def                   #>   <chr>       <chr> <chr>                       #> 1 intercept   NA    normal(0, 2)                #> 2 maineffect  NA    lognormal(0, 1)             #> 3 interaction NA    normal(0, 2)                #> 4 structural  Vc    dirichlet(rep_vector(1, C))"},{"path":"https://measr.info/dev/reference/ecpe.html","id":null,"dir":"Reference","previous_headings":"","what":"Examination for the Certificate of Proficiency in English (ECPE) — ecpe_data","title":"Examination for the Certificate of Proficiency in English (ECPE) — ecpe_data","text":"data grammar section ECPE, administered annually English Language Institute University Michigan. data contains responses 28 questions 2,922 respondents, ask respondents complete sentence correct word. data set used Templin & Hoffman (2013) Templin & Bradshaw (2014) demonstrating log-linear cognitive diagnosis model (LCDM) hierarchical diagnostic classification model (HDCM), respectively.","code":""},{"path":"https://measr.info/dev/reference/ecpe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examination for the Certificate of Proficiency in English (ECPE) — ecpe_data","text":"","code":"ecpe_data  ecpe_qmatrix"},{"path":"https://measr.info/dev/reference/ecpe.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Examination for the Certificate of Proficiency in English (ECPE) — ecpe_data","text":"ecpe_data tibble containing ECPE response data 2,922 rows 29 variables. resp_id: Respondent identifier E1-E28: Dichotomous item responses 28 ECPE items ecpe_qmatrix tibble identifies skills measured ECPE item. section ECPE contains 28 items measuring 3 skills. ecpe_qmatrix correspondingly made 28 rows 4 variables. item_id: Item identifier, corresponds E1-E28 ecpe_data morphosyntactic, cohesive, lexical: Dichotomous indicator whether skill measured item. value 1 indicates skill measured item value 0 indicates skill measured item.","code":""},{"path":"https://measr.info/dev/reference/ecpe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Examination for the Certificate of Proficiency in English (ECPE) — ecpe_data","text":"skills correspond knowledge : Morphosyntactic rules Cohesive rules Lexical rules details, see Buck & Tatsuoka (1998) Henson & Templin (2007).","code":""},{"path":"https://measr.info/dev/reference/ecpe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Examination for the Certificate of Proficiency in English (ECPE) — ecpe_data","text":"Buck, G., & Tatsuoka, K. K. (1998). Application rule-space procedure language testing: Examining attributes free response listening test. Language Testing, 15(2), 119-157. doi:10.1177/026553229801500201 Henson, R., & Templin, J. (2007, April). Large-scale language assessment using cognitive diagnosis models. Paper presented Annual meeting National Council Measurement Education, Chicago, IL. Templin, J., & Hoffman, L. (2013). Obtaining diagnostic classification model estimates using Mplus. Educational Measurement: Issues Practice, 32(2), 37-50. doi:10.1111/emip.12010 Templin, J., & Bradshaw, L. (2014). Hierarchical diagnostic classification models: family models estimating testing attribute hierarchies. Psychometrika, 79(2), 317-339. doi:10.1007/s11336-013-9362-0","code":""},{"path":"https://measr.info/dev/reference/fit_m2.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","title":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","text":"diagnostic classification models, M2 statistic calculated described Hansen et al. (2016) Liu et al. (2016).","code":""},{"path":"https://measr.info/dev/reference/fit_m2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","text":"","code":"# S3 method for measrdcm fit_m2(model, ..., ci = 0.9, force = FALSE)"},{"path":"https://measr.info/dev/reference/fit_m2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","text":"model estimated diagnostic classification model. ... Unused, extensibility. ci confidence interval RMSEA. force M2 already saved model object add_fit(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/fit_m2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","text":"data frame created dcm2::fit_m2().","code":""},{"path":"https://measr.info/dev/reference/fit_m2.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","text":"fit_m2(measrdcm): M2 diagnostic classification models.","code":""},{"path":"https://measr.info/dev/reference/fit_m2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","text":"Hansen, M., Cai, L., Monroe, S., & Li, Z. (2016). Limited-information goodness--fit testing diagnostic classification item response models. British Journal Mathematical Statistical Psychology, 69(3), 225-252. doi:10.1111/bmsp.12074 Liu, Y., Tian, W., & Xin, T. (2016). application M2 statistic evaluate fit cognitive diagnostic models. Journal Educational Behavioral Statistics, 41(1), 3-26. doi:10.3102/1076998615621293","code":""},{"path":"https://measr.info/dev/reference/fit_m2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the M2 fit statistic for\ndiagnostic classification models — fit_m2.measrdcm","text":"","code":"rstn_mdm_lcdm <- measr_dcm(   data = mdm_data, missing = NA, qmatrix = mdm_qmatrix,   resp_id = \"respondent\", item_id = \"item\", type = \"lcdm\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  fit_m2(rstn_mdm_lcdm) #> # A tibble: 1 × 8 #>       m2    df  pval rmsea ci_lower ci_upper `90% CI`     srmsr #>    <dbl> <int> <dbl> <dbl>    <dbl>    <dbl> <chr>        <dbl> #> 1 0.0219     1 0.882     0        0    0.110 [0, 0.1102] 0.0456"},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior predictive model checks for assessing model fit — fit_ppmc","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"models estimated method = \"mcmc\", use posterior distributions compute expected distributions fit statistics compare values observed data.","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"","code":"fit_ppmc(   model,   ndraws = NULL,   probs = c(0.025, 0.975),   return_draws = 0,   model_fit = c(\"raw_score\"),   item_fit = c(\"conditional_prob\", \"odds_ratio\"),   force = FALSE )"},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"model measrfit object. ndraws number posterior draws base checks . Must less equal total number posterior draws retained estimated model. NULL (default) total number estimated model used. probs percentiles computed [stats::quantile()] function summarizing posterior distributions specified fit statistics. return_draws Proportion posterior draws specified fit statistic returned. affect calculation posterior predictive checks, can useful visualizing fit statistics. example, ndraws = 500, return_draws = 0.2, model_fit = \"raw_score\", raw score chi-square computed 500 times (draw) 100 values (0.2 * 500) returned. 0 (default), summaries posterior returned (individual samples). model_fit posterior predictive model checks compute evaluation model-level fit. NULL, model-level checks computed. See details. item_fit posterior predictive model checks compute evaluation item-level fit. NULL, item-level checks computed. Multiple checks can provided order calculate one check simultaneously (e.g., item_fit = c(\"conditional_prob\", \"odds_ratio\")). See details. force requested PPMCs already added model object using add_fit(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"list two elements, \"model_fit\" \"item_fit\". either model_fit = NULL item_fit = NULL function call, one-element list, null criteria excluded. list element, list one element specified PPMC containing tibble. example item_fit = c(\"conditional_prob\", \"odds_ratio\"), \"item_fit\" element list length two, element tibble containing results PPMC. tibbles follow general structure: obs_{ppmc}: value relevant statistic observed data. ppmc_mean: mean ndraws posterior samples calculated given statistic. Quantile columns: 1 column value probs, providing corresponding quantiles ndraws posterior samples calculated given statistic. samples: list column, element contains vector length (ndraws * return_draws), representing samples posterior distribution calculated statistic. column excluded return_draws = 0. ppp: posterior predictive p-value. proportion posterior samples calculated statistic greater observed value. Values close 0 1 indicate incompatibility fitted model observed data.","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"Posterior predictive model checks (PPMCs) use posterior distribution estimated model compute different statistics. creates expected distribution given statistic, estimated parameters correct. compute statistic observed data compare observed value expected distribution. Observed values fall outside expected distributions indicate incompatibility estimated model observed data. currently support PPMCs model item level. model level, calculate expected raw score distribution (model_fit = \"raw_score\"), described Thompson (2019) Park et al. (2015). item level, can calculate conditional probability respondent class provides correct response (item_fit = \"conditional_prob\") described Thompson (2019) Sinharay & Almond (2007). can also calculate odds ratio pair items (item_fit = \"odds_ratio\") described Park et al. (2015) Sinharay et al. (2006).","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"Park, J. Y., Johnson, M. S., Lee, Y-S. (2015). Posterior predictive model checks cognitive diagnostic models. International Journal Quantitative Research Education, 2(3-4), 244-264. doi:10.1504/IJQRE.2015.071738 Sinharay, S., & Almond, R. G. (2007). Assessing fit cognitive diagnostic models. Educational Psychological Measurement, 67(2), 239-257. doi:10.1177/0013164406292025 Sinharay, S., Johnson, M. S., & Stern, H. S. (2006). Posterior predictive assessment item response theory models. Applied Psychological Measurement, 30(4), 298-321. doi:10.1177/0146621605285517 Thompson, W. J. (2019). Bayesian psychometrics diagnostic assessments: proof concept (Research Report . 19-01). University Kansas; Accessible Teaching, Learning, Assessment Systems. doi:10.35542/osf.io/jzqs8","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"","code":"mdm_dina <- measr_dcm(   data = mdm_data, missing = NA, qmatrix = mdm_qmatrix,   resp_id = \"respondent\", item_id = \"item\", type = \"dina\",   method = \"mcmc\", seed = 63277, backend = \"rstan\",   iter = 700, warmup = 500, chains = 2, refresh = 0 ) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess  fit_ppmc(mdm_dina, model_fit = \"raw_score\", item_fit = NULL) #> $model_fit #> $model_fit$raw_score #> # A tibble: 1 × 5 #>   obs_chisq ppmc_mean `2.5%` `97.5%`   ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <dbl> #> 1      5.28      5.91  0.693    16.0  0.49 #>  #>"},{"path":"https://measr.info/dev/reference/get_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a list of possible parameters — get_parameters","title":"Get a list of possible parameters — get_parameters","text":"specifying prior distributions, often useful see parameters included given model. Using Q-matrix type diagnostic model estimated, can create list included parameters prior can specified.","code":""},{"path":"https://measr.info/dev/reference/get_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a list of possible parameters — get_parameters","text":"","code":"get_parameters(   qmatrix,   item_id = NULL,   rename_att = FALSE,   rename_item = FALSE,   type = c(\"lcdm\", \"dina\", \"dino\", \"crum\"),   attribute_structure = c(\"unconstrained\", \"independent\") )"},{"path":"https://measr.info/dev/reference/get_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a list of possible parameters — get_parameters","text":"qmatrix Q-matrix. data frame 1 row per item 1 column per attribute. cells either 0 (item measure attribute) 1 (item measure attribute). item_id Optional. Variable name column qmatrix contains item identifiers. NULL (default) indicates identifiers present Q-matrix. rename_att attribute names qmatrix replaced generic, consistent names (e.g., \"att1\", \"att2\", \"att3\"). rename_item item names qmatrix replaced generic, consistent names (e.g., 1, 2, 3). type Type DCM estimate. Must one lcdm, dina, dino, crum. attribute_structure Structural model specification. Must one unconstrained, independent. unconstrained makes assumptions relationships attributes, whereas independent assumes proficiency statuses attributes independent .","code":""},{"path":"https://measr.info/dev/reference/get_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a list of possible parameters — get_parameters","text":"tibble one row per parameter.","code":""},{"path":"https://measr.info/dev/reference/get_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a list of possible parameters — get_parameters","text":"","code":"get_parameters(ecpe_qmatrix, item_id = \"item_id\", type = \"lcdm\") #> # A tibble: 75 × 4 #>    item_id class       attributes                coef   #>    <fct>   <chr>       <chr>                     <glue> #>  1 E1      intercept   NA                        l1_0   #>  2 E1      maineffect  morphosyntactic           l1_11  #>  3 E1      maineffect  cohesive                  l1_12  #>  4 E1      interaction morphosyntactic__cohesive l1_212 #>  5 E2      intercept   NA                        l2_0   #>  6 E2      maineffect  cohesive                  l2_12  #>  7 E3      intercept   NA                        l3_0   #>  8 E3      maineffect  morphosyntactic           l3_11  #>  9 E3      maineffect  lexical                   l3_13  #> 10 E3      interaction morphosyntactic__lexical  l3_213 #> # ℹ 65 more rows  get_parameters(ecpe_qmatrix, item_id = \"item_id\", type = \"lcdm\",                rename_att = TRUE) #> # A tibble: 75 × 4 #>    item_id class       attributes coef   #>    <fct>   <chr>       <chr>      <glue> #>  1 E1      intercept   NA         l1_0   #>  2 E1      maineffect  att1       l1_11  #>  3 E1      maineffect  att2       l1_12  #>  4 E1      interaction att1__att2 l1_212 #>  5 E2      intercept   NA         l2_0   #>  6 E2      maineffect  att2       l2_12  #>  7 E3      intercept   NA         l3_0   #>  8 E3      maineffect  att1       l3_11  #>  9 E3      maineffect  att3       l3_13  #> 10 E3      interaction att1__att3 l3_213 #> # ℹ 65 more rows"},{"path":"https://measr.info/dev/reference/is.measrprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if argument is a measrprior object — is.measrprior","title":"Checks if argument is a measrprior object — is.measrprior","text":"Checks argument measrprior object","code":""},{"path":"https://measr.info/dev/reference/is.measrprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if argument is a measrprior object — is.measrprior","text":"","code":"is.measrprior(x)"},{"path":"https://measr.info/dev/reference/is.measrprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if argument is a measrprior object — is.measrprior","text":"x object","code":""},{"path":"https://measr.info/dev/reference/is.measrprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks if argument is a measrprior object — is.measrprior","text":"logical indicating x measrprior object.","code":""},{"path":"https://measr.info/dev/reference/is.measrprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Checks if argument is a measrprior object — is.measrprior","text":"","code":"prior1 <- prior(lognormal(0, 1), class = maineffect) is.measrprior(prior1) #> [1] TRUE  prior2 <- 3 is.measrprior(prior2) #> [1] FALSE"},{"path":"https://measr.info/dev/reference/loo.measrfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficient approximate leave-one-out cross-validation (LOO) — loo.measrfit","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo.measrfit","text":"loo::loo() method customized measrfit objects. simple wrapper around loo::loo.array(). See loo package vignettes details.","code":""},{"path":"https://measr.info/dev/reference/loo.measrfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo.measrfit","text":"","code":"# S3 method for measrfit loo(x, ..., r_eff = NA, force = FALSE)"},{"path":"https://measr.info/dev/reference/loo.measrfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo.measrfit","text":"x measrfit object. ... Additional arguments passed loo::loo.array(). r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalizing importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates -optimistic. posterior draws independent r_eff=1 can omitted. warning message thrown r_eff specified can disabled setting r_eff NA. See relative_eff() helper functions computing r_eff. force LOO criterion already added model object add_criterion(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/loo.measrfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo.measrfit","text":"object returned loo::loo.array().","code":""},{"path":"https://measr.info/dev/reference/loo_compare.measrfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative model fit comparisons — loo_compare.measrfit","title":"Relative model fit comparisons — loo_compare.measrfit","text":"loo::loo_compare() method customized measrfit objects. See loo package vignettes details.","code":""},{"path":"https://measr.info/dev/reference/loo_compare.measrfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative model fit comparisons — loo_compare.measrfit","text":"","code":"# S3 method for measrfit loo_compare(x, ..., criterion = c(\"loo\", \"waic\"), model_names = NULL)"},{"path":"https://measr.info/dev/reference/loo_compare.measrfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative model fit comparisons — loo_compare.measrfit","text":"x measrfit object. ... Additional objects class measrfit. criterion name criterion extracted measrfit object comparison. model_names Names given provided model comparison output. NULL (default), names parsed names objects passed comparison.","code":""},{"path":"https://measr.info/dev/reference/loo_compare.measrfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative model fit comparisons — loo_compare.measrfit","text":"object returned loo::loo_compare().","code":""},{"path":"https://measr.info/dev/reference/mdm.html","id":null,"dir":"Reference","previous_headings":"","what":"MacReady & Dayton (1977) Multiplication Data — mdm_data","title":"MacReady & Dayton (1977) Multiplication Data — mdm_data","text":"small data set multiplication item responses. data contains responses 4 items 142 respondents, ask respondents complete integer multiplication problem.","code":""},{"path":"https://measr.info/dev/reference/mdm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MacReady & Dayton (1977) Multiplication Data — mdm_data","text":"","code":"mdm_data  mdm_qmatrix"},{"path":"https://measr.info/dev/reference/mdm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"MacReady & Dayton (1977) Multiplication Data — mdm_data","text":"mdm_data tibble containing responses multiplication items, described MacReady & Dayton (1977). 142 rows 5 variables. respondent: Respondent identifier mdm1-mdm4: Dichotomous item responses 4 multiplication items mdm_qmatrix tibble identifies skills measured MDM item. MDM data contains 4 items, measure skill multiplication. mdm_qmatrix correspondingly made 4 rows 2 variables. item: Item identifier, corresponds mdm1-mdm4 mdm_data multiplication: Dichotomous indicator whether multiplication skill measured item. value 1 indicates skill measured item value 0 indicates skill measured item.","code":""},{"path":"https://measr.info/dev/reference/mdm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MacReady & Dayton (1977) Multiplication Data — mdm_data","text":"MacReady, G. B., & Dayton, C. M. (1977). use probabilistic models assessment mastery. Journal Educational Statistics, 2(2), 99-120. doi:10.2307/1164802","code":""},{"path":"https://measr.info/dev/reference/measr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"measr: Bayesian Psychometric Measurement Using 'Stan' — measr-package","title":"measr: Bayesian Psychometric Measurement Using 'Stan' — measr-package","text":"Estimate diagnostic classification models (also called cognitive diagnostic models) 'Stan'. Diagnostic classification models confirmatory latent class models, described Rupp et al. (2010, ISBN: 978-1-60623-527-0). Automatically generate 'Stan' code general loglinear cognitive diagnostic diagnostic model proposed Henson et al. (2009) doi:10.1007/s11336-008-9089-5  subtypes introduce additional model constraints. Using generated 'Stan' code, estimate model evaluate model's performance using model fit indices, information criteria, reliability metrics.","code":""},{"path":[]},{"path":"https://measr.info/dev/reference/measr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"measr: Bayesian Psychometric Measurement Using 'Stan' — measr-package","text":"Maintainer: W. Jake Thompson wjakethompson@gmail.com (ORCID) contributors: Nathan Jones jonesnateb@gmail.com (ORCID) [contributor] Matthew Johnson (Provided code adapted reliability.measrdcm()) [copyright holder] Paul-Christian Bürkner (Author eval_silent()) [copyright holder] University Kansas [copyright holder] Institute Education Sciences [funder]","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Bayesian diagnostic classification models — measr_dcm","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"Estimate diagnostic classification models (DCMs; also known cognitive diagnostic models) using 'Stan'. Models can estimated using Stan's optimizer, full Markov chain Monte Carlo (MCMC).","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"","code":"measr_dcm(   data,   missing = NA,   qmatrix,   resp_id = NULL,   item_id = NULL,   type = c(\"lcdm\", \"dina\", \"dino\", \"crum\"),   max_interaction = Inf,   attribute_structure = c(\"unconstrained\", \"independent\"),   method = c(\"mcmc\", \"optim\"),   prior = NULL,   backend = getOption(\"measr.backend\", \"rstan\"),   file = NULL,   file_refit = getOption(\"measr.file_refit\", \"never\"),   ... )"},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"data Response data. data frame 1 row per respondent 1 column per item. missing R expression specifying missing data data coded (e.g., NA, \".\", -99, etc.). default NA. qmatrix Q-matrix. data frame 1 row per item 1 column per attribute. cells either 0 (item measure attribute) 1 (item measure attribute). resp_id Optional. Variable name column data contains respondent identifiers. NULL (default) indicates identifiers present data, row numbers used identifiers. item_id Optional. Variable name column qmatrix contains item identifiers. NULL (default) indicates identifiers present Q-matrix. case, column names data (excluding column specified resp_id) used item identifiers. NULL also assumes order rows Q-matrix order columns data (.e., item row 1 qmatrix item column 1 data, excluding resp_id). type Type DCM estimate. Must one lcdm, dina, dino, crum. max_interaction type = \"lcdm\", highest level interaction estimate. default estimate possible interactions. example, item measures 4 attributes 4 main effects, 6 two-way interactions, 4 three-way interactions, 1 four-way interaction. Setting max_interaction = 2 result estimating main effects two-way interactions, excluding three- four- way interactions. attribute_structure Structural model specification. Must one unconstrained, independent. unconstrained makes assumptions relationships attributes, whereas independent assumes proficiency statuses attributes independent . method Estimation method. Options \"mcmc\", uses Stan's sampling method, \"optim\", uses Stan's optimizer. prior measrprior object. NULL, default priors used, specified default_dcm_priors(). backend Character string naming package use backend fitting Stan model. Options \"rstan\" (default) \"cmdstanr\". Can set globally current R session via \"measr.backend\" option (see options()). Details rstan cmdstanr packages available https://mc-stan.org/rstan/ https://mc-stan.org/cmdstanr/, respectively. file Either NULL (default) character string. character string, fitted model object saved .rds object using saveRDS() using supplied character string. .rds extension automatically added. specified file already exists, measr load previously saved model. Unless file_refit specified, model refit. file_refit Controls saved model refit. Options \"never\", \"always\", \"on_change\". Can set globally current R session via \"measr.file_refit\" option (see options()). \"never\" (default), fitted model always loaded file exists, model fitting skipped. \"always\", model always refitted, regardless whether file exists. \"on_change\", model refit data, prior, method specified different saved file. ... Additional arguments passed Stan. backend = \"rstan\", arguments passed rstan::sampling() rstan::optimizing(). backend = \"cmdstanr\", arguments passed sample optimize methods CmdStanModel class.","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"measrfit object.","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"","code":"rstn_mdm_lcdm <- measr_dcm(   data = mdm_data, missing = NA, qmatrix = mdm_qmatrix,   resp_id = \"respondent\", item_id = \"item\", type = \"lcdm\",   method = \"optim\", seed = 63277, backend = \"rstan\" )"},{"path":"https://measr.info/dev/reference/measr_examples.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine if code is executed interactively or in pkgdown — measr_examples","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"Used determining examples run CRAN, can run pkgdown website.","code":""},{"path":"https://measr.info/dev/reference/measr_examples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"","code":"measr_examples()"},{"path":"https://measr.info/dev/reference/measr_examples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"logical value indicating whether examples run.","code":""},{"path":"https://measr.info/dev/reference/measr_examples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"","code":"measr_examples() #> [1] TRUE"},{"path":"https://measr.info/dev/reference/measr_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract components of a measrfit object. — measr_extract","title":"Extract components of a measrfit object. — measr_extract","text":"Extract components measrfit object. Extract components estimated diagnostic classification model","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract components of a measrfit object. — measr_extract","text":"","code":"measr_extract(model, ...)  # S3 method for measrdcm measr_extract(model, what, ...)"},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract components of a measrfit object. — measr_extract","text":"model estimated extract information . ... Additional arguments passed extract method. ppmc_interval: = \"odds_ratio_flags\" = \"conditional_prob_flags\", compatibility interval used determining model fit flags return. example, ppmc_interval 0.95 (default) return PPMCs posterior predictive p-value (ppp) less 0.025 greater 0.975. agreement: = \"classification_reliability\", additional measures agreement include. default, classification accuracy consistency metrics defined Johnson & Sinharay (2018) returned. Additional metrics can specified agreement Goodman & Kruskal's lambda (lambda), Cohen's kappa (kappa), Youden's statistic (youden), tetrachoric correlation (tetra), true positive rate (tp), true negative rate (tn). = \"probability_reliability\", additional measures agreement include. default, informational reliability index defined Johnson & Sinharay (2020) returned. Additional metrics can specified agreement point biserial reliability index (bs), parallel forms reliability index (pf), tetrachoric reliability index (tb), originally defined Templin & Bradshaw (2013). Character string. information extracted. See details available options.","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract components of a measrfit object. — measr_extract","text":"extracted information. specific structure vary depending extracted, usually returned object tibble requested information.","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract components of a measrfit object. — measr_extract","text":"diagnostic classification models, can extract following information: item_param: estimated item parameters. shows name parameter, class parameter, estimated value. strc_param: estimated structural parameters. base rate membership class. shows class pattern estimated proportion respondents class. prior: priors used estimating model. classes: possible classes profile patterns. show class label (.e., pattern proficiency) attributes included class. class_prob: probability respondent belongs class (.e., given pattern proficiency). attribute_prob: proficiency probability respondent attribute. m2: M2 fit statistic. See fit_m2() details. Model fit information must first added model using add_fit(). rmsea: root mean square error approximation (RMSEA) fit statistic associated confidence interval. See fit_m2() details. Model fit information must first added model using add_fit(). srmsr: standardized root mean square residual (SRMSR) fit statistic. See fit_m2() details. Model fit information must first added model using add_fit(). ppmc_raw_score: observed posterior predicted chi-square statistic raw score distribution. See fit_ppmc() details. Model fit information must first added model using add_fit(). ppmc_conditional_prob: observed posterior predicted conditional probabilities class providing correct response item. See fit_ppmc() details. Model fit information must first added model using add_fit(). ppmc_conditional_prob_flags: subset PPMC conditional probabilities ppp outside specified ppmc_interval. ppmc_odds_ratio: observed posterior predicted odds ratios item pair. See fit_ppmc() details. Model fit information must first added model using add_fit(). ppmc_odds_ratio_flags: subset PPMC odds ratios ppp outside specified ppmc_interval. loo: leave-one-cross validation results. See loo::loo() details. information criterion must first added model using add_criterion(). waic: widely applicable information criterion results. See loo::waic() details. information criterion must first added model using add_criterion(). pattern_reliability: accuracy consistency overall attribute profile classification, described Cui et al. (2012). Reliability information must first added model using add_reliability(). classification_reliability: classification accuracy consistency attribute, using metrics described Johnson & Sinharay (2018). Reliability information must first added model using add_reliability(). probability_reliability: Reliability estimates probability proficiency attribute, described Johnson & Sinharay (2020). Reliability information must first added model using add_reliability().","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Extract components of a measrfit object. — measr_extract","text":"measr_extract(measrdcm): Extract components estimated diagnostic classification model.","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract components of a measrfit object. — measr_extract","text":"Cui, Y., Gierl, M. J., & Chang, H.-H. (2012). Estimating classification consistency accuracy cognitive diagnostic assessment. Journal Educational Measurement, 49(1), 19-38. doi:10.1111/j.1745-3984.2011.00158.x Johnson, M. S., & Sinharay, S. (2018). Measures agreement assess attribute-level classification accuracy consistency cognitive diagnostic assessments. Journal Educational Measurement, 55(4), 635-664. doi:10.1111/jedm.12196 Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Behavioral Statistics, 45(1), 5-31. doi:10.3102/1076998619864550 Templin, J., & Bradshaw, L. (2013). Measuring reliability diagnostic classification model examinee estimates. Journal Classification, 30(2), 251-275. doi:10.1007/s00357-013-9129-4","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract components of a measrfit object. — measr_extract","text":"","code":"rstn_mdm_lcdm <- measr_dcm(   data = mdm_data, missing = NA, qmatrix = mdm_qmatrix,   resp_id = \"respondent\", item_id = \"item\", type = \"lcdm\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  measr_extract(rstn_mdm_lcdm, \"strc_param\") #> # A tibble: 2 × 2 #>   class   estimate #>   <chr> <rvar[1d]> #> 1 [0]    0.49 ± NA #> 2 [1]    0.51 ± NA"},{"path":"https://measr.info/dev/reference/measrfit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class measrfit of models fitted with the measr package — measrfit-class","title":"Class measrfit of models fitted with the measr package — measrfit-class","text":"Models fitted measr package represented measrfit object, contains posterior draws, Stan code, priors, relevant information.","code":""},{"path":"https://measr.info/dev/reference/measrfit-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class measrfit of models fitted with the measr package — measrfit-class","text":"data data Q-matrix used estimate model. type type DCM estimated. prior measrprior object containing information priors used model. stancode model code Stan language. method method used fit model. algorithm name algorithm used fit model. backend name backend used fit model. model fitted Stan model. object class rstan::stanfit backend = \"rstan\" CmdStanMCMC backend = \"cmdstanr\" specified fitting model. respondent_estimates empty list adding estimated person parameters fitting model. fit empty list adding model fit information fitting model. criteria empty list adding information criteria fitting model. reliability empty list adding reliability information fitting model. file Optional name file model objects saved loaded . version versions measr, Stan, rstan /cmdstanr used fit model.","code":""},{"path":[]},{"path":"https://measr.info/dev/reference/measrprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior definitions for measr models — measrprior","title":"Prior definitions for measr models — measrprior","text":"Create prior definitions classes parameters, specific parameters.","code":""},{"path":"https://measr.info/dev/reference/measrprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior definitions for measr models — measrprior","text":"","code":"measrprior(   prior,   class = c(\"structural\", \"intercept\", \"maineffect\", \"interaction\", \"slip\", \"guess\"),   coef = NA,   lb = NA,   ub = NA )  prior(prior, ...)  prior_(prior, ...)  prior_string(prior, ...)"},{"path":"https://measr.info/dev/reference/measrprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior definitions for measr models — measrprior","text":"prior character string defining distribution Stan language. list distributions supported Stan can found Stan Language Functions Reference https://mc-stan.org/users/documentation/. class parameter class. Defaults \"intercept\". Must one \"intercept\", \"maineffect\", \"interaction\" LCDM, one \"slip\" \"guess\" DINA DINO models. coef Name specific parameter within defined class. defined, prior applied parameters within class. lb Lower bound parameter restriction. Defaults restriction. ub Upper bound parameter restriction. Defaults restriction. ... Additional arguments passed measrprior().","code":""},{"path":"https://measr.info/dev/reference/measrprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prior definitions for measr models — measrprior","text":"tibble class measrprior.","code":""},{"path":"https://measr.info/dev/reference/measrprior.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Prior definitions for measr models — measrprior","text":"prior(): Alias measrprior() allows arguments specified expressions without quotation marks. prior_(): Alias measrprior() allows arguments specified one-sided formulas wrapped base::quote(). prior_string(): Alias measrprior() allows arguments specified character strings.","code":""},{"path":"https://measr.info/dev/reference/measrprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prior definitions for measr models — measrprior","text":"","code":"# Use alias functions to define priors without quotes, as formulas, # or as character strings. (prior1 <- prior(lognormal(0, 1), class = maineffect)) #> # A tibble: 1 × 3 #>   class      coef  prior_def       #>   <chr>      <chr> <chr>           #> 1 maineffect NA    lognormal(0, 1)  (prior2 <- prior_(~lognormal(0, 1), class = ~maineffect)) #> # A tibble: 1 × 3 #>   class      coef  prior_def       #>   <chr>      <chr> <chr>           #> 1 maineffect NA    lognormal(0, 1)  (prior3 <- prior_string(\"lognormal(0, 1)\", class = \"maineffect\")) #> # A tibble: 1 × 3 #>   class      coef  prior_def       #>   <chr>      <chr> <chr>           #> 1 maineffect NA    lognormal(0, 1)  identical(prior1, prior2) #> [1] TRUE identical(prior1, prior3) #> [1] TRUE identical(prior2, prior3) #> [1] TRUE  # Define a prior for an entire class of parameters prior(beta(5, 25), class = \"slip\") #> # A tibble: 1 × 3 #>   class coef  prior_def   #>   <chr> <chr> <chr>       #> 1 slip  NA    beta(5, 25)  # Or for a specific item (e.g., just the slipping parameter for item 7) prior(beta(5, 25), class = \"slip\", coef = \"slip[7]\") #> # A tibble: 1 × 3 #>   class coef    prior_def   #>   <chr> <chr>   <chr>       #> 1 slip  slip[7] beta(5, 25)"},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":null,"dir":"Reference","previous_headings":"","what":"Add model evaluation metrics model objects — model_evaluation","title":"Add model evaluation metrics model objects — model_evaluation","text":"Add model evaluation metrics fitted model objects. functions wrappers around functions compute metrics. benefit using wrappers model evaluation metrics saved part model object time-intensive calculations need repeated. See Details specifics.","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add model evaluation metrics model objects — model_evaluation","text":"","code":"add_criterion(   x,   criterion = c(\"loo\", \"waic\"),   overwrite = FALSE,   save = TRUE,   ...,   r_eff = NA )  add_reliability(x, overwrite = FALSE, save = TRUE)  add_fit(   x,   method = c(\"m2\", \"ppmc\"),   overwrite = FALSE,   save = TRUE,   ...,   ci = 0.9 )  add_respondent_estimates(   x,   probs = c(0.025, 0.975),   overwrite = FALSE,   save = TRUE )"},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add model evaluation metrics model objects — model_evaluation","text":"x measrfit object. criterion vector criteria calculate add model object. overwrite Logical. Indicates whether specified elements already added estimated model overwritten. Default FALSE. save Logical. relevant file specified measrfit object passed x. TRUE (default), model re-saved specified file new criteria added R object. FALSE, new criteria added R object, saved file updated. ... Additional arguments passed relevant methods. See Details. r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalizing importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates -optimistic. posterior draws independent r_eff=1 can omitted. warning message thrown r_eff specified can disabled setting r_eff NA. See relative_eff() helper functions computing r_eff. method vector model fit methods evaluate add model object. ci confidence interval RMSEA, computed M2 probs percentiles computed [stats::quantile()] function summarize posterior distributions person parameter. relevant method = \"mcmc\" used estimate model.","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add model evaluation metrics model objects — model_evaluation","text":"modified measrfit object corresponding slot populated specified information.","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add model evaluation metrics model objects — model_evaluation","text":"add_respondent_estimates(), estimated person parameters added $respondent_estimates element fitted model. add_fit(), model item fit information added $fit element fitted model. function wraps fit_m2() calculate M2 statistic (Hansen et al., 2016; Liu et al., 2016) /fit_ppmc() calculate posterior predictive model checks (Park et al., 2015; Sinharay & Almond, 2007; Sinharay et al., 2006; Thompson, 2019), depending methods specified. Additional arguments supplied ... passed fit_ppmc(). add_criterion(), relative fit criteria added $criteria element fitted model. function wraps loo() /waic(), depending criteria specified, calculate leave-one-(LOO; Vehtari et al., 2017) /widely applicable information criteria (WAIC; Watanabe, 2010) fitted model objects. Additional arguments supplied ... passed loo::loo.array() loo::waic.array(). add_reliability(), reliability information added $reliability element fitted model. Pattern level reliability described Cui et al. (2012). Classification reliability posterior probability reliability described Johnson & Sinharay (2018, 2020), respectively. function wraps reliability().","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add model evaluation metrics model objects — model_evaluation","text":"Cui, Y., Gierl, M. J., & Chang, H.-H. (2012). Estimating classification consistency accuracy cognitive diagnostic assessment. Journal Educational Measurement, 49(1), 19-38. doi:10.1111/j.1745-3984.2011.00158.x Hansen, M., Cai, L., Monroe, S., & Li, Z. (2016). Limited-information goodness--fit testing diagnostic classification item response models. British Journal Mathematical Statistical Psychology, 69(3), 225-252. doi:10.1111/bmsp.12074 Johnson, M. S., & Sinharay, S. (2018). Measures agreement assess attribute-level classification accuracy consistency cognitive diagnostic assessments. Journal Educational Measurement, 55(4), 635-664. doi:10.1111/jedm.12196 Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Behavioral Statistics, 45(1), 5-31. doi:10.3102/1076998619864550 Liu, Y., Tian, W., & Xin, T. (2016). application M2 statistic evaluate fit cognitive diagnostic models. Journal Educational Behavioral Statistics, 41(1), 3-26. doi:10.3102/1076998615621293 Park, J. Y., Johnson, M. S., Lee, Y-S. (2015). Posterior predictive model checks cognitive diagnostic models. International Journal Quantitative Research Education, 2(3-4), 244-264. doi:10.1504/IJQRE.2015.071738 Sinharay, S., & Almond, R. G. (2007). Assessing fit cognitive diagnostic models. Educational Psychological Measurement, 67(2), 239-257. doi:10.1177/0013164406292025 Sinharay, S., Johnson, M. S., & Stern, H. S. (2006). Posterior predictive assessment item response theory models. Applied Psychological Measurement, 30(4), 298-321. doi:10.1177/0146621605285517 Thompson, W. J. (2019). Bayesian psychometrics diagnostic assessments: proof concept (Research Report . 19-01). University Kansas; Accessible Teaching, Learning, Assessment Systems. doi:10.35542/osf.io/jzqs8 Vehtari, ., Gelman, ., & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing, 27(5), 1413-1432. doi:10.1007/s11222-016-9696-4 Watanabe, S. (2010). Asymptotic equivalence Bayes cross validation widely applicable information criterion singular learning theory. Journal Machine Learning Research, 11(116), 3571-3594. https://jmlr.org/papers/v11/watanabe10a.html","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add model evaluation metrics model objects — model_evaluation","text":"","code":"cmds_mdm_dina <- measr_dcm(   data = mdm_data, missing = NA, qmatrix = mdm_qmatrix,   resp_id = \"respondent\", item_id = \"item\", type = \"dina\",   method = \"optim\", seed = 63277, backend = \"rstan\",   prior = c(prior(beta(5, 17), class = \"slip\"),             prior(beta(5, 17), class = \"guess\")) )  cmds_mdm_dina <- add_reliability(cmds_mdm_dina) cmds_mdm_dina <- add_fit(cmds_mdm_dina, method = \"m2\") cmds_mdm_dina <- add_respondent_estimates(cmds_mdm_dina)"},{"path":"https://measr.info/dev/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://measr.info/dev/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://measr.info/dev/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://measr.info/dev/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://measr.info/dev/reference/predict.measrdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior draws of respondent proficiency — predict.measrdcm","title":"Posterior draws of respondent proficiency — predict.measrdcm","text":"Calculate posterior draws respondent proficiency. Optionally retain posterior draws return summaries distribution respondent.","code":""},{"path":"https://measr.info/dev/reference/predict.measrdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior draws of respondent proficiency — predict.measrdcm","text":"","code":"# S3 method for measrdcm predict(   object,   newdata = NULL,   resp_id = NULL,   missing = NA,   summary = TRUE,   probs = c(0.025, 0.975),   force = FALSE,   ... )"},{"path":"https://measr.info/dev/reference/predict.measrdcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior draws of respondent proficiency — predict.measrdcm","text":"object object class measrdcm. Generated measr_dcm(). newdata Optional new data. provided, data used estimate model scored. provided, newdata data frame 1 row per respondent 1 column per item. items appear newdata appear data used estimate object. resp_id Optional. Variable name column newdata contains respondent identifiers. NULL (default) indicates identifiers present data, row numbers used identifiers. newdata specified data used estimate model scored, resp_id taken original data. missing R expression specifying missing data data coded (e.g., NA, \".\", -99, etc.). default NA. summary summary statistics returned instead raw posterior draws? relevant model estimated method = \"mcmc\". Default FALSE. probs percentiles computed [stats::quantile()] function. relevant model estimated method = \"mcmc\". used summary TRUE. force respondent estimates already added model object add_respondent_estimates(), recalculated. Default FALSE. ... Unused.","code":""},{"path":"https://measr.info/dev/reference/predict.measrdcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior draws of respondent proficiency — predict.measrdcm","text":"list two elements: class_probabilities attribute_probabilities. summary FALSE, element tibble number rows equal number draws object columns: .chain, .iteration, .draw, respondent identifier, one column probabilities possible classes. summary TRUE, element tibble one row per respondent class attribute, columns respondent identifier, class attribute, mean, one column every value specified probs.","code":""},{"path":"https://measr.info/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. dcm2 fit_m2 loo loo, loo_compare, waic posterior as_draws, E, Pr, rvar_mad, rvar_max, rvar_mean, rvar_median, rvar_min, rvar_prod, rvar_sd, rvar_sum, rvar_var","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the reliability of psychometric models — reliability","title":"Estimate the reliability of psychometric models — reliability","text":"diagnostic classification models, reliability can estimated pattern attribute level. Pattern-level reliability represents classification consistency accuracy placing students overall mastery profile. Rather overall profile, attributes can also scored individually. case, classification consistency accuracy evaluated individual attribute, rather overall profile. referred maximum posteriori (MAP) reliability. Finally, may desirable report results probability proficiency mastery attribute instead proficient/proficient classification. case, reliability posterior probability reported. expected posteriori (EAP) reliability.","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the reliability of psychometric models — reliability","text":"","code":"reliability(model, ...)  # S3 method for measrdcm reliability(model, ..., force = FALSE)"},{"path":"https://measr.info/dev/reference/reliability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the reliability of psychometric models — reliability","text":"model estimated model evaluated. ... Unused. future extensions. force reliability information already added model object add_reliability(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the reliability of psychometric models — reliability","text":"class measrdcm, list 3 elements: pattern_reliability: pattern-level accuracy (p_a) consistency (p_c) described Cui et al. (2012). map_reliability: list 2 elements: accuracy consistency, include attribute-level classification reliability statistics described Johnson & Sinharay (2018). eap_reliability: attribute-level posterior probability reliability statistics described Johnson & Sinharay (2020).","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate the reliability of psychometric models — reliability","text":"pattern-level reliability (pattern_reliability) statistics described Cui et al. (2012). Attribute-level classification reliability statistics (map_reliability) described Johnson & Sinharay (2018). Reliability statistics posterior mean skill indicators (.e., mastery proficiency probabilities; eap_reliability) described Johnson & Sinharay (2019).","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Estimate the reliability of psychometric models — reliability","text":"reliability(measrdcm): Reliability measures diagnostic classification models.","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate the reliability of psychometric models — reliability","text":"Cui, Y., Gierl, M. J., & Chang, H.-H. (2012). Estimating classification consistency accuracy cognitive diagnostic assessment. Journal Educational Measurement, 49(1), 19-38. doi:10.1111/j.1745-3984.2011.00158.x Johnson, M. S., & Sinharay, S. (2018). Measures agreement assess attribute-level classification accuracy consistency cognitive diagnostic assessments. Journal Educational Measurement, 55(4), 635-664. doi:10.1111/jedm.12196 Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Behavioral Statistics, 45(1), 5-31. doi:10.3102/1076998619864550","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the reliability of psychometric models — reliability","text":"","code":"rstn_mdm_lcdm <- measr_dcm(   data = mdm_data, missing = NA, qmatrix = mdm_qmatrix,   resp_id = \"respondent\", item_id = \"item\", type = \"lcdm\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  reliability(rstn_mdm_lcdm) #> $pattern_reliability #>       p_a       p_c  #> 0.9122250 0.8401031  #>  #> $map_reliability #> $map_reliability$accuracy #> # A tibble: 1 × 8 #>   attribute        acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>          <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 multiplication 0.912    0.820   0.823    0.824   0.962 0.923 0.901 #>  #> $map_reliability$consistency #> # A tibble: 1 × 10 #>   attribute      consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>            <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 multiplication   0.840    0.666   0.821    0.680   0.876 0.847 0.833  0.870 #> # ℹ 1 more variable: pc_prime <dbl> #>  #>  #> $eap_reliability #> # A tibble: 1 × 5 #>   attribute      rho_pf rho_bs rho_i rho_tb #>   <chr>           <dbl>  <dbl> <dbl>  <dbl> #> 1 multiplication  0.740  0.740 0.613  0.918 #>"},{"path":"https://measr.info/dev/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way.   enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions).   simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[.   Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround.   Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually :   Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"},{"path":"https://measr.info/dev/reference/tidyeval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy eval helpers — tidyeval","text":"See documentation specific functions rlang.","code":""},{"path":"https://measr.info/dev/reference/waic.measrfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Widely applicable information criterion (WAIC) — waic.measrfit","title":"Widely applicable information criterion (WAIC) — waic.measrfit","text":"loo::waic() method customized measrfit objects. simple wrapper around loo::waic.array(). See loo package vignettes details.","code":""},{"path":"https://measr.info/dev/reference/waic.measrfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Widely applicable information criterion (WAIC) — waic.measrfit","text":"","code":"# S3 method for measrfit waic(x, ..., force = FALSE)"},{"path":"https://measr.info/dev/reference/waic.measrfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Widely applicable information criterion (WAIC) — waic.measrfit","text":"x measrfit object. ... Additional arguments passed loo::waic.array(). force WAIC criterion already added model object add_criterion(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/waic.measrfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Widely applicable information criterion (WAIC) — waic.measrfit","text":"object returned loo::waic.array().","code":""},{"path":[]},{"path":"https://measr.info/dev/news/index.html","id":"new-documentation-development-version","dir":"Changelog","previous_headings":"","what":"New documentation","title":"measr (development version)","text":"new article model evaluation added project website (https://measr.info). model estimation article updated use (simulated) data set model evaluation article. detailed installation instructions added getting started vignette (#23). case study demonstrating full DCM-based analysis using data ECPE (?ecpe_data) added project website.","code":""},{"path":"https://measr.info/dev/news/index.html","id":"minor-improvements-and-fixes-development-version","dir":"Changelog","previous_headings":"","what":"Minor improvements and fixes","title":"measr (development version)","text":"Fixed bug LCDM specification constraints level-3 interaction terms. Functions evaluating estimated models (e.g., fit_ppmc(), reliability()) longer recalculate indices previously saved model object. behavior can overwritten force = TRUE. Updated Stan syntax compatible new array syntax (@andrjohns, #36) get_parameters() now preserves item identifiers default. Items can renamed numbers (e.g., 1, 2, 3, …) setting rename_item = TRUE. measr now reexports functions posterior conducting mathematical operations posterior::rvar() objects. Respondent estimates now returned posterior::rvar() objects summarized.","code":""},{"path":"https://measr.info/dev/news/index.html","id":"measr-031","dir":"Changelog","previous_headings":"","what":"measr 0.3.1","title":"measr 0.3.1","text":"CRAN release: 2023-05-27 Added NEWS.md file track changes package.","code":""},{"path":"https://measr.info/dev/news/index.html","id":"new-features-0-3-1","dir":"Changelog","previous_headings":"","what":"New features","title":"measr 0.3.1","text":"compensatory reparameterized unified model (C-RUM) can now estimated defining type = \"crum\" measr_dcm() function. Users can now drop higher order interactions loglinear cognitive diagnostic model (LCDM). new argument measr_dcm(), max_interaction, defines highest order interactions estimate. example, max_interaction = 2 estimate intercepts, main effects, two-way interactions. new argument measr_dcm(), attribute_structure allows users specified either “unconstrained” relationships attributes “independent” attributes. Users can now specify prior distribution structural parameters govern base rates class membership (#2). Safeguards added warn users specified prior defined chosen DCM sub-type. example, error generated prior defined slipping parameter, LCDM chosen type model estimated (#1).","code":""},{"path":"https://measr.info/dev/news/index.html","id":"minor-improvements-and-fixes-0-3-1","dir":"Changelog","previous_headings":"","what":"Minor improvements and fixes","title":"measr 0.3.1","text":"Fixed bug backend = \"rstan\" warmup iterations total iterations requested user warmup iterations also specified (#6). Additional specifications added measr_extract() extracting results estimated model.","code":""}]
