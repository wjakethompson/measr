[{"path":[]},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, respectful community.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement wjakethompson@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://measr.info/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to measr","title":"Contributing to measr","text":"outlines propose change measr.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to measr","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to measr","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). See tidyverse guide create great issue advice.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to measr","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"wjakethompson/measr\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to measr","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://measr.info/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to measr","text":"Please note measr project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://measr.info/dev/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://measr.info/dev/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://measr.info/dev/articles/ecpe.html","id":"explore-the-data","dir":"Articles","previous_headings":"","what":"Explore the Data","title":"Examination for the Certificate of Proficiency in English","text":"ECPE data built measr can accessed loading package. complete description data can viewed using ?ecpe_data. can see data set one row respondent, 2,922 respondents completed section ECPE. also see data 29 columns. first column contains respondent identifiers, remaining 28 columns contain dichotomous item responses items. item responses coded 0 incorrect response 1 correct response. addition data, also Q-matrix define attributes measured item. Q-matrix 28 rows, corresponds total number items. first column Q-matrix contains item identifiers, column names ecpe_data contain item responses. remaining columns define attributes measured ECPE. value 0 indicates item measure attribute, whereas value 1 indicates attribute measured item. example, item E1 measures morphosyntactic rules cohesive rules, item E4 measures lexical rules. quick summary data, can calculate proportion respondents answered question correctly (.e., item p-values). can join item p-values Q-matrix get sense attributes difficult. Overall, items relatively high p-values, items p-value .6 .9. Note general, items measuring morphosyntactic rules tend difficult (.e., lower p-values), followed items measuring cohesive rules, finally items measuring lexical rules.","code":"library(dcmdata)  ecpe_data #> # A tibble: 2,922 × 29 #>    resp_id    E1    E2    E3    E4    E5    E6    E7    E8    E9   E10 #>      <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> #>  1       1     1     1     1     0     1     1     1     1     1     1 #>  2       2     1     1     1     1     1     1     1     1     1     1 #>  3       3     1     1     1     1     1     1     0     1     1     1 #>  4       4     1     1     1     1     1     1     1     1     1     1 #>  5       5     1     1     1     1     1     1     1     1     1     1 #>  6       6     1     1     1     1     1     1     1     1     1     1 #>  7       7     1     1     1     1     1     1     1     1     1     1 #>  8       8     0     1     1     1     1     1     0     1     1     1 #>  9       9     1     1     1     1     1     1     1     1     1     1 #> 10      10     1     1     1     1     0     0     1     1     1     1 #> # ℹ 2,912 more rows #> # ℹ 18 more variables: E11 <int>, E12 <int>, E13 <int>, E14 <int>, #> #   E15 <int>, E16 <int>, E17 <int>, E18 <int>, E19 <int>, E20 <int>, #> #   E21 <int>, E22 <int>, E23 <int>, E24 <int>, E25 <int>, E26 <int>, #> #   E27 <int>, E28 <int> ecpe_qmatrix #> # A tibble: 28 × 4 #>    item_id morphosyntactic cohesive lexical #>    <chr>             <int>    <int>   <int> #>  1 E1                    1        1       0 #>  2 E2                    0        1       0 #>  3 E3                    1        0       1 #>  4 E4                    0        0       1 #>  5 E5                    0        0       1 #>  6 E6                    0        0       1 #>  7 E7                    1        0       1 #>  8 E8                    0        1       0 #>  9 E9                    0        0       1 #> 10 E10                   1        0       0 #> # ℹ 18 more rows library(tidyverse)  ecpe_data |>   summarize(across(-resp_id, mean)) |>   pivot_longer(everything(), names_to = \"item_id\", values_to = \"pvalue\") #> # A tibble: 28 × 2 #>    item_id pvalue #>    <chr>    <dbl> #>  1 E1       0.803 #>  2 E2       0.830 #>  3 E3       0.579 #>  4 E4       0.706 #>  5 E5       0.887 #>  6 E6       0.854 #>  7 E7       0.721 #>  8 E8       0.898 #>  9 E9       0.702 #> 10 E10      0.658 #> # ℹ 18 more rows ecpe_data |>   summarize(across(-resp_id, mean)) |>   pivot_longer(everything(), names_to = \"item_id\", values_to = \"pvalue\") |>   left_join(ecpe_qmatrix, join_by(item_id)) |>   pivot_longer(c(morphosyntactic, cohesive, lexical),                names_to = \"attribute\",                values_to = \"measured\") |>   filter(measured == 1) |>   summarize(measures = paste(str_to_title(attribute), collapse = \"/<br>\"),             .by = c(item_id, pvalue)) |>   mutate(measures = fct_reorder(measures, pvalue, mean)) |>   ggplot(aes(x = pvalue, y = measures)) +   geom_point(aes(color = measures),              position = position_jitter(height = 0.2, width = 0,                                         seed = 1213),              size = 4, show.legend = FALSE) +   scale_color_manual(values = c(\"#023047\", \"#D7263D\", \"#8ECAE6\", \"#219EBC\",                                 \"#F3D3BD\", \"#000000\")) +   expand_limits(x = c(0, 1)) +   scale_x_continuous(breaks = seq(0, 1, 0.2)) +   labs(x = \"Item *p*-value\", y = \"Measured attributes\")"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"dcm-estimation","dir":"Articles","previous_headings":"","what":"DCM Estimation","title":"Examination for the Certificate of Proficiency in English","text":"Now feel data, estimate DCM. Following original analysis ECPE data Templin & Hoffman (2013), ’ll estimate loglinear cognitive diagnostic model (LCDM). LCDM general diagnostic model allows different attribute relationships items (e.g., compensatory, non-compensatory) subsumes many types DCMs (Henson et al., 2009; Henson & Templin, 2019). following code estimate LCDM. first two lines, specify data, Q-matrix, respondent item identifiers. specify type DCM want estimate define model estimated. case, want estimate model using MCMC rstan package estimation engine. Finally, can customize MCMC process executed. example, specified 4 chains, 1,000 warmup iterations 500 retained iterations 1,500 iterations total. results total posterior distribution 2,000 samples parameter (.e., 500 iterations 4 chains). also specified file estimated model saved estimated. Now ’ve estimated model, let’s examine output. three types information ’ll examine: structural parameters, item parameters, respondent proficiency.","code":"library(measr) #>  #> Attaching package: 'measr' #> The following object is masked from 'package:stats': #>  #>     optim  ecpe_spec <- dcm_specify(qmatrix = ecpe_qmatrix, identifier = \"item_id\",                          measurement_model = lcdm(),                          structural_model = unconstrained())  ecpe_lcdm <- dcm_estimate(ecpe_spec, data = ecpe_data, identifier = \"resp_id\",                           method = \"mcmc\", backend = \"rstan\",                           chains = 4, iter = 1500, warmup = 1000,                           file = \"fits/ecpe-lcdm\")"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"structural-parameters","dir":"Articles","previous_headings":"DCM Estimation","what":"Structural Parameters","title":"Examination for the Certificate of Proficiency in English","text":"structural parameters define base rate membership attribute profiles. ECPE data consists 3 dichotomous attributes, total 23 = 8 possible profiles, classes. can view possible profiles using measr_extract(). function extracts different aspects model estimated measr. order attributes profiles corresponds order attributes listed Q-matrix used estimate model. means attributes 1, 2, 3 correspond morphosyntactic, cohesive, lexical rules, respectively. can extract structural parameters also using measr_extract(). structural parameters, see class, attribute profile, estimated proportion respondents class measure error (standard deviation posterior). example, nearly 30% respondents estimated proficient attributes (class 1), 17% estimated proficient just attributes 2 3 (class 7). looking structural parameters, can see respondents typically fall 4 8 possible profiles. Specifically, respondents typically proficient attributes, attribute 3 (lexical rules), attributes 2 3 (cohesive lexical rules), attributes. may indicate presence attribute hierarchy, suggested Templin & Bradshaw (2014), respondents must gain proficiency lexical rules can gain proficiency cohesive rules, finally morphosyntactic rules.  can also collapse across classes calculate base rate proficiency individual attribute. Overall, model estimates 38% respondents proficient morphosyntactic rules, 54% respondents proficient cohesive rules, 66% respondents proficient lexical rules. summary, profile- attribute-level base rates tell similar story. Respondents likely proficient lexical rules least likely proficient morphosyntactic rules. also mirrors analysis item p-values exploring data, showed items measuring morphosyntactic rules difficult items measuring lexical cohesive rules.","code":"ecpe_classes <- measr_extract(ecpe_lcdm, \"classes\") ecpe_classes #> # A tibble: 8 × 4 #>   class   morphosyntactic cohesive lexical #>   <chr>             <int>    <int>   <int> #> 1 [0,0,0]               0        0       0 #> 2 [1,0,0]               1        0       0 #> 3 [0,1,0]               0        1       0 #> 4 [0,0,1]               0        0       1 #> 5 [1,1,0]               1        1       0 #> 6 [1,0,1]               1        0       1 #> 7 [0,1,1]               0        1       1 #> 8 [1,1,1]               1        1       1 structural_parameters <- measr_extract(ecpe_lcdm, \"strc_param\") structural_parameters #> # A tibble: 8 × 2 #>   class           estimate #>   <chr>         <rvar[1d]> #> 1 [0,0,0]  0.2971 ± 0.0170 #> 2 [1,0,0]  0.0120 ± 0.0065 #> 3 [0,1,0]  0.0169 ± 0.0108 #> 4 [0,0,1]  0.1282 ± 0.0199 #> 5 [1,1,0]  0.0094 ± 0.0056 #> 6 [1,0,1]  0.0178 ± 0.0101 #> 7 [0,1,1]  0.1731 ± 0.0200 #> 8 [1,1,1]  0.3455 ± 0.0173 structural_parameters |>   mutate(class = fct_inorder(class),          prob = map_dbl(estimate, mean)) |>   ggplot(aes(x = class, y = prob)) +   geom_col(fill = msr_colors[2]) +   labs(x = \"Class\", y = \"Base rate\") ecpe_classes |>   left_join(structural_parameters, join_by(class)) |>   summarize(morphosyntactic = rvar_sum(estimate[which(morphosyntactic == 1)]),             cohesive = rvar_sum(estimate[which(cohesive == 1)]),             lexical = rvar_sum(estimate[which(lexical == 1)])) #> # A tibble: 1 × 3 #>   morphosyntactic      cohesive       lexical #>        <rvar[1d]>    <rvar[1d]>    <rvar[1d]> #> 1    0.38 ± 0.019  0.54 ± 0.029  0.66 ± 0.015"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"item-parameters","dir":"Articles","previous_headings":"DCM Estimation","what":"Item Parameters","title":"Examination for the Certificate of Proficiency in English","text":"item parameters define log-odds respondent class providing correct response. can extract estimated item parameters using measr_extract(). , estimate column reports estimated value parameter measure associated error (.e., standard deviation posterior distribution). example, item E1 four parameters, measures two attributes: intercept, represents log-odds providing correct response respondent proficient neither attributes item measures (.e., morphosyntactic rules cohesive rules). main effect morphosyntactic rules, represents increase log-odds providing correct response respondent proficient attribute. main effect cohesive rules, represents increase log-odds providing correct response respondent proficient attribute. interaction morphosyntactic cohesive rules, change log-odds respondent proficient attributes. can compare estimates Templin & Hoffman (2013) reported using different software estimate model. following figure, parameters fall close dashed line, represents perfect agreement.  parameters deviate line perfect agreement, expected. example, take item E7, measures morphosyntactic lexical rules. measr Templin & Hoffman (2013) report values approximately -0.09 intercept 0.93 main effect lexical rules. main effect morphosyntactic rules, measr estimated value 1.57, compared value 2.86 reported Templin & Hoffman (2013), difference -1.29. Similarly, interaction term estimated measr 0.39, compared value -0.95 reported Templin & Hoffman (2013), difference 1.34. indicates log-odds providing correct response individual mastered attributes approximately , regardless software. , measr, get log-odds -0.07 + 1.57 + 0.91 + 0.39 = 2.79, Templin & Hoffman (2013), get log-odds -0.11 + 2.86 + 0.95 + -0.95 = 2.75. true differences figure. change main effect morphosyntactic rules corresponding change interaction term “cancels ” difference. happening? Let’s revisit proportion respondents class. respondents proficient morphosyntactic rules without also proficient attributes (classes 2, 5, 6; less 4% respondents). Therefore, less information estimating morphosyntactic main effects, items measure multiple attributes, represent increase log-odds proficiency morphosyntactic rules conditional proficient attribute. less information available morphosyntactic main effects, prior influence parameters. Note figure main effect estimates diagonal less extreme using measr. example, triangle top right main effect estimated nearly 3 Templin & Hoffman (2013), just 1.5 model estimated measr. Thus, regularizing effect, prior pulling extreme values, intended outcome. discuss priors estimating model instead used default priors provided measr. information prior distributions, including information specify prior distributions model parameters, see ?prior model estimation vignette.","code":"item_parameters <- measr_extract(ecpe_lcdm, what = \"item_param\") item_parameters #> # A tibble: 74 × 5 #>    item_id type        attributes               coefficient       estimate #>    <chr>   <chr>       <chr>                    <chr>           <rvar[1d]> #>  1 E1      intercept   NA                       l1_0          0.81 ± 0.077 #>  2 E1      maineffect  morphosyntactic          l1_11         0.66 ± 0.409 #>  3 E1      maineffect  cohesive                 l1_12         0.65 ± 0.221 #>  4 E1      interaction morphosyntactic__cohesi… l1_212        0.47 ± 0.528 #>  5 E2      intercept   NA                       l2_0          1.04 ± 0.080 #>  6 E2      maineffect  cohesive                 l2_12         1.23 ± 0.155 #>  7 E3      intercept   NA                       l3_0         -0.35 ± 0.075 #>  8 E3      maineffect  morphosyntactic          l3_11         0.74 ± 0.381 #>  9 E3      maineffect  lexical                  l3_13         0.36 ± 0.116 #> 10 E3      interaction morphosyntactic__lexical l3_213        0.53 ± 0.398 #> # ℹ 64 more rows param_compare |>   ggplot(aes(x = measr_est, y = mplus_est)) +   geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +   geom_point(aes(color = type, shape = type), size = 3) +   scale_color_manual(values = msr_colors) +   expand_limits(x = c(-2, 3), y = c(-2, 3)) +   coord_fixed() +   labs(x = \"measr\", y = \"Templin & Hoffman (2013)\",        color = \"Parameter Type\", shape = \"Parameter Type\") structural_parameters #> # A tibble: 8 × 2 #>   class           estimate #>   <chr>         <rvar[1d]> #> 1 [0,0,0]  0.2971 ± 0.0170 #> 2 [1,0,0]  0.0120 ± 0.0065 #> 3 [0,1,0]  0.0169 ± 0.0108 #> 4 [0,0,1]  0.1282 ± 0.0199 #> 5 [1,1,0]  0.0094 ± 0.0056 #> 6 [1,0,1]  0.0178 ± 0.0101 #> 7 [0,1,1]  0.1731 ± 0.0200 #> 8 [1,1,1]  0.3455 ± 0.0173"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"respondent-proficiency","dir":"Articles","previous_headings":"DCM Estimation","what":"Respondent Proficiency","title":"Examination for the Certificate of Proficiency in English","text":"final piece output model examine respondent probabilities. two types probabilities can calculate, returned score() function. class_probabilites probabilities respondent belongs 8 possible classes (.e., profiles proficiency). attribute_probabilites probabilities respondent proficient individual attributes. better describe difference two probabilities, let’s look results respondent 73. looking class probabilities, likely profile [1,1,1], meaning respondent proficient attributes. However, 39% chance respondent belongs class. also greater 10% chance belonging [0,0,1] [0,1,1] classes. attribute probabilities respondent 73 show slightly different story. probabilities indicate 42% chance respondent proficient morphosyntactic rules, 76% chance respondent proficient cohesive rules, 93% chance respondent proficient lexical rules. , ’re fairly confident respondent 73 proficient lexical rules, somewhat confident proficient cohesive rules, confident whether student proficient morphosyntactic rules (.e., proficiency probability reasonably low 27% high 57%). probabilities can turned classifications setting proficiency thresholds. example, might decide probabilities greater .5 (.e., likely ) indicate proficiency (e.g., Bradshaw & Levy, 2019). hand, might want confident respondent proficient reporting , therefore might set higher threshold (e.g., .8, Thompson et al., 2019). respondent 73, thresholds .5 .8 result proficiency profiles [0,1,1] [0,0,1], respectively. Either way, profiles differ overall likely profile indicated class probabilities. Thus, important give careful consideration results determined reported. default, score() returns summary posterior distribution probability (.e., mean 95% credible interval). many class attribute probabilities, therefore object containing full posterior distributions quite large. can change percentiles returned posterior summary setting probs argument quantiles default probs = c(0.025, 0.975). Alternatively, want full posterior distribution probability, can set summary = FALSE. return posterior::rvar() object (structural item parameter summaries) contains posterior draws probability, displayed mean posterior ±1 standard deviation. information rvar objects, see accompanying vignette (vignette(\"rvar\", package = \"posterior\")).","code":"resp_probs <- score(ecpe_lcdm) resp_probs #> $class_probabilities #> # A tibble: 23,376 × 5 #>    resp_id class   probability       `2.5%`    `97.5%` #>    <chr>   <chr>         <dbl>        <dbl>      <dbl> #>  1 1       [0,0,0] 0.00000766  0.00000379   0.0000135  #>  2 1       [1,0,0] 0.0000999   0.00000723   0.000300   #>  3 1       [0,1,0] 0.000000525 0.0000000308 0.00000146 #>  4 1       [0,0,1] 0.00131     0.000735     0.00209    #>  5 1       [1,1,0] 0.0000895   0.00000767   0.000271   #>  6 1       [1,0,1] 0.0424      0.00346      0.102      #>  7 1       [0,1,1] 0.00207     0.00129      0.00310    #>  8 1       [1,1,1] 0.954       0.894        0.993      #>  9 2       [0,0,0] 0.00000584  0.00000277   0.0000108  #> 10 2       [1,0,0] 0.0000763   0.00000575   0.000243   #> # ℹ 23,366 more rows #>  #> $attribute_probabilities #> # A tibble: 8,766 × 5 #>    resp_id attribute       probability `2.5%` `97.5%` #>    <chr>   <chr>                 <dbl>  <dbl>   <dbl> #>  1 1       morphosyntactic       0.997  0.995   0.998 #>  2 1       cohesive              0.956  0.896   0.995 #>  3 1       lexical               1.000  1.000   1.000 #>  4 2       morphosyntactic       0.995  0.992   0.997 #>  5 2       cohesive              0.902  0.776   0.987 #>  6 2       lexical               1.000  1.000   1.000 #>  7 3       morphosyntactic       0.983  0.971   0.991 #>  8 3       cohesive              0.988  0.974   0.997 #>  9 3       lexical               1.000  1.000   1.000 #> 10 4       morphosyntactic       0.998  0.996   0.998 #> # ℹ 8,756 more rows resp_probs$class_probabilities |>  filter(resp_id == 73) #> # A tibble: 8 × 5 #>   resp_id class   probability   `2.5%` `97.5%` #>   <chr>   <chr>         <dbl>    <dbl>   <dbl> #> 1 73      [0,0,0]     0.0493  0.0241    0.0887 #> 2 73      [1,0,0]     0.00591 0.000368  0.0204 #> 3 73      [0,1,0]     0.00458 0.000240  0.0131 #> 4 73      [0,0,1]     0.170   0.0961    0.268  #> 5 73      [1,1,0]     0.00764 0.000366  0.0289 #> 6 73      [1,0,1]     0.0131  0.00105   0.0345 #> 7 73      [0,1,1]     0.360   0.243     0.476  #> 8 73      [1,1,1]     0.389   0.247     0.534 resp_probs$attribute_probabilities |>   filter(resp_id == 73) #> # A tibble: 3 × 5 #>   resp_id attribute       probability `2.5%` `97.5%` #>   <chr>   <chr>                 <dbl>  <dbl>   <dbl> #> 1 73      morphosyntactic       0.416  0.269   0.570 #> 2 73      cohesive              0.761  0.644   0.855 #> 3 73      lexical               0.933  0.881   0.967 score(ecpe_lcdm, summary = FALSE) #> $class_probabilities #> # A tibble: 2,922 × 9 #>    resp_id          `[0,0,0]`              `[1,0,0]`          `[0,1,0]` #>    <chr>           <rvar[1d]>             <rvar[1d]>         <rvar[1d]> #>  1 1        7.7e-06 ± 2.5e-06  0.0000999 ± 0.0000798  5.2e-07 ± 3.8e-07 #>  2 2        5.8e-06 ± 2.0e-06  0.0000763 ± 0.0000622  2.1e-07 ± 1.8e-07 #>  3 3        5.6e-06 ± 2.1e-06  0.0000168 ± 0.0000172  1.8e-06 ± 1.3e-06 #>  4 4        3.2e-07 ± 1.1e-07  0.0000041 ± 0.0000032  1.0e-07 ± 7.2e-08 #>  5 5        1.2e-03 ± 3.7e-04  0.0086487 ± 0.0063399  3.7e-04 ± 2.6e-04 #>  6 6        3.0e-06 ± 1.0e-06  0.0000158 ± 0.0000148  9.3e-07 ± 6.7e-07 #>  7 7        3.0e-06 ± 1.0e-06  0.0000158 ± 0.0000148  9.3e-07 ± 6.7e-07 #>  8 8        3.8e-02 ± 1.2e-02  0.0000862 ± 0.0001018  1.4e-03 ± 1.1e-03 #>  9 9        6.5e-05 ± 1.9e-05  0.0002082 ± 0.0001485  2.1e-05 ± 1.4e-05 #> 10 10       4.1e-01 ± 1.4e-01  0.4156164 ± 0.1798912  3.7e-03 ± 3.0e-03 #> # ℹ 2,912 more rows #> # ℹ 5 more variables: `[0,0,1]` <rvar[1d]>, `[1,1,0]` <rvar[1d]>, #> #   `[1,0,1]` <rvar[1d]>, `[0,1,1]` <rvar[1d]>, `[1,1,1]` <rvar[1d]> #>  #> $attribute_probabilities #> # A tibble: 2,922 × 4 #>    resp_id   morphosyntactic       cohesive          lexical #>    <chr>          <rvar[1d]>     <rvar[1d]>       <rvar[1d]> #>  1 1        0.9966 ± 0.00067  0.96 ± 0.0251  1.00 ± 0.000116 #>  2 2        0.9950 ± 0.00133  0.90 ± 0.0558  1.00 ± 0.000074 #>  3 3        0.9827 ± 0.00522  0.99 ± 0.0058  1.00 ± 0.000079 #>  4 4        0.9976 ± 0.00051  0.99 ± 0.0057  1.00 ± 0.000014 #>  5 5        0.9880 ± 0.00235  0.98 ± 0.0086  0.95 ± 0.025971 #>  6 6        0.9924 ± 0.00211  0.99 ± 0.0058  1.00 ± 0.000068 #>  7 7        0.9924 ± 0.00211  0.99 ± 0.0058  1.00 ± 0.000068 #>  8 8        0.0044 ± 0.00193  0.44 ± 0.0818  0.96 ± 0.011942 #>  9 9        0.9452 ± 0.01210  0.98 ± 0.0061  1.00 ± 0.000766 #> 10 10       0.5448 ± 0.15235  0.12 ± 0.0621  0.11 ± 0.049288 #> # ℹ 2,912 more rows"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"dcm-evaluation","dir":"Articles","previous_headings":"","what":"DCM Evaluation","title":"Examination for the Certificate of Proficiency in English","text":"several ways might evaluate estimate model. case study, ’ll focus two: absolute model fit classification reliability.","code":""},{"path":"https://measr.info/dev/articles/ecpe.html","id":"absolute-model-fit","dir":"Articles","previous_headings":"DCM Evaluation","what":"Absolute Model Fit","title":"Examination for the Certificate of Proficiency in English","text":"One common measures model fit DCMs M2 statistic. index limited information goodness--fit measure originally described Maydeu-Olivares & Joe (2005, 2006) adapted DCMs Y. Liu et al. (2016). can calculate M2 model estimated measr fit_m2(). addition calculated M2 statistic, fit_m2() also returns root mean square error approximation (RMSEA) associated confidence interval standardized root mean square residual (SRMSR). estimated LCDM, see M2 value 512.9, corresponding p-value <.01. interpreting M2 p-value, null hypothesis model fits. Thus, p-value represents probability observing M2 value large model fits. estimated LCDM, p-value extremely small, indicating model poor fit. described model evaluation vignette, fully Bayesian estimation allows us evaluate model fit using posterior predictive model checks (PPMCs). Specifically, measr supports PPMC overall raw score distribution described Park et al. (2015) Thompson (2019). replicated data sets, calculate number students raw score (.e., number correct responses). can done using fit_ppmc(). Note can also calculate item-level PPMCs. However, case study interested overall model fit, ’ll set item_fit = NULL save computation time. output, posterior predictive p-value (ppp) small, indicating poor fit. unpack really means, let’s visualize PPMC. following figure, blue bars show credible intervals number respondents expect see raw score point, given estimated model parameters. red dots line indicate number respondents observed raw score point observed data (ecpe_data). example, model expects 110 160 respondents total score 14. observed data, 92 respondents total score 14. general, model tends overestimate number respondents raw score 14–16 23–25. hand, model underestimates number respondents raw score 6–10 27–28.  can quantify different observed raw score distribution replicated data sets calculating χ2-like statistic. , first calculate expected number students raw score taking mean posterior distribution score point. , replicated data set, calculate χ2-like statistic \\chi^2_{rep} = \\sum_{s=0}^S \\frac{[n_s - E(n_s)]^2}{E(n_s)}, s represents raw score, ns number respondents score point s, E(ns) expected number respondents score point s (.e., mean posterior distribution). calculation completed replicated data sets, creating posterior distribution χ2rep represents plausible values χ2-like statistic model correct. distribution summarized fit_ppmc() output. Specifically, expect χ2-like statistic observed data 12 59, shown following figure. However, calculate statistic observed data, get value 930, way beyond expected range. represented ppp value, proportion χ2rep values larger observed value. case, values χ2rep larger observed value, leading ppp 0.  summary, M2 raw score PPMC indicate poor fit estimated LCDM observed data. unexpected, given classes small. Recall discussion estimated structural parameters three classes combine include less 4% respondents. classes small, parameter estimates can unstable, leading poor model fit (e.g., Hu & Templin, 2020; Ma et al., 2023; Martinez & Templin, 2023; Templin & Bradshaw, 2014; Wang & Lu, 2021).","code":"fit_m2(ecpe_lcdm) #> # A tibble: 1 × 8 #>      m2    df     pval  rmsea ci_lower ci_upper `90% CI`          srmsr #>   <dbl> <int>    <dbl>  <dbl>    <dbl>    <dbl> <chr>             <dbl> #> 1  513.   325 1.32e-10 0.0141   0.0117   0.0163 [0.0117, 0.0163] 0.0320 rawscore_ppmc <- fit_ppmc(ecpe_lcdm, model_fit = \"raw_score\",                           return_draws = 500) rawscore_ppmc #> $ppmc_raw_score #> # A tibble: 1 × 7 #>   obs_chisq ppmc_mean `2.5%` `97.5%` rawscore_samples chisq_samples    ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <list>           <list>         <dbl> #> 1      930.      28.8   12.3    58.6 <tibble>         <dbl [500]>   0.0005 library(ggdist)  obs_scores <- ecpe_data |>   pivot_longer(cols = -\"resp_id\") |>   summarize(raw_score = sum(value), .by = resp_id) |>   count(raw_score) |>   complete(raw_score = 0:28, fill = list(n = 0L))  rawscore_ppmc$ppmc_raw_score |>   dplyr::select(rawscore_samples) |>   unnest(rawscore_samples) |>   unnest(raw_scores) |>   ggplot() +   stat_interval(aes(x = raw_score, y = n, color_ramp = after_stat(level)),                 point_interval = \"mean_qi\",                 color = msr_colors[2], linewidth = 5,                 show.legend = c(color = FALSE)) +   geom_line(data = obs_scores,             aes(x = raw_score, y = n),             color = msr_colors[3]) +   geom_point(data = obs_scores,              aes(x = raw_score, y = n, fill = \"Observed Data\"),              shape = 21, color = msr_colors[3], size = 2) +   scale_color_ramp_discrete(from = \"white\", range = c(0.2, 1),                             breaks = c(0.5, 0.8, 0.95),                             labels = ~sprintf(\"%0.2f\", as.numeric(.x))) +   scale_fill_manual(values = c(msr_colors[3])) +   scale_x_continuous(breaks = seq(0, 28, 2), expand = c(0, 0)) +   scale_y_comma() +   labs(x = \"Raw score\", y = \"Respondents\",        color_ramp = \"Credible Interval\", fill = NULL) +   guides(fill = guide_legend(override.aes = list(size = 3))) rawscore_ppmc$ppmc_raw_score |>   dplyr::select(chisq_samples) |>   unnest(chisq_samples) |>   ggplot(aes(x = chisq_samples)) +   stat_dots(quantiles = 500, layout = \"hex\", stackratio = 0.9,             color = msr_colors[2], fill = msr_colors[2],             na.rm = TRUE) +   scale_x_continuous(limits = c(0, 100)) +   labs(y = NULL, x = \"&chi;^2^<sub>rep<\/sub>\") +   theme(axis.text.y = element_blank(),         axis.ticks.y = element_blank())"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"classification-reliability","dir":"Articles","previous_headings":"DCM Evaluation","what":"Classification Reliability","title":"Examination for the Certificate of Proficiency in English","text":"Depending intended uses assessment, may less concerned overall model fit concerned consistency accuracy classifications. words, may focused reliability classifications produced model. several ways evaluate reliability evidence DCMs. comprehensive summary methods, see Sinharay & Johnson (2019). Using measr, can easily calculate wide variety reliability metrics estimated LCDM using reliability(). default, reliability() returns several different types reliability evidence. types evidence, indices range 0–1, values close 1 indicating high accuracy consistency. information relevant depend scores determined reported. example, determine respondent’s scores choosing overall profile consistent observed responses (.e., class probabilities returned score()). type classification want look pattern reliability, classifying responding overall pattern proficiency attributes. values p_a p_c described Cui et al. (2012). Pa probability classifying random respondent correct class, Pc probability consistently classifying random respondent class across two test administrations. hand, rather basing results overall likely profile, score attribute individually (.e., attribute probabilities returned score()). accomplished calculating probability proficiency attribute creating classifications based given threshold (usually .5). result known maximum posteriori (MAP) represents likely latent state respondent attribute. pattern-level classifications, attribute level classifications can evaluated accuracy consistency. Johnson & Sinharay (2018) developed accuracy (acc) consistency (consist) metrics attribute level classifications, also examined agreement measures based contingency tables Goodman & Kruskal’s λ, Cohen’s κ, Youden’s J, true positive rate, true negative rate. Using cutoffs recommended Johnson & Sinharay (2018), cohesive rules attribute fair accuracy morphosyntactic lexical rules attributes good accuracy. attributes fair classification consistency. Finally, results reported probabilities proficiency attribute, rather categorical classification. instance, probabilities reported, want report reliability precision probability estimate. type result known expected posteriori (EAP) estimate expected value classification. Johnson & Sinharay (2020) described four metrics evaluating reliability EAP estimates: (1) biserial, (2) informational, (3) parallel forms, (4) constrained parallel forms originally proposed Templin & Bradshaw (2013). paper, Johnson & Sinharay (2020) note types parallel form reliability tend estimate reliability, therefore recommend using biserial informational reliability metrics. metrics available reliability output rho_bs rho_i. Using cutoffs suggested Johnson & Sinharay (2020), three attributes poor EAP reliability. ’s surprising EAP reliability lower MAP reliability, harder place respondents specific point scale (.e., probability scale) place respondents category. example, let’s return example respondent 73. estimated 93% chance respondent proficient lexical rules. However, credible interval tells us probability anywhere 88% 97%. ’s nine percentage point range plausible. don’t great deal certainty specific probability respondent proficient lexical rules; however, entire plausible range high, make classification “proficient” regardless range true probability proficiency . , consistently make classification decision, regardless uncertainty probability .","code":"ecpe_reliability <- reliability(ecpe_lcdm) ecpe_reliability #> $pattern_reliability #>       p_a       p_c  #> 0.7387898 0.6635520  #>  #> $map_reliability #> $map_reliability$accuracy #> # A tibble: 3 × 8 #>   attribute         acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>           <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 morphosyntactic 0.896    0.729   0.787    0.775   0.942 0.851 0.924 #> 2 cohesive        0.852    0.674   0.703    0.699   0.892 0.876 0.823 #> 3 lexical         0.916    0.750   0.609    0.802   0.959 0.947 0.855 #>  #> $map_reliability$consistency #> # A tibble: 3 × 10 #>   attribute   consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>         <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 morphosynt…   0.834    0.556   0.684    0.646   0.853 0.778 0.868  0.852 #> 2 cohesive      0.806    0.562   0.681    0.607   0.816 0.826 0.781  0.789 #> 3 lexical       0.856    0.553   0.626    0.670   0.875 0.894 0.776  0.880 #> # ℹ 1 more variable: pc_prime <dbl> #>  #>  #> $eap_reliability #> # A tibble: 3 × 5 #>   attribute       rho_pf rho_bs rho_i rho_tb #>   <chr>            <dbl>  <dbl> <dbl>  <dbl> #> 1 morphosyntactic  0.734  0.687 0.573  0.884 #> 2 cohesive         0.728  0.574 0.505  0.785 #> 3 lexical          0.758  0.730 0.587  0.915 ecpe_reliability$pattern_reliability #>       p_a       p_c  #> 0.7387898 0.6635520 ecpe_reliability$map_reliability #> $accuracy #> # A tibble: 3 × 8 #>   attribute         acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>           <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 morphosyntactic 0.896    0.729   0.787    0.775   0.942 0.851 0.924 #> 2 cohesive        0.852    0.674   0.703    0.699   0.892 0.876 0.823 #> 3 lexical         0.916    0.750   0.609    0.802   0.959 0.947 0.855 #>  #> $consistency #> # A tibble: 3 × 10 #>   attribute   consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>         <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 morphosynt…   0.834    0.556   0.684    0.646   0.853 0.778 0.868  0.852 #> 2 cohesive      0.806    0.562   0.681    0.607   0.816 0.826 0.781  0.789 #> 3 lexical       0.856    0.553   0.626    0.670   0.875 0.894 0.776  0.880 #> # ℹ 1 more variable: pc_prime <dbl> ecpe_reliability$eap_reliability #> # A tibble: 3 × 5 #>   attribute       rho_pf rho_bs rho_i rho_tb #>   <chr>            <dbl>  <dbl> <dbl>  <dbl> #> 1 morphosyntactic  0.734  0.687 0.573  0.884 #> 2 cohesive         0.728  0.574 0.505  0.785 #> 3 lexical          0.758  0.730 0.587  0.915 resp_probs$attribute_probabilities |>   filter(resp_id == 73) #> # A tibble: 3 × 5 #>   resp_id attribute       probability `2.5%` `97.5%` #>   <chr>   <chr>                 <dbl>  <dbl>   <dbl> #> 1 73      morphosyntactic       0.416  0.269   0.570 #> 2 73      cohesive              0.761  0.644   0.855 #> 3 73      lexical               0.933  0.881   0.967"},{"path":"https://measr.info/dev/articles/ecpe.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Examination for the Certificate of Proficiency in English","text":"case study, estimated LCDM analyze ECPE data. model estimation, saw estimates provided measr highly consistent previously reported parameters estimates ECPE. However, model fit indices indicated LCDM great job represented observed data. likely due dependencies among attributes. analyze data, might consider model different attribute structure, hierarchical diagnostic classification model (Templin & Bradshaw, 2014). Despite poor model fit, reliability indices showed classification consistency accuracy generally fair good range, therefore, depending intended uses, model may sufficient reporting respondent proficiency three attributes.","code":""},{"path":[]},{"path":"https://measr.info/dev/articles/measr.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting started with measr","text":"measr uses Stan backend estimating DCMs, installation rstan cmdstanr required.","code":""},{"path":"https://measr.info/dev/articles/measr.html","id":"rstan","dir":"Articles","previous_headings":"Installation","what":"rstan","title":"Getting started with measr","text":"installing rstan, system must configured compile C++ code. can find instructions RStan Getting Started guide Windows, Mac, Linux. rstan package can installed directly CRAN: verify installation successful, can run test model. everything set correctly, model compile sample. additional troubleshooting help, see RStan Getting Started guide.","code":"install.packages(\"rstan\") library(rstan)  example(stan_model, package = \"rstan\", run.dontrun = TRUE)"},{"path":"https://measr.info/dev/articles/measr.html","id":"cmdstanr","dir":"Articles","previous_headings":"Installation","what":"cmdstanr","title":"Getting started with measr","text":"cmdstanr package yet available CRAN. beta release can installed Stan R package repository: development version can installed GitHub: cmdstanr package requires suitable C++ toolchain. Requirements instructions ensuring toolchain properly set described CmdStan User Guide. can verify C++ toolchain set correctly : Finally, cmdstanr requires CmdStan (shell interface Stan). toolchain properly set , CmdStan can installed : additional installation help, getting Getting Started CmdStanR vignette.","code":"install.packages(\"cmdstanr\",                  repos = c(\"https://mc-stan.org/r-packages/\",                            getOption(\"repos\"))) # install.packages(\"remotes\") remotes::install_github(\"stan-dev/cmdstanr\") library(cmdstanr)  check_cmdstan_toolchain() install_cmdstan(cores = 2)"},{"path":"https://measr.info/dev/articles/measr.html","id":"measr","dir":"Articles","previous_headings":"Installation","what":"measr","title":"Getting started with measr","text":"rstan /cmdstanr installed, ready install measr. released version measr can installed directly CRAN: , development version can installed GitHub: everything installed, ’re ready start estimating evaluating DCMs.","code":"install.packages(\"measr\") # install.packages(\"remotes\") remotes::install_github(\"wjakethompson/measr\") library(measr) #>  #> Attaching package: 'measr' #> The following object is masked from 'package:stats': #>  #>     optim"},{"path":"https://measr.info/dev/articles/measr.html","id":"model-estimation","dir":"Articles","previous_headings":"","what":"Model Estimation","title":"Getting started with measr","text":"illustrate, ’ll fit loglinear cognitive diagnostic model (LCDM) assessment English language proficiency (see Templin & Hoffman, 2013). many different subtypes DCMs make different assumptions attributes relate . LCDM general model makes assumptions compensatory nature relationships attributes. details LCDM, see Henson & Templin (2019). data set ’re using contains 29 items together measure three attributes: morphosyntactic rules, cohesive rules, lexical rules. Q-matrix defines attributes measured item. example, item E1 measures morphosyntactic cohesive rules. data described ?ecpe. can estimate LCDM first specifying model using dcm_specify(). specify Q-matrix column name item identifiers. function also allows us define type DCM want estimate, case, LCDM unconstrained attributes. created specification, can estimate model using dcm_estimate(). provide model specification, along data set column name respondent identifiers. can also add arguments control estimation process. method defines model estimated. computational efficiency, ’ve selected \"optim\", uses Stan’s optimizer estimate model. fully Bayesian estimation, can change method = \"mcmc\". backend defines Stan engine use estimation. default \"rstan\", use rstan package estimating model. Alternatively, backend = \"cmdstanr\" use cmdstanr package. details options customizing model specification estimation, see model estimation article measr website. model estimated, can use measr_extract() pull probability respondent proficient attributes. example, first respondent probabilities near 1 attributes, indicating high degree confidence proficient attributes. hand, respondent 8 relatively low probabilities morphosyntactic cohesive attributes, likely proficient lexical rules.","code":"library(dcmdata)  ecpe_data #> # A tibble: 2,922 × 29 #>    resp_id    E1    E2    E3    E4    E5    E6    E7    E8    E9   E10 #>      <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> #>  1       1     1     1     1     0     1     1     1     1     1     1 #>  2       2     1     1     1     1     1     1     1     1     1     1 #>  3       3     1     1     1     1     1     1     0     1     1     1 #>  4       4     1     1     1     1     1     1     1     1     1     1 #>  5       5     1     1     1     1     1     1     1     1     1     1 #>  6       6     1     1     1     1     1     1     1     1     1     1 #>  7       7     1     1     1     1     1     1     1     1     1     1 #>  8       8     0     1     1     1     1     1     0     1     1     1 #>  9       9     1     1     1     1     1     1     1     1     1     1 #> 10      10     1     1     1     1     0     0     1     1     1     1 #> # ℹ 2,912 more rows #> # ℹ 18 more variables: E11 <int>, E12 <int>, E13 <int>, E14 <int>, #> #   E15 <int>, E16 <int>, E17 <int>, E18 <int>, E19 <int>, E20 <int>, #> #   E21 <int>, E22 <int>, E23 <int>, E24 <int>, E25 <int>, E26 <int>, #> #   E27 <int>, E28 <int>  ecpe_qmatrix #> # A tibble: 28 × 4 #>    item_id morphosyntactic cohesive lexical #>    <chr>             <int>    <int>   <int> #>  1 E1                    1        1       0 #>  2 E2                    0        1       0 #>  3 E3                    1        0       1 #>  4 E4                    0        0       1 #>  5 E5                    0        0       1 #>  6 E6                    0        0       1 #>  7 E7                    1        0       1 #>  8 E8                    0        1       0 #>  9 E9                    0        0       1 #> 10 E10                   1        0       0 #> # ℹ 18 more rows ecpe_spec <- dcm_specify(ecpe_qmatrix, identifier = \"item_id\",                          measurement_model = lcdm(),                          structural_model = unconstrained())  ecpe_lcdm <- dcm_estimate(ecpe_spec, data = ecpe_data, identifier = \"resp_id\",                           method = \"optim\", backend = \"rstan\") ecpe_lcdm <- add_respondent_estimates(ecpe_lcdm) measr_extract(ecpe_lcdm, \"attribute_prob\") #> # A tibble: 2,922 × 4 #>    resp_id morphosyntactic cohesive lexical #>    <chr>             <dbl>    <dbl>   <dbl> #>  1 1               0.997      0.962  1.000  #>  2 2               0.995      0.911  1.000  #>  3 3               0.985      0.990  1.000  #>  4 4               0.998      0.991  1.000  #>  5 5               0.989      0.984  0.956  #>  6 6               0.993      0.991  1.000  #>  7 7               0.993      0.991  1.000  #>  8 8               0.00453    0.462  0.963  #>  9 9               0.949      0.986  0.998  #> 10 10              0.627      0.139  0.0928 #> # ℹ 2,912 more rows"},{"path":"https://measr.info/dev/articles/measr.html","id":"model-evaluation","dir":"Articles","previous_headings":"","what":"Model Evaluation","title":"Getting started with measr","text":"many ways evaluate estimated model including model fit, model comparisons, reliability. complete listing available options, see ?model_evaluation. illustrate functions work, ’ll look classification accuracy consistency metrics described Johnson & Sinharay (2018). start adding reliability information estimated model using add_reliability(). can extract information, using measr_extract(). indices, numbers close 1 indicate high level classification accuracy consistency. numbers amazing, overall look pretty good. guidance cutoff values “good,” “fair,” etc. reliability, see Johnson & Sinharay (2018).","code":"ecpe_lcdm <- add_reliability(ecpe_lcdm) measr_extract(ecpe_lcdm, \"classification_reliability\") #> # A tibble: 3 × 3 #>   attribute       accuracy consistency #>   <chr>              <dbl>       <dbl> #> 1 morphosyntactic    0.896       0.832 #> 2 cohesive           0.858       0.810 #> 3 lexical            0.918       0.858"},{"path":[]},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Estimating diagnostic classification models","text":"demonstrate model estimation functionality measr, ’ll examine simulated data set. data set contains 2,000 respondents 20 items measure total 4 attributes, item measures 2 attributes. data generated loglinear cognitive diagnostic model (LCDM), general model subsumes many DCM subtypes (Henson et al., 2009). using simulated data set, can compare parameter estimates measr true data generating parameters.","code":"library(tidyverse)  sim_data <- read_rds(\"data/simulated-data.rds\")  sim_data$data #> # A tibble: 2,000 × 21 #>    resp_id    A1    A2    A3    A4    A5    A6    A7    A8    A9   A10 #>      <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> #>  1       1     1     1     0     1     0     0     0     0     1     0 #>  2       2     1     1     1     0     0     1     0     1     1     0 #>  3       3     1     1     1     1     1     0     1     1     0     1 #>  4       4     1     0     1     0     0     1     0     1     1     0 #>  5       5     1     1     0     0     0     0     0     1     1     0 #>  6       6     1     1     1     0     1     0     0     1     1     0 #>  7       7     1     0     1     0     0     1     0     1     1     0 #>  8       8     0     1     1     0     0     1     0     1     1     0 #>  9       9     1     1     1     0     0     1     1     1     1     0 #> 10      10     1     1     1     0     1     1     0     1     1     1 #> # ℹ 1,990 more rows #> # ℹ 10 more variables: A11 <int>, A12 <int>, A13 <int>, A14 <int>, #> #   A15 <int>, A16 <int>, A17 <int>, A18 <int>, A19 <int>, A20 <int>  sim_data$q_matrix #> # A tibble: 20 × 5 #>    item_id  att1  att2  att3  att4 #>    <chr>   <int> <int> <int> <int> #>  1 A1          0     1     0     1 #>  2 A2          0     0     1     1 #>  3 A3          1     1     0     0 #>  4 A4          1     0     0     0 #>  5 A5          1     0     0     1 #>  6 A6          0     1     0     0 #>  7 A7          1     0     0     0 #>  8 A8          0     1     0     1 #>  9 A9          0     1     0     1 #> 10 A10         1     0     0     1 #> 11 A11         1     0     0     1 #> 12 A12         0     0     1     1 #> 13 A13         0     0     1     1 #> 14 A14         0     0     1     0 #> 15 A15         0     1     0     1 #> 16 A16         0     1     0     0 #> 17 A17         0     0     0     1 #> 18 A18         1     0     1     0 #> 19 A19         0     1     0     1 #> 20 A20         0     0     0     1"},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"specifying-a-dcm-for-estimation","dir":"Articles","previous_headings":"","what":"Specifying a DCM for Estimation","title":"Estimating diagnostic classification models","text":"measr, DCMs specified estimated using dcm_specify() dcm_estimate() functions, respectively. ’ll start estimating loglinear cognitive diagnostic model (LCDM). LCDM general DCM subsumes many DCM subtypes (Henson et al., 2009). First, specify model using Q-matrix (qmatrix). Note required argument dcm_specify() function. arguments provided, sensible defaults (described ) take care rest specification. Next, can specify column, , qmatrix contains item identifiers. variables present data, argument can omitted, measr assign identifiers based row number (.e., row 1 qmatrix becomes item 1). can specify type DCM want estimate. , ’ll choose LCDM measurement model, ’ll use unconstrained structural model.1 can pass model specification dcm_estimate(), along data (data). model specification, can specify column, , contains respondent identifiers data object. model estimation, option choose engine use, via backend argument. default backend backend = \"rstan\", use rstan package estimate model. Alternatively, can use cmdstanr package estimate model specifying backend = \"cmdstanr\". cmdstanr package works using local installation Stan estimate models, rather version pre-compiled rstan. backend chosen, can supply additional arguments specific estimating functions. example , specify 1,000 warm-iterations per chain, 500 post-warm-iterations per chain, 4 cores run chains parallel. full set options available rstan cmdstanr can found looking help pages ?rstan::sampling() ?cmdstanr::`model-method-sample`, respectively. Finally, estimating models can time intensive, can specify file. file specified, R object fitted model automatically saved specified file. specified file already exists, fitted model read back R, eliminating need re-estimate model.","code":"model_spec <- dcm_specify(qmatrix = sim_data$q_matrix, identifier = \"item_id\",                           measurement_model = lcdm(),                           structural_model = unconstrained())  model_spec #> A loglinear cognitive diagnostic model (LCDM) measuring 4 attributes with #> 20 items. #>  #> ℹ Attributes: #> • \"att1\" (7 items) #> • \"att2\" (8 items) #> • \"att3\" (5 items) #> • \"att4\" (13 items) #>  #> ℹ Attribute structure: #>   Unconstrained #>  #> ℹ Prior distributions: #>   intercept ~ normal(0, 2) #>   maineffect ~ lognormal(0, 1) #>   interaction ~ normal(0, 2) #>   `Vc` ~ dirichlet(1, 1, 1, 1) lcdm <- dcm_estimate(model_spec, data = sim_data$data, identifier = \"resp_id\",                      method = \"mcmc\", backend = \"cmdstanr\",                      iter_warmup = 1000, iter_sampling = 500,                      chains = 4, parallel_chains = 4,                      file = \"fits/sim-lcdm\")"},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"examining-parameter-estimates","dir":"Articles","previous_headings":"Specifying a DCM for Estimation","what":"Examining Parameter Estimates","title":"Estimating diagnostic classification models","text":"Now ’ve estimated model, let’s compare parameter estimates true values used generate data. can start looking estimates using measr_extract(). function extracts different aspects model estimated measr. , estimate column reports estimated value parameter measure associated error (.e., standard deviation posterior distribution). example, item A1 measures two attributes therefore four parameters: intercept, represents log-odds providing correct response respondent proficient neither attributes item measures (.e., att2 att4). main effect second attribute, represents increase log-odds providing correct response respondent proficient attribute. main effect fourth attribute, represents increase log-odds providing correct response respondent proficient attribute. interaction second fourth attributes, change log-odds respondent proficient attributes. can compare estimates used generate data. figure , parameters fall close dashed line, represents perfect agreement, indicating estimated model accurately estimating parameter values.  can also examine structural parameters, represent overall proportion respondents class. , see relatively strong agreement estimates model true generating values.","code":"item_parameters <- measr_extract(lcdm, what = \"item_param\") item_parameters #> # A tibble: 66 × 5 #>    item_id type        attributes coefficient       estimate #>    <chr>   <chr>       <chr>      <chr>           <rvar[1d]> #>  1 A1      intercept   NA         l1_0         -0.98 ± 0.099 #>  2 A1      maineffect  att2       l1_12         2.46 ± 0.154 #>  3 A1      maineffect  att4       l1_14         4.46 ± 0.313 #>  4 A1      interaction att2__att4 l1_224        0.16 ± 1.303 #>  5 A2      intercept   NA         l2_0         -2.41 ± 0.294 #>  6 A2      maineffect  att3       l2_13         4.00 ± 0.323 #>  7 A2      maineffect  att4       l2_14         3.82 ± 0.334 #>  8 A2      interaction att3__att4 l2_234       -3.59 ± 0.376 #>  9 A3      intercept   NA         l3_0         -2.01 ± 0.159 #> 10 A3      maineffect  att1       l3_11         2.22 ± 0.189 #> # ℹ 56 more rows"},{"path":[]},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"prior-distributions","dir":"Articles","previous_headings":"Customizing the Model Estimation Process","what":"Prior Distributions","title":"Estimating diagnostic classification models","text":"code define LCDM , specify prior distributions call dcm_specify(). default, measr uses following prior distributions LCDM: can see, main effect parameters get lognormal(0, 1) prior default. Different prior distributions can specified prior() function. example, can specify normal(0, 10) prior main effects : default, prior applied parameters class (.e., main effects). However, can also apply prior specific parameter. example, specify χ2 distribution 2 degrees freedom default prior main effects, exponential distribution rate 2 main effect attribute 1 just item 7. see parameters (including type coefficient) can specified, can pass model specification get_parameters(). distribution supported Stan language can used prior. list distributions available Stan documentation, linked ?prior() help page. Priors can defined estimating function, created time model estimated. example, following equivalent. set prior main effects truncated normal distribution lower bound 0. done main effects LCDM constrained positive ensure monotonicity model. Additionally note ’ve set method = \"optim\". means estimate model using Stan’s optimizer, rather using full Markov Chain Monte Carlo. Note prior still influences model using method = \"optim\", just using method = \"mcmc\" (default). priors used estimate model saved returned model object, can always go back see priors used unsure. can see new_lcdm model, specified normal prior used main effects, default priors still applied parameters explicitly state prior distribution.","code":"default_dcm_priors(measurement_model = lcdm()) #> # A tibble: 3 × 3 #>   type        coefficient prior           #>   <chr>       <chr>       <chr>           #> 1 intercept   NA          normal(0, 2)    #> 2 maineffect  NA          lognormal(0, 1) #> 3 interaction NA          normal(0, 2) prior(normal(0, 10), type = \"maineffect\") #> # A tibble: 1 × 3 #>   type       coefficient prior         #>   <chr>      <chr>       <chr>         #> 1 maineffect NA          normal(0, 10) c(prior(chi_square(2), type = \"maineffect\"),   prior(exponential(2), type = \"maineffect\", coefficient = \"l7_11\")) #> # A tibble: 2 × 3 #>   type       coefficient prior          #>   <chr>      <chr>       <chr>          #> 1 maineffect NA          chi_square(2)  #> 2 maineffect l7_11       exponential(2)  get_parameters(model_spec) #> # A tibble: 67 × 4 #>    item_id type        attributes coefficient #>    <chr>   <chr>       <chr>      <chr>       #>  1 A1      intercept   NA         l1_0        #>  2 A1      maineffect  att2       l1_12       #>  3 A1      maineffect  att4       l1_14       #>  4 A1      interaction att2__att4 l1_224      #>  5 A2      intercept   NA         l2_0        #>  6 A2      maineffect  att3       l2_13       #>  7 A2      maineffect  att4       l2_14       #>  8 A2      interaction att3__att4 l2_234      #>  9 A3      intercept   NA         l3_0        #> 10 A3      maineffect  att1       l3_11       #> # ℹ 57 more rows new_prior <- prior(normal(0, 15), type = \"maineffect\", lower_bound = 0)  new_spec <- dcm_specify(qmatrix = sim_data$q_matrix, identifier = \"item_id\",                         measurement_model = lcdm(),                         structural_model = unconstrained(),                         priors = new_prior)  new_spec <- dcm_specify(qmatrix = sim_data$q_matrix, identifier = \"item_id\",                         measurement_model = lcdm(),                         structural_model = unconstrained(),                         priors = prior(normal(0, 15), type = \"maineffect\",                                        lower_bound = 0))  # Estimate the updated model new_lcdm <- dcm_estimate(new_spec, data = sim_data$data, identifier = \"resp_id\",                          method = \"optim\", backend = \"cmdstanr\",                          file = \"fits/sim-lcdm-optim\") measr_extract(new_lcdm, \"prior\") #> # A tibble: 4 × 3 #>   type        coefficient prior                       #>   <chr>       <chr>       <chr>                       #> 1 maineffect  NA          normal(0, 15)T[0,]          #> 2 intercept   NA          normal(0, 2)                #> 3 interaction NA          normal(0, 2)                #> 4 structural  Vc          dirichlet(rep_vector(1, C))"},{"path":"https://measr.info/dev/articles/model-estimation.html","id":"subtype","dir":"Articles","previous_headings":"Customizing the Model Estimation Process","what":"Other DCM Sub-Types","title":"Estimating diagnostic classification models","text":"Although primary motivation measr provide researchers software makes LCDM readily accessible, popular DCM subtypes also supported. example, can estimate deterministic inputs, noisy “” gate (DINA, Junker & Sijtsma, 2001) deterministic inputs, noisy “” gate (DINO, Templin & Henson, 2006) models specifying different measurement_model dcm_specify() function. complete list currently supported measurement structural models, see ?dcmstan::`measurement-model` ?dcmstan::`structural-model`, respectively. Future development work continue add functionality DCM subtypes. specific subtype interested , like see supported, please open issue GitHub repository.","code":""},{"path":[]},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Evaluating diagnostic classification models","text":"demonstrate model fit functionality measr, ’ll use simulated data set used illustrate model estimation functionality. data set contains 2,000 respondents 20 items measure total 4 attributes, item measures 2 attributes. data generated loglinear cognitive diagnostic model (LCDM), general model subsumes many DCM subtypes (Henson et al., 2009). demonstrate model fit functionality, ’ll first fit LCDM deterministic-input, noisy “” gate (DINA) model (de la Torre & Douglas, 2004) data set order compare fit indices. LCDM used generate fake data, expect estimated LCDM model perform well. hand, DINA model places heavy constraints LCDM, therefore expect worse performance DINA model. details model estimation, see Estimating diagnostic classification models.","code":"library(tidyverse)  sim_data <- read_rds(\"data/simulated-data.rds\")  lcdm <- dcm_estimate(   dcm_spec = dcm_specify(qmatrix = sim_data$q_matrix, identifier = \"item_id\",                          measurement_model = lcdm()),   data = sim_data$data, identifier = \"resp_id\",   method = \"mcmc\", backend = \"cmdstanr\",   iter_warmup = 1000, iter_sampling = 500, chains = 4, parallel_chains = 4,   file = \"fits/sim-lcdm\" )  dina <- dcm_estimate(   dcm_spec = dcm_specify(qmatrix = sim_data$q_matrix, identifier = \"item_id\",                          measurement_model = dina()),   data = sim_data$data, identifier = \"resp_id\",   method = \"mcmc\", backend = \"cmdstanr\",   iter_warmup = 1000, iter_sampling = 500, chains = 4, parallel_chains = 4,   file = \"fits/sim-dina\" )"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"model-evaluation","dir":"Articles","previous_headings":"","what":"Model Evaluation","title":"Evaluating diagnostic classification models","text":"three major types evaluations supported measr. Absolute model fit Relative model fit (.e., model comparisons) Reliability discussed turn.","code":""},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"absolute-model-fit","dir":"Articles","previous_headings":"Model Evaluation","what":"Absolute Model Fit","title":"Evaluating diagnostic classification models","text":"Absolute model fit measures well estimated model fits observed data. One popular methods evaluating absolute model fit DCMs M2 statistic (Hansen et al., 2016; Liu et al., 2016). can calculate M2 statistics fit_m2() function. function returns data frame M2 statistic (m2), degrees freedom p-value associated M2 (df pval, respectively). p-value less .05 typically indicate poor model fit. expected example, estimated LCDM shows adequate model fit data (p > .05). fit_m2() also return information RMSEA SRMSR fit statistics. M2, RMSEA, SRMSR considered limited-information fit indices. example, M2 based univariate item statistics bivariate relationships items. Thus, capture aspects model fit higher-order relationships (e.g., triplets items). used fully Bayesian estimation models, can use posterior distributions provide another evaluation model fit can incorporate information. method known posterior predictive model check (PPMC). general process PPMCs follows: draw posterior distribution, generate synthetic data set using parameters values draw. synthetic data set calculate summary data. process creates posterior distribution summary. synthetic data sets generated parameter values posterior distribution, distribution data summary represents expect summary look like, estimated model correct true. Calculate data summary observed data set. Compare summary observed data posterior distribution. observed value falls within posterior distribution summary, evidence estimated model consistent observed data. hand, discrepancies observed value posteriors indicates inconsistencies. PPMCs can used evaluate model- item-level fit. model level, fit evaluated expected raw score distribution, described Park et al. (2015) Thompson (2019). item level, can evaluate fit examining expected conditional probabilities members class providing correct response (Sinharay & Almond, 2007; Thompson, 2019), well expected odds ratio pair items (Park et al., 2015; Sinharay et al., 2006). measr, PPMCs can calculated fit_ppmc(). Using fit_ppmc() can specify PPMCs calculate. example, estimate just model-level raw score check setting item_fit = NULL. fit_ppmc() returns list, element different PPMC. , specified one PPMC, get raw_score element back. obs_chisq raw score χ2 values observed data. see mean posterior distribution χ2, quantiles posterior distribution, posterior predictive p-value (ppp). ppp proportion posterior draws greater observed value. Values close 0 indicate poor fit. Values close 1 may indicate overfitting. LCDM used generate data, ’s surprising ppp approaching close 0.5 estimated model, model perfectly capturing data generating process (.e., observed data right middle estimated model expect). can also specify posterior quantiles returned. example, can calculate item-level odds ratios request quantiles result 90% credible interval. see similar output item-level indices: observed odds ratio item pair (obs_or), mean posterior distribution item pair (ppmc_mean), quantiles posterior specified, ppp. raw score distribution, ppp represents proportion posterior draws odds ratio greater observed value.","code":"fit_m2(lcdm) #> # A tibble: 1 × 8 #>      m2    df  pval rmsea ci_lower ci_upper `90% CI`     srmsr #>   <dbl> <int> <dbl> <dbl>    <dbl>    <dbl> <chr>        <dbl> #> 1  121.   129 0.672     0        0   0.0091 [0, 0.0091] 0.0166 fit_ppmc(lcdm, model_fit = \"raw_score\") #> $ppmc_raw_score #> # A tibble: 1 × 5 #>   obs_chisq ppmc_mean `2.5%` `97.5%`   ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <dbl> #> 1      24.0      23.7   10.9    40.9 0.452 fit_ppmc(lcdm, model_fit = NULL, item_fit = \"odds_ratio\",          probs = c(0.05, 0.95)) #> $ppmc_odds_ratio #> # A tibble: 190 × 7 #>    item_1 item_2 obs_or ppmc_mean  `5%` `95%`   ppp #>    <chr>  <chr>   <dbl>     <dbl> <dbl> <dbl> <dbl> #>  1 A1     A2      2.61       2.76 2.22   3.37 0.644 #>  2 A1     A3      2.04       1.96 1.60   2.37 0.344 #>  3 A1     A4      0.904      1.06 0.870  1.28 0.910 #>  4 A1     A5      1.99       2.10 1.69   2.57 0.628 #>  5 A1     A6      3.27       3.24 2.57   4.03 0.428 #>  6 A1     A7      0.966      1.05 0.864  1.25 0.747 #>  7 A1     A8      6.78       6.56 5.06   8.38 0.376 #>  8 A1     A9     10.1        9.76 7.56  12.4  0.359 #>  9 A1     A10     2.98       2.85 2.21   3.68 0.352 #> 10 A1     A11     2.98       3.06 2.50   3.71 0.550 #> # ℹ 180 more rows"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"relative-model-fit","dir":"Articles","previous_headings":"Model Evaluation","what":"Relative Model Fit","title":"Evaluating diagnostic classification models","text":"Relative fit measures used compare multiple competing models. case, estimate LCDM DINA model want compare model performs better. first note “better” necessarily mean “good.” Evidence one model performs better another evidence “good” fit absolute sense. absolute model fit indices can provide evidence adequate fit data. However, multiple models show adequate absolute fit, relative fit indices can used, along understanding constructs, select preferred model. Currently, Stan ecosystem supports two information criteria loo package can used relative fit indices: leave-one-(LOO) cross validation Pareto-smoothed importance sampling (Vehtari et al., 2017, 2022) widely applicable information criterion (WAIC) described Watanabe (2010). information criteria can calculated using associated functions loo package (.e., loo() waic()). , calculate LOO LCDM DINA models. isolation, output useful, indices meant facilitate model comparisons. can conduct model comparisons using loo_compare(), used comparing LOO WAIC estimates. output, model first row preferred model. subsequent rows, epld_diff column reports difference information criteria (case LOO) model row preferred model. se_diff column standard error difference model preferred model. Bengio & Grandvalet (2004) recommended cutoff 2.5 standard errors identifying preferred model. example, absolute value elpd_diff greater 45.1 × 2.5 = 112.8, conclude LCDM fits significantly better DINA model. expected outcome case, given data generation process results absolute model fit analysis. difference less 2.5 standard errors, conclude models fit equally well.","code":"lcdm_loo <- loo(lcdm) lcdm_loo #>  #> Computed from 2000 by 2000 log-likelihood matrix. #>  #>          Estimate    SE #> elpd_loo -21731.5 102.7 #> p_loo        77.8   1.2 #> looic     43463.0 205.4 #> ------ #> MCSE of elpd_loo is 0.2. #> MCSE and ESS estimates assume independent draws (r_eff=1). #>  #> All Pareto k estimates are good (k < 0.7). #> See help('pareto-k-diagnostic') for details.  dina_loo <- loo(dina) dina_loo #>  #> Computed from 2000 by 2000 log-likelihood matrix. #>  #>          Estimate    SE #> elpd_loo -23539.8  79.1 #> p_loo       886.9  18.9 #> looic     47079.5 158.3 #> ------ #> MCSE of elpd_loo is 0.6. #> MCSE and ESS estimates assume independent draws (r_eff=1). #>  #> All Pareto k estimates are good (k < 0.7). #> See help('pareto-k-diagnostic') for details. loo_compare(list(lcdm = lcdm_loo, dina = dina_loo)) #>      elpd_diff se_diff #> lcdm     0.0       0.0 #> dina -1808.3      45.1"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"reliability","dir":"Articles","previous_headings":"Model Evaluation","what":"Reliability","title":"Evaluating diagnostic classification models","text":"can also evaluate DCMs reliability. , ’s important understand accuracy consistency classifications made model. models estimated measr, estimates reliability can calculated using reliability(). several types reliability evidence provided output. indices reported, values can range 0 1, 1 represents perfect accuracy consistency. first type reliability output pattern-level reliability, described Cui et al. (2012). reliability describes accuracy (p_a) consistency (p_c) classification respondents overall profile proficiency assessed skills. example, 3-attribute assessment 8 possible profiles: [0,0,0], [1,0,0], [0,1,0], [0,0,1], [1,1,0], [1,0,1], [0,1,1], [1,1,1]. One option reporting results DCM-based assessment select profile likely respondent. pattern-level reliability metrics provide measure accuracy consistency type classification. hand, rather reporting results based overall likely profile, can assign proficiency individual attribute, build overall profile attribute-level decisions. type reporting may may result profile overall likely profile. scenario classifications made attribute level, need examine classification accuracy consistency individual attribute. models estimated measr, referred maximum posteriori (MAP) reliability, classifications based likely category attribute respondent. MAP values reported output described Johnson & Sinharay (2018). acc consist variables map_reliability$accuracy map_reliability_consistency tables, respectively, classification accuracy consistency metrics described Johnson & Sinharay (2018). paper, also compared metrics measures agreement (e.g., Cohen’s κ, Goodman Kruskal’s λ), also included output. Johnson & Sinharay (2018) also provide recommendations threshold values metric represent poor, fair, good, good, excellent reliability. Finally, rather reporting results classifications (e.g., proficient/proficient), results can also reported simply probability respondent proficient attribute. Thus, rather reporting accuracy consistency classification, report precision reported probability. referred expected posteriori (EAP) reliability, probability represents expected value attribute respondent. EAP values reported output (eap_reliability) described Johnson & Sinharay (2020) Templin & Bradshaw (2013). Templin & Bradshaw (2013) describe reliability index based restrictive assumption parallel forms (rho_tb). Johnson & Sinharay (2020) described generalized parallel forms reliability (rho_pf), along additional biserial (rho_bs), informational (rho_i) reliability indices. proficiency probabilities provided attribute level, EAP reliability estimates also provided attribute measured assessment. classification reliability indices, Johnson & Sinharay (2020) provide recommendations thresholds representing poor, fair, good, good, excellent reliability four EAP reliability indices.","code":"reliability(lcdm) #> $pattern_reliability #>       p_a       p_c  #> 0.7444377 0.6093438  #>  #> $map_reliability #> $map_reliability$accuracy #> # A tibble: 4 × 8 #>   attribute   acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>     <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 att1      0.931    0.857   0.244    0.862   0.977 0.929 0.933 #> 2 att2      0.980    0.955   0.944    0.960   0.998 0.981 0.979 #> 3 att3      0.835    0.633   0.650    0.659   0.869 0.882 0.777 #> 4 att4      0.966    0.931   0.395    0.932   0.994 0.968 0.964 #>  #> $map_reliability$consistency #> # A tibble: 4 × 10 #>   attribute consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>       <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 att1        0.873    0.737   0.860    0.745   0.921 0.868 0.877  0.898 #> 2 att2        0.960    0.909   0.935    0.919   0.992 0.955 0.964  0.970 #> 3 att3        0.761    0.423   0.623    0.507   0.718 0.796 0.711  0.771 #> 4 att4        0.936    0.870   0.932    0.871   0.980 0.935 0.936  0.948 #> # ℹ 1 more variable: pc_prime <dbl> #>  #>  #> $eap_reliability #> # A tibble: 4 × 5 #>   attribute rho_pf rho_bs rho_i rho_tb #>   <chr>      <dbl>  <dbl> <dbl>  <dbl> #> 1 att1       0.799  0.797 0.647  0.949 #> 2 att2       0.937  0.938 0.717  0.995 #> 3 att3       0.619  0.537 0.480  0.748 #> 4 att4       0.902  0.897 0.700  0.987"},{"path":"https://measr.info/dev/articles/model-evaluation.html","id":"storing-model-evaluations","dir":"Articles","previous_headings":"","what":"Storing Model Evaluations","title":"Evaluating diagnostic classification models","text":"followed along running code vignette, noticed model evaluations take significant amount computation time. means repeating calculations (e.g., didn’t assign output new new object, opened new R session) can time-consuming process. make analysis efficient, measr offers several functions can used add model evaluation metrics described vignette directly model object. specified file model estimated, updated model object model evaluation components automatically resave, ensuring don’t rerun computationally intensive tasks. three functions adding model evaluation components model object, correspond three types evaluation described vignette: add_fit(): Adds absolute model fit indices (.e., M2, PPMCs) add_criterion(): Adds relative model fit indices (.e., LOO, WAIC) add_reliability(): Adds reliability metrics three functions several arguments common. x: model add evaluation components . save: Whether resave model object file specified estimating model. default TRUE. overwrite: Whether overwrite existing evaluations. example, attempt add reliability metrics add_reliability(), metrics already added, reliability metrics recalculated overwrite existing metrics? default FALSE. Additionally, three functions ... argument passing additional arguments along relevant functions. example, want add PPMC absolute model fit indices, can specify types model- item-level fit indices calculate, just using fit_ppmc(). components added model, helper function, measr_extract(), can used pull relevant pieces output. example, can extract PPMC raw score results. addition, can also extract elements model, priors used estimation, estimated parameters like base rate membership class. complete list can extract measr_extract(), see ?measr_extract.","code":"lcdm <- add_fit(lcdm, method = \"ppmc\",                 model_fit = \"raw_score\",                 item_fit = \"odds_ratio\") #> Warning in file.remove(current_files[!current_files %in% new_paths]): #> cannot remove file #> '/Users/jakethompson/Documents/GIT/packages/measr/vignettes/articles/fits/sim-lcdm-1.csv', #> reason 'No such file or directory' #> Warning in file.remove(current_files[!current_files %in% new_paths]): #> cannot remove file #> '/Users/jakethompson/Documents/GIT/packages/measr/vignettes/articles/fits/sim-lcdm-2.csv', #> reason 'No such file or directory' #> Warning in file.remove(current_files[!current_files %in% new_paths]): #> cannot remove file #> '/Users/jakethompson/Documents/GIT/packages/measr/vignettes/articles/fits/sim-lcdm-3.csv', #> reason 'No such file or directory' #> Warning in file.remove(current_files[!current_files %in% new_paths]): #> cannot remove file #> '/Users/jakethompson/Documents/GIT/packages/measr/vignettes/articles/fits/sim-lcdm-4.csv', #> reason 'No such file or directory' #> Moved 4 files and set internal paths to new locations: #> - /home/runner/work/measr/measr/vignettes/articles/NA #> - /home/runner/work/measr/measr/vignettes/articles/NA #> - /home/runner/work/measr/measr/vignettes/articles/NA #> - /home/runner/work/measr/measr/vignettes/articles/NA measr_extract(lcdm, what = \"ppmc_raw_score\") #> # A tibble: 1 × 5 #>   obs_chisq ppmc_mean `2.5%` `97.5%`   ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <dbl> #> 1      24.0      23.7   10.9    40.9 0.452 measr_extract(lcdm, what = \"prior\") #> # A tibble: 4 × 3 #>   type        coefficient prior                       #>   <chr>       <chr>       <chr>                       #> 1 intercept   NA          normal(0, 2)                #> 2 maineffect  NA          lognormal(0, 1)             #> 3 interaction NA          normal(0, 2)                #> 4 structural  Vc          dirichlet(rep_vector(1, C))  measr_extract(lcdm, what = \"strc_param\") #> # A tibble: 16 × 2 #>    class            estimate #>    <chr>          <rvar[1d]> #>  1 [0,0,0,0]  0.059 ± 0.0069 #>  2 [1,0,0,0]  0.080 ± 0.0075 #>  3 [0,1,0,0]  0.063 ± 0.0065 #>  4 [0,0,1,0]  0.083 ± 0.0078 #>  5 [0,0,0,1]  0.052 ± 0.0086 #>  6 [1,1,0,0]  0.044 ± 0.0059 #>  7 [1,0,1,0]  0.051 ± 0.0066 #>  8 [1,0,0,1]  0.060 ± 0.0110 #>  9 [0,1,1,0]  0.083 ± 0.0078 #> 10 [0,1,0,1]  0.049 ± 0.0079 #> 11 [0,0,1,1]  0.081 ± 0.0100 #> 12 [1,1,1,0]  0.043 ± 0.0066 #> 13 [1,1,0,1]  0.044 ± 0.0095 #> 14 [1,0,1,1]  0.092 ± 0.0111 #> 15 [0,1,1,1]  0.047 ± 0.0085 #> 16 [1,1,1,1]  0.068 ± 0.0099"},{"path":[]},{"path":"https://measr.info/dev/articles/paper.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"measr: Bayesian psychometric measurement using Stan","text":"educational psychological research, often interested discrete latent states individuals responding assessment (e.g., proficiency non-proficiency educational standards, presence absence psychological disorder). Diagnostic classification models (DCMs; also called cognitive diagnostic models [CDMs]) type psychometric model facilitates inferences (Rupp et al., 2010; von Davier & Lee, 2019). DCMs multi-dimensional, meaning can classify respondents multiple latent attributes within profile skills. Q-matrix used define items assessment measure attribute. Using pre-defined latent profiles Q-matrix, DCMs estimate probability respondents profile, corresponding pattern proficiency, presence, attributes. means DCMs able provide fine-grained feedback specific skills may need additional instruction educational context, particular symptoms may contributing diagnosis psychological context. Finally, DCMs classifying respondents rather placing along performance continuum, models able achieve reliable results shorter test lengths (Templin & Bradshaw, 2013), reducing burden respondents. Given benefits, goal measr make DCMs accessible applied researchers practitioners providing simple interface estimating evaluating DCMs.","code":""},{"path":"https://measr.info/dev/articles/paper.html","id":"statement-of-need","dir":"Articles","previous_headings":"","what":"Statement of need","title":"measr: Bayesian psychometric measurement using Stan","text":"measr R package developed easily estimate evaluate DCMs applied settings. Despite ability DCMs provide reliable, fine-grained feedback specific skills, models widely used research operational programs. due large part limitations existing software estimating evaluating DCMs (Ravand & Baghaei, 2020; Sessoms & Henson, 2018). Typically, DCMs estimated maximum likelihood estimator evaluated using limited-information fit indices (e.g., Liu et al., 2016). approach taken using Mplus (e.g., Templin & Hoffman, 2013) popular R packages GDINA (Ma & de la Torre, 2020) CDM (George et al., 2016). However, name “limited-information” implies, methods look limited relationships items, univariate bivariate relationships. means higher-level relationships items evaluated (e.g., relationships triplets items). Bayesian estimation methods offer robust methods evaluating model fit posterior predictive checks (Park et al., 2015; Thompson, 2019). date, three R packages offer Bayesian estimation DCMs: dina (Culpepper, 2015), hmcdm (Zhang et al., 2023), blatent (Templin, 2020). However, packages estimate single type DCM, severely limiting generalizability wide range applications. measr package seeks overcome limitations existing software options serving interface Stan probabilistic programming language (Carpenter et al., 2017). Stan backend, measr can estimate wide variety DCMs. Primarily, measr supports estimation loglinear cognitive diagnostic model (LCDM). However, LCDM general DCM subsumes many subtypes (Henson et al., 2008), measr also supports DCMs deterministic inputs, noisy “” gate (DINA) model (de la Torre & Douglas, 2004) deterministic inputs, noisy “” gate (DINO) model (Templin & Henson, 2006). estimation, measr provides model evaluations using limited-information indices posterior predictive checks. providing straightforward estimation evaluation DCMs, measr makes models accessible practitioners applied researchers. Thus, measr, users get power Bayesian methods model evaluation, compatibility packages larger Stan ecosystem, user-friendly interface knowledge Stan language required. However, models estimated measr also include fitted Stan object, users can access familiar Stan prefer work object. Additionally, Stan code used estimate model also returned users familiar Stan language can use code starting point writing customized models.","code":""},{"path":"https://measr.info/dev/articles/paper.html","id":"acknowledgments","dir":"Articles","previous_headings":"","what":"Acknowledgments","title":"measr: Bayesian psychometric measurement using Stan","text":"research reported supported Institute Education Sciences, U.S. Department Education, Grant R305D210045 University Kansas. opinions expressed authors represent views Institute U.S. Department Education. grateful project advisory committee members provided feedback development R package: Russell Almond, Claudia Flowers, Robert Henson, Matthew Madison.","code":""},{"path":[]},{"path":"https://measr.info/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"W. Jake Thompson. Author, maintainer. Jeffrey Hoover. Author. Auburn Jimenez. Contributor. Nathan Jones. Contributor. Matthew Johnson. Copyright holder.           Authored code adapted measrdcm method `reliability()` . Copyright holder. . Funder.","code":""},{"path":"https://measr.info/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Thompson WJ (2023). “measr: Bayesian psychometric measurement using Stan.” Journal Open Source Software, 8(91), 5742. doi:10.21105/joss.05742.","code":"@Article{,   title = {{measr}: {Bayesian} psychometric measurement using {Stan}},   author = {W. Jake Thompson},   year = {2023},   journal = {Journal of Open Source Software},   volume = {8},   number = {91},   pages = {5742},   doi = {10.21105/joss.05742}, }"},{"path":"https://measr.info/dev/index.html","id":"measr-","dir":"","previous_headings":"","what":"Estimate Diagnostic Classification Models with Stan","title":"Estimate Diagnostic Classification Models with Stan","text":"Diagnostic classification models (DCMs) class psychometric models estimate respondent abilities profile proficiency pre-defined set skills, attributes. Despite utility DCMs providing fine-grained actionable feedback shorter assessments, widely used applied settings, part due lack user-friendly software. Using R Stan, measr (said: “measure”) simplifies process estimating evaluating DCMs. Users can specify different DCM subtypes, define prior distributions, estimate model using rstan cmdstanr interface Stan. can easily examine model parameters, calculate model fit metrics, compare competing models, evaluate reliability attributes.","code":""},{"path":"https://measr.info/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimate Diagnostic Classification Models with Stan","text":"can install released version measr CRAN : install development version measr GitHub use: measr based Stan, C++ compiler required. Windows, Rtools program comes C++ compiler. Mac, ’s recommended install Xcode. additional instructions help setting compilers, see RStan installation help page.","code":"install.packages(\"measr\") # install.packages(\"remotes\") remotes::install_github(\"wjakethompson/measr\")"},{"path":"https://measr.info/dev/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Estimate Diagnostic Classification Models with Stan","text":"can define DCM using dcm_specify(). function requires Q-matrix defining attributes measured item. also identify item identifier columns. arguments can specified customize type model estimate (e.g., type measurement structural model; see ?dcmstan::dcm_specify()). can estimate specified DCM using dcm_estimate(). supply specification data set, along respondent identifiers. dcm_specify(), arguments can specified customize model estimation process (e.g., estimation backend method; see ?dcm_estimate()). demonstrate measr’s functionality, example data sets available dcmdata package. use Examination Certificate Proficiency English (ECPE; Templin & Hoffman, 2013) data (see ?dcmdata::ecpe details). Note default, measr uses full Markov chain Monte Carlo (MCMC) estimation Stan, can time computationally intensive. quicker estimation, use Stan’s optimizer instead MCMC adding method = \"optim\" function call. However, please note functionality lost using optimizer (e.g., calculation model fit criteria requires use MCMC). model estimated, can add evaluate model fit. can done absolute model fit, relative model fit (information criteria), reliability indices. Model parameters, respondent classifications, results model fit analyses can extracted using measr_extract(). Contributions welcome. ensure smooth process, please review Contributing Guide. Please note measr project released Contributor Code Conduct. contributing project, agree abide terms.","code":"library(measr)  model_spec <- dcm_specify(dcmdata::ecpe_qmatrix, identifier = \"item_id\")  model <- dcm_estimate(dcm_spec = model_spec,                       data = dcmdata::ecpe_data, identifier = \"resp_id\",                       iter = 1000, warmup = 200, chains = 2, cores = 2) model <- add_fit(model, method = \"m2\") model <- add_criterion(model, criterion = \"loo\") model <- add_reliability(model)  measr_extract(model, \"m2\") #> # A tibble: 1 × 3 #>      m2    df     pval #>   <dbl> <int>    <dbl> #> 1  514.   325 1.17e-10"},{"path":"https://measr.info/dev/reference/aic-bic.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum likelihood based information criteria — aic","title":"Maximum likelihood based information criteria — aic","text":"Calculate information criteria diagnostic models estimated full Markov chain Monte Carlo (.e., method = \"optim\"). Available information include Akaike information criterion (AIC; Akaike, 1973) Bayesian information criterion (BIC; Schwarz, 1978).","code":""},{"path":"https://measr.info/dev/reference/aic-bic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum likelihood based information criteria — aic","text":"","code":"aic(x, ..., force = FALSE)  bic(x, ..., force = FALSE)"},{"path":"https://measr.info/dev/reference/aic-bic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum likelihood based information criteria — aic","text":"x measrdcm object estimated backend = \"optim\". ... Unused. force criterion already added model object add_criterion(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/aic-bic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum likelihood based information criteria — aic","text":"numeric value information criterion.","code":""},{"path":"https://measr.info/dev/reference/aic-bic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Maximum likelihood based information criteria — aic","text":"Akaike, H. (1973). Information theory extension maximum likelihood principle. B. N. Petrov & F. Csáki (Eds.), Proceedings Second International Symposium Information Theory (pp. 267-281). Akademiai Kiado. Schwarz, G. (1978). Estimating dimension model. Annals Statistics, 6(2), 461–464. doi:10.1214/aos/1176344136","code":""},{"path":"https://measr.info/dev/reference/aic-bic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum likelihood based information criteria — aic","text":"","code":"model_spec <- dcm_specify(qmatrix = dcmdata::mdm_qmatrix,                           identifier = \"item\") model <- dcm_estimate(dcm_spec = model_spec, data = dcmdata::mdm_data,                       identifier = \"respondent\", method = \"optim\",                       seed = 63277)  aic(model) #> [1] 707.0866  bic(model) #> [1] 733.689"},{"path":"https://measr.info/dev/reference/bayes_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayes factor for model comparisons — bayes_factor","title":"Bayes factor for model comparisons — bayes_factor","text":"Calculate Bayes factor model comparisons, represents posterior odds null hypothesis prior probability null model 0.5 (Jeffreys, 1935; Kass & Raftery, 1995). Consistent Bayesian reporting guidelines Kruschke (2021), calculate posterior probability null model variety prior probabilities, addition Bayes factor.","code":""},{"path":"https://measr.info/dev/reference/bayes_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayes factor for model comparisons — bayes_factor","text":"","code":"bayes_factor(   x,   ...,   model_names = NULL,   prior_prob = seq(0.02, 0.98, by = 0.02) )"},{"path":"https://measr.info/dev/reference/bayes_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayes factor for model comparisons — bayes_factor","text":"x measrdcm object. ... Additional measrdcm compared x. model_names Names given provided model comparison output. NULL (default), names parsed names objects passed comparison. prior_prob numeric vector prior probabilities null model used calculate posterior probability null model relative alternative model. See details information.","code":""},{"path":"https://measr.info/dev/reference/bayes_factor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayes factor for model comparisons — bayes_factor","text":"tibble one row per model comparison four columns. null_model: null model comparison. alt_model: alternative model comparison. bf: estimated Bayes factor. posterior_probs: nested list column, element element tibble two columns: prior_prob_null: prior probability null model correct. posterior_prob_null: posterior probability null model correct. list column can unnested tidyr::unnest() (see examples). prior_prob NULL, posterior_probs column excluded returned object.","code":""},{"path":"https://measr.info/dev/reference/bayes_factor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayes factor for model comparisons — bayes_factor","text":"Bayes factors calculated possible pairwise comparisons models provided x .... comparison, one model identified null model, alternative. distinction terribly meaningful calculation standpoint, probabilities alternative model simply 1 minus null probabilities. want particular models labeled \"null\", determination made order models sent function. , x always null model. first model included ... alternative model compared x null model compared models included .... Similarly, second model included ... alternative model compared x first model included ... null model comparisons. prior_prob used specify vector possible prior probabilities null model. used conjunction Bayes factor determine posterior model probability null model, relative alternative model. posterior probability alternative model can calculated 1 minus null model's posterior probability. may specify specific prior probability, specify range possibilities construct graph similar Kruschke's (2021) Figure 1. probabilities can interpreted , \"prior probability {prior_prob_null}, posterior {posterior_prob_null}\" (1 minus alternative model).","code":""},{"path":"https://measr.info/dev/reference/bayes_factor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayes factor for model comparisons — bayes_factor","text":"Jeffreys, H. (1935). tests significance, treated theory probability. Mathematical Proceedings Cambridge Philosophical Society, 31(2), 203-222. doi:10.1017/S030500410001330X Kass, R. E., & Raftery, . E. (1995). Bayes factors. Journal American Statistical Association, 90(430), 773-795. doi:10.1080/01621459.1995.10476572 Kruschke, J. K. (2021). Bayesian analysis reporting guidelines. Nature, 5, 1282-1291. doi:10.1038/s41562-021-01177-7","code":""},{"path":"https://measr.info/dev/reference/bayes_factor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayes factor for model comparisons — bayes_factor","text":"","code":"mdm_dina <- dcm_estimate(   dcm_specify(dcmdata::mdm_qmatrix, identifier = \"item\",               measurement_model = dina()),   data = dcmdata::mdm_data, missing = NA, identifier = \"respondent\",   method = \"mcmc\", seed = 63277, backend = \"rstan\",   iter = 700, warmup = 500, chains = 2, refresh = 0 ) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess  mdm_dino <- dcm_estimate(   dcm_specify(dcmdata::mdm_qmatrix, identifier = \"item\",               measurement_model = dino()),   data = dcmdata::mdm_data, missing = NA, identifier = \"respondent\",   method = \"mcmc\", seed = 63277, backend = \"rstan\",   iter = 700, warmup = 500, chains = 2, refresh = 0 ) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess  bf <- bayes_factor(mdm_dina, mdm_dino) bf #> # A tibble: 1 × 4 #>   null_model alt_model    bf posterior_probs   #>   <chr>      <chr>     <dbl> <list>            #> 1 mdm_dina   mdm_dino  0.972 <tibble [49 × 2]>  tidyr::unnest(bf, \"posterior_probs\") #> # A tibble: 49 × 5 #>    null_model alt_model    bf prior_prob_null posterior_prob_null #>    <chr>      <chr>     <dbl>           <dbl>               <dbl> #>  1 mdm_dina   mdm_dino  0.972            0.02              0.0212 #>  2 mdm_dina   mdm_dino  0.972            0.04              0.0424 #>  3 mdm_dina   mdm_dino  0.972            0.06              0.0635 #>  4 mdm_dina   mdm_dino  0.972            0.08              0.0845 #>  5 mdm_dina   mdm_dino  0.972            0.1               0.106  #>  6 mdm_dina   mdm_dino  0.972            0.12              0.127  #>  7 mdm_dina   mdm_dino  0.972            0.14              0.147  #>  8 mdm_dina   mdm_dino  0.972            0.16              0.168  #>  9 mdm_dina   mdm_dino  0.972            0.18              0.189  #> 10 mdm_dina   mdm_dino  0.972            0.2               0.210  #> # ℹ 39 more rows"},{"path":"https://measr.info/dev/reference/cdi.html","id":null,"dir":"Reference","previous_headings":"","what":"Item, attribute, and test-level discrimination indices — cdi","title":"Item, attribute, and test-level discrimination indices — cdi","text":"cognitive diagnostic index (CDI) measure well assessment able distinguish attribute profiles. index originally proposed Henson & Douglas (2005) item- test-level discrimination, expanded Henson et al. (2008) include attribute-level discrimination indices.","code":""},{"path":"https://measr.info/dev/reference/cdi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Item, attribute, and test-level discrimination indices — cdi","text":"","code":"cdi(model, weight_prevalence = TRUE)"},{"path":"https://measr.info/dev/reference/cdi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Item, attribute, and test-level discrimination indices — cdi","text":"model estimated model evaluated. weight_prevalence Logical indicating whether discrimination indices weighted prevalence attribute profiles. See details additional information.","code":""},{"path":"https://measr.info/dev/reference/cdi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Item, attribute, and test-level discrimination indices — cdi","text":"list two elements: item_discrimination: tibble one row per item containing CDI item relevant attributes. test_discrimination: tibble one row containing total CDI assessment attribute.","code":""},{"path":"https://measr.info/dev/reference/cdi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Item, attribute, and test-level discrimination indices — cdi","text":"Henson et al. (2008) described two attribute-level discrimination indices, \\(\\mathbf{d}_{()\\mathbf{\\cdot}}\\) (Equation 8) \\(\\mathbf{d}_{(B)\\mathbf{\\cdot}}\\) (Equation 13), similar sum item-level discrimination indices. cases, item-level discrimination indices calculated average Kullback-Leibler information pairs attributes profiles item. item-level indices summed achieve test-level discrimination index attribute, test overall. However, whereas \\(\\mathbf{d}_{()\\mathbf{\\cdot}}\\) unweighted average Kullback-Leibler information, \\(\\mathbf{d}_{(B)\\mathbf{\\cdot}}\\) weighted average, weight defined prevalence profile (.e., measr_extract(model, = \"strc_param\")).","code":""},{"path":"https://measr.info/dev/reference/cdi.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Item, attribute, and test-level discrimination indices — cdi","text":"Henson, R., & Douglas, J. (2005). Test construction cognitive diagnosis. Applied Psychological Measurement, 29(4), 262-277. doi:10.1177/0146621604272623 Henson, R., Roussos, L., Douglas, J., & Xuming, H. (2008). Cognitive diagnostic attribute-level discrimination indices. Applied Psychological Measurement, 32(4), 275-288. doi:10.1177/0146621607302478","code":""},{"path":"https://measr.info/dev/reference/cdi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Item, attribute, and test-level discrimination indices — cdi","text":"","code":"rstn_ecpe_lcdm <- dcm_estimate(   dcm_specify(dcmdata::ecpe_qmatrix, identifier = \"item_id\"),   data = dcmdata::ecpe_data, missing = NA, identifier = \"resp_id\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  cdi(rstn_ecpe_lcdm) #> $item_discrimination #> # A tibble: 28 × 5 #>     item overall morphosyntactic cohesive lexical #>    <int>   <dbl>           <dbl>    <dbl>   <dbl> #>  1     1  0.0615          0.0435   0.0618  0      #>  2     2  0.0483          0        0.1000  0      #>  3     3  0.0917          0.136    0       0.0462 #>  4     4  0.142           0        0       0.294  #>  5     5  0.0929          0        0       0.192  #>  6     6  0.0845          0        0       0.175  #>  7     7  0.189           0.277    0       0.0756 #>  8     8  0.0660          0        0.137   0      #>  9     9  0.0720          0        0       0.149  #> 10    10  0.191           0.397    0       0      #> # ℹ 18 more rows #>  #> $test_discrimination #> # A tibble: 1 × 4 #>   overall morphosyntactic cohesive lexical #>     <dbl>           <dbl>    <dbl>   <dbl> #> 1    3.42            2.53    0.872    3.48 #>"},{"path":"https://measr.info/dev/reference/dcm_estimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Bayesian diagnostic classification models — dcm_estimate","title":"Fit Bayesian diagnostic classification models — dcm_estimate","text":"Estimate diagnostic classification models (DCMs; also known cognitive diagnostic models) using 'Stan'. Models can estimated using Stan's optimizer, full Markov chain Monte Carlo (MCMC).","code":""},{"path":"https://measr.info/dev/reference/dcm_estimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Bayesian diagnostic classification models — dcm_estimate","text":"","code":"dcm_estimate(   dcm_spec,   data,   missing = NA,   identifier = NULL,   method = c(\"mcmc\", \"optim\"),   backend = getOption(\"measr.backend\", \"rstan\"),   file = NULL,   file_refit = getOption(\"measr.file_refit\", \"never\"),   ... )"},{"path":"https://measr.info/dev/reference/dcm_estimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Bayesian diagnostic classification models — dcm_estimate","text":"dcm_spec DCM specification created dcm_specify(). data Response data. data frame 1 row per respondent 1 column per item. missing R expression specifying missing data data coded (e.g., NA, \".\", -99, etc.). default NA. identifier Optional. Variable name column data contains respondent identifiers. NULL (default) indicates identifiers present data, row numbers used identifiers. method Estimation method. Options \"mcmc\", uses Stan's sampling method, \"optim\", uses Stan's optimizer. backend Character string naming package use backend fitting Stan model. Options \"rstan\" (default) \"cmdstanr\". Can set globally current R session via \"measr.backend\" option (see options()). Details rstan cmdstanr packages available https://mc-stan.org/rstan/ https://mc-stan.org/cmdstanr/, respectively. file Either NULL (default) character string. character string, fitted model object saved .rds object using saveRDS() using supplied character string. .rds extension automatically added. specified file already exists, measr load previously saved model. Unless file_refit specified, model refit. file_refit Controls saved model refit. Options \"never\", \"always\", \"on_change\". Can set globally current R session via \"measr.file_refit\" option (see options()). \"never\" (default), fitted model always loaded file exists, model fitting skipped. \"always\", model always refitted, regardless whether file exists. \"on_change\", model refit dcm_spec, data, method, backend specified different saved file. ... Additional arguments passed Stan. backend = \"rstan\", arguments passed rstan::sampling() rstan::optimizing(). backend = \"cmdstanr\", arguments passed $sample() $optimize() methods CmdStanModel class.","code":""},{"path":"https://measr.info/dev/reference/dcm_estimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Bayesian diagnostic classification models — dcm_estimate","text":"measrdcm object.","code":""},{"path":"https://measr.info/dev/reference/dcm_estimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Bayesian diagnostic classification models — dcm_estimate","text":"","code":"model_spec <- dcm_specify(qmatrix = dcmdata::mdm_qmatrix,                           identifier = \"item\") model <- dcm_estimate(dcm_spec = model_spec, data = dcmdata::mdm_data,                       identifier = \"respondent\", method = \"optim\",                       seed = 63277)"},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior predictive model checks for assessing model fit — fit_ppmc","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"models estimated method = \"mcmc\", use posterior distributions compute expected distributions fit statistics compare values observed data.","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"","code":"fit_ppmc(   x,   ...,   model_fit = NULL,   item_fit = NULL,   ndraws = NULL,   probs = c(0.025, 0.975),   return_draws = 0,   force = FALSE )"},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"x estimated model object (e.g., dcm_estimate()). ... Unused. future extensions. model_fit posterior predictive model checks compute evaluation model-level fit. NULL, model-level checks computed. See details. item_fit posterior predictive model checks compute evaluation item-level fit. NULL, item-level checks computed. See details. ndraws number posterior draws base checks . Must less equal total number posterior draws retained estimated model. NULL (default) total number estimated model used. probs percentiles computed stats::quantile() function summarizing posterior distribution fit statistic. return_draws Number posterior draws specified fit statistic returned. affect calculation posterior predictive checks, can useful visualizing fit statistics. Must less ndraws (total number draws ndraws = NULL). 0 (default), summaries posterior returned (individual samples). force requested PPMCs already added model object using add_fit(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"list two elements, \"model_fit\" \"item_fit\". either model_fit = NULL item_fit = NULL function call, one-element list, null criteria excluded. list element, list one element specified PPMC containing tibble. example item_fit = c(\"conditional_prob\", \"odds_ratio\"), \"item_fit\" element list length two, element tibble containing results PPMC. tibbles follow general structure: obs_{ppmc}: value relevant statistic observed data. ppmc_mean: mean ndraws posterior samples calculated given statistic. Quantile columns: 1 column value probs, providing corresponding quantiles ndraws posterior samples calculated given statistic. samples: list column, element contains vector length return_draws, representing samples posterior distribution calculated statistic. column excluded return_draws = 0. ppp: posterior predictive p-value. proportion posterior samples calculated statistic greater observed value. Values close 0 1 indicate incompatibility fitted model observed data.","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"Posterior predictive model checks (PPMCs) use posterior distribution estimated model compute different statistics. creates expected distribution given statistic, estimated parameters correct. compute statistic observed data compare observed value expected distribution. Observed values fall outside expected distributions indicate incompatibility estimated model observed data. DCMs, currently support PPMCs model item level. model level, calculate expected raw score distribution (model_fit = \"raw_score\") described Thompson (2019) Park et al. (2015). item level, can calculate conditional probability respondent class provides correct response (item_fit = \"conditional_prob\") described Thompson (2019) Sinharay & Almond (2007) overall proportion correct item (item_fit = \"pvalue\"), described Thompson (2019). can also calculate odds ratio pair items (item_fit = \"odds_ratio\") described Park et al. (2015) Sinharay et al. (2006).","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"Park, J. Y., Johnson, M. S., Lee, Y-S. (2015). Posterior predictive model checks cognitive diagnostic models. International Journal Quantitative Research Education, 2(3-4), 244-264. doi:10.1504/IJQRE.2015.071738 Sinharay, S., & Almond, R. G. (2007). Assessing fit cognitive diagnostic models. Educational Psychological Measurement, 67(2), 239-257. doi:10.1177/0013164406292025 Sinharay, S., Johnson, M. S., & Stern, H. S. (2006). Posterior predictive assessment item response theory models. Applied Psychological Measurement, 30(4), 298-321. doi:10.1177/0146621605285517 Thompson, W. J. (2019). Bayesian psychometrics diagnostic assessments: proof concept (Research Report . 19-01). University Kansas; Accessible Teaching, Learning, Assessment Systems. doi:10.35542/osf.io/jzqs8","code":""},{"path":"https://measr.info/dev/reference/fit_ppmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior predictive model checks for assessing model fit — fit_ppmc","text":"","code":"mdm_dina <- dcm_estimate(   dcm_specify(dcmdata::mdm_qmatrix, identifier = \"item\",               measurement_model = dina()),   data = dcmdata::mdm_data, missing = NA, identifier = \"respondent\",   method = \"mcmc\", seed = 63277, backend = \"rstan\",   iter = 700, warmup = 500, chains = 2, refresh = 0 ) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess  fit_ppmc(mdm_dina, model_fit = \"raw_score\") #> $ppmc_raw_score #> # A tibble: 1 × 5 #>   obs_chisq ppmc_mean `2.5%` `97.5%`   ppp #>       <dbl>     <dbl>  <dbl>   <dbl> <dbl> #> 1      5.80      6.15  0.974    15.8 0.405 #>"},{"path":"https://measr.info/dev/reference/log_mll.html","id":null,"dir":"Reference","previous_headings":"","what":"Log marginal likelihood calculation — log_mll","title":"Log marginal likelihood calculation — log_mll","text":"Calculate log marginal likelihood bridge sampling (Meng & Wong, 1996). wrapper around bridgesampling::bridge_sampler(). Therefore, log marginal likelihood calculation currently available models estimated {rstan} using MCMC.","code":""},{"path":"https://measr.info/dev/reference/log_mll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log marginal likelihood calculation — log_mll","text":"","code":"log_mll(x, ..., force = FALSE)"},{"path":"https://measr.info/dev/reference/log_mll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log marginal likelihood calculation — log_mll","text":"x measrdcm object estimated backend = \"optim\". ... Unused. force criterion already added model object add_criterion(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/log_mll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log marginal likelihood calculation — log_mll","text":"estimate log marginal likelihood.","code":""},{"path":"https://measr.info/dev/reference/log_mll.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Log marginal likelihood calculation — log_mll","text":"Meng, X.-L., & Wong, W. H. (1996). Simulating ratios normalizing constants via simple identity: theoretical exploration. Statistical Sinica, 6(4), 831-860. https://www.jstor.org/stable/24306045","code":""},{"path":"https://measr.info/dev/reference/log_mll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log marginal likelihood calculation — log_mll","text":"","code":"model_spec <- dcm_specify(qmatrix = dcmdata::mdm_qmatrix,                           identifier = \"item\") model <- dcm_estimate(dcm_spec = model_spec, data = dcmdata::mdm_data,                       identifier = \"respondent\", method = \"mcmc\",                       seed = 63277) #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.00013 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.3 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 4000 [  0%]  (Warmup) #> Chain 1: Iteration:  400 / 4000 [ 10%]  (Warmup) #> Chain 1: Iteration:  800 / 4000 [ 20%]  (Warmup) #> Chain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup) #> Chain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup) #> Chain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup) #> Chain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling) #> Chain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling) #> Chain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling) #> Chain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling) #> Chain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling) #> Chain 1: Iteration: 4000 / 4000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 7.398 seconds (Warm-up) #> Chain 1:                7.26 seconds (Sampling) #> Chain 1:                14.658 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 0.000125 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.25 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 4000 [  0%]  (Warmup) #> Chain 2: Iteration:  400 / 4000 [ 10%]  (Warmup) #> Chain 2: Iteration:  800 / 4000 [ 20%]  (Warmup) #> Chain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup) #> Chain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup) #> Chain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup) #> Chain 2: Iteration: 2001 / 4000 [ 50%]  (Sampling) #> Chain 2: Iteration: 2400 / 4000 [ 60%]  (Sampling) #> Chain 2: Iteration: 2800 / 4000 [ 70%]  (Sampling) #> Chain 2: Iteration: 3200 / 4000 [ 80%]  (Sampling) #> Chain 2: Iteration: 3600 / 4000 [ 90%]  (Sampling) #> Chain 2: Iteration: 4000 / 4000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 7.556 seconds (Warm-up) #> Chain 2:                9.011 seconds (Sampling) #> Chain 2:                16.567 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 0.000125 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.25 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 4000 [  0%]  (Warmup) #> Chain 3: Iteration:  400 / 4000 [ 10%]  (Warmup) #> Chain 3: Iteration:  800 / 4000 [ 20%]  (Warmup) #> Chain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup) #> Chain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup) #> Chain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup) #> Chain 3: Iteration: 2001 / 4000 [ 50%]  (Sampling) #> Chain 3: Iteration: 2400 / 4000 [ 60%]  (Sampling) #> Chain 3: Iteration: 2800 / 4000 [ 70%]  (Sampling) #> Chain 3: Iteration: 3200 / 4000 [ 80%]  (Sampling) #> Chain 3: Iteration: 3600 / 4000 [ 90%]  (Sampling) #> Chain 3: Iteration: 4000 / 4000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 7.42 seconds (Warm-up) #> Chain 3:                6.114 seconds (Sampling) #> Chain 3:                13.534 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 0.00013 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.3 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 4000 [  0%]  (Warmup) #> Chain 4: Iteration:  400 / 4000 [ 10%]  (Warmup) #> Chain 4: Iteration:  800 / 4000 [ 20%]  (Warmup) #> Chain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup) #> Chain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup) #> Chain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup) #> Chain 4: Iteration: 2001 / 4000 [ 50%]  (Sampling) #> Chain 4: Iteration: 2400 / 4000 [ 60%]  (Sampling) #> Chain 4: Iteration: 2800 / 4000 [ 70%]  (Sampling) #> Chain 4: Iteration: 3200 / 4000 [ 80%]  (Sampling) #> Chain 4: Iteration: 3600 / 4000 [ 90%]  (Sampling) #> Chain 4: Iteration: 4000 / 4000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 7.704 seconds (Warm-up) #> Chain 4:                7.127 seconds (Sampling) #> Chain 4:                14.831 seconds (Total) #> Chain 4:  #> Warning: There were 2 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems  log_mll(model) #> [1] -346.3355"},{"path":"https://measr.info/dev/reference/loglik_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the log-likelihood of an estimated model — loglik_array","title":"Extract the log-likelihood of an estimated model — loglik_array","text":"loglik_array() methods measrdcm objects calculates log-likelihood estimated model via generated quantities functionality Stan returns draws log_lik parameter.","code":""},{"path":"https://measr.info/dev/reference/loglik_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the log-likelihood of an estimated model — loglik_array","text":"","code":"loglik_array(model, ...)"},{"path":"https://measr.info/dev/reference/loglik_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the log-likelihood of an estimated model — loglik_array","text":"model measrdcm object. ... Unused. future extensions.","code":""},{"path":"https://measr.info/dev/reference/loglik_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the log-likelihood of an estimated model — loglik_array","text":"\"draws_array\" object containing log-likelihood estimates model.","code":""},{"path":"https://measr.info/dev/reference/loo-waic.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative fit for Bayesian models — loo-waic","title":"Relative fit for Bayesian models — loo-waic","text":"models estimated MCMC, relative model fit comparisons can made using LOO-CV WAIC indicates (Vehtari et al., 2017). functions wrappers loo package. See loo package vignettes details implementation.","code":""},{"path":"https://measr.info/dev/reference/loo-waic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative fit for Bayesian models — loo-waic","text":"","code":"# S3 method for class '`measr::measrdcm`' loo(x, ..., r_eff = NA, force = FALSE)  # S3 method for class '`measr::measrdcm`' waic(x, ..., force = FALSE)  # S3 method for class '`measr::measrdcm`' loo_compare(x, ..., criterion = c(\"loo\", \"waic\"), model_names = NULL)"},{"path":"https://measr.info/dev/reference/loo-waic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative fit for Bayesian models — loo-waic","text":"x measrdcm object. ... loo() waic(), additional arguments passed loo::loo.array() loo::waic.array(), respectively. loo_compare(), additional measrdcm objects compared x. r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalized importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper functions help computing r_eff. force LOO criterion already added model object add_criterion(), recalculated. Default FALSE. criterion name criterion extracted x comparison. model_names Names given provided model comparison output. NULL (default), names parsed names objects passed comparison.","code":""},{"path":"https://measr.info/dev/reference/loo-waic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative fit for Bayesian models — loo-waic","text":"loo() waic(), information criteria returned loo::loo.array() loo::waic.array(), respectively. loo_compare(), criterion comparison returned loo::loo_compare().","code":""},{"path":"https://measr.info/dev/reference/loo-waic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Relative fit for Bayesian models — loo-waic","text":"Vehtari, ., Gelman, ., & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing, 27(5), 1413-1432. doi:10.1007/s11222-016-9696-4","code":""},{"path":"https://measr.info/dev/reference/m2.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the M2 fit statistic for diagnostic classification models — m2","title":"Estimate the M2 fit statistic for diagnostic classification models — m2","text":"diagnostic classification models, M2 statistic calculated described Hansen et al. (2016) Liu et al. (2016).","code":""},{"path":"https://measr.info/dev/reference/m2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the M2 fit statistic for diagnostic classification models — m2","text":"","code":"# S3 method for class '`measr::measrdcm`' fit_m2(model, ..., ci = 0.9, force = FALSE)"},{"path":"https://measr.info/dev/reference/m2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the M2 fit statistic for diagnostic classification models — m2","text":"model estimated diagnostic classification model. ... Unused, extensibility. ci confidence interval RMSEA. force M2 already saved model object add_fit(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/m2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the M2 fit statistic for diagnostic classification models — m2","text":"data frame created dcm2::fit_m2().","code":""},{"path":"https://measr.info/dev/reference/m2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate the M2 fit statistic for diagnostic classification models — m2","text":"Hansen, M., Cai, L., Monroe, S., & Li, Z. (2016). Limited-information goodness--fit testing diagnostic classification item response models. British Journal Mathematical Statistical Psychology, 69(3), 225-252. doi:10.1111/bmsp.12074 Liu, Y., Tian, W., & Xin, T. (2016). application M2 statistic evaluate fit cognitive diagnostic models. Journal Educational Behavioral Statistics, 41(1), 3-26. doi:10.3102/1076998615621293","code":""},{"path":"https://measr.info/dev/reference/m2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the M2 fit statistic for diagnostic classification models — m2","text":"","code":"rstn_mdm_lcdm <- dcm_estimate(   dcm_specify(dcmdata::mdm_qmatrix, identifier = \"item\"),   data = dcmdata::mdm_data, missing = NA, identifier = \"respondent\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  fit_m2(rstn_mdm_lcdm) #> # A tibble: 1 × 8 #>       m2    df  pval rmsea ci_lower ci_upper `90% CI`     srmsr #>    <dbl> <int> <dbl> <dbl>    <dbl>    <dbl> <chr>        <dbl> #> 1 0.0219     1 0.882     0        0    0.110 [0, 0.1102] 0.0456"},{"path":"https://measr.info/dev/reference/measr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"measr: Bayesian Psychometric Measurement Using 'Stan' — measr-package","title":"measr: Bayesian Psychometric Measurement Using 'Stan' — measr-package","text":"Estimate diagnostic classification models (also called cognitive diagnostic models) 'Stan'. Diagnostic classification models confirmatory latent class models, described Rupp et al. (2010, ISBN: 978-1-60623-527-0). Automatically generate 'Stan' code general loglinear cognitive diagnostic diagnostic model proposed Henson et al. (2009) doi:10.1007/s11336-008-9089-5  subtypes introduce additional model constraints. Using generated 'Stan' code, estimate model evaluate model's performance using model fit indices, information criteria, reliability metrics.","code":""},{"path":[]},{"path":"https://measr.info/dev/reference/measr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"measr: Bayesian Psychometric Measurement Using 'Stan' — measr-package","text":"Maintainer: W. Jake Thompson wjakethompson@gmail.com (ORCID) contributors: Nathan Jones jonesnateb@gmail.com (ORCID) [contributor] Matthew Johnson (Provided code adapted reliability.measrdcm()) [copyright holder] University Kansas [copyright holder] Institute Education Sciences [funder]","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Bayesian diagnostic classification models — measr_dcm","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"measr_dcm() deprecated favor dcm_estimate(). Please use dcm_estimate(), measr_dcm() removed future release.","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"","code":"measr_dcm(   data,   missing = NA,   qmatrix,   resp_id = NULL,   item_id = NULL,   type = c(\"lcdm\", \"dina\", \"dino\", \"crum\"),   max_interaction = Inf,   attribute_structure = c(\"unconstrained\", \"independent\"),   method = c(\"mcmc\", \"optim\"),   prior = NULL,   backend = getOption(\"measr.backend\", \"rstan\"),   file = NULL,   file_refit = getOption(\"measr.file_refit\", \"never\"),   ... )"},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"data Response data. data frame 1 row per respondent 1 column per item. missing R expression specifying missing data data coded (e.g., NA, \".\", -99, etc.). default NA. qmatrix Q-matrix. data frame 1 row per item 1 column per attribute. cells either 0 (item measure attribute) 1 (item measure attribute). resp_id Optional. Variable name column data contains respondent identifiers. NULL (default) indicates identifiers present data, row numbers used identifiers. item_id Optional. Variable name column qmatrix contains item identifiers. NULL (default) indicates identifiers present Q-matrix. case, column names data (excluding column specified resp_id) used item identifiers. NULL also assumes order rows Q-matrix order columns data (.e., item row 1 qmatrix item column 1 data, excluding resp_id). type Type DCM estimate. Must one \"lcdm\", \"dina\", \"dino\", \"crum\". max_interaction type = \"lcdm\", highest level interaction estimate. default estimate possible interactions. example, item measures 4 attributes 4 main effects, 6 two-way interactions, 4 three-way interactions, 1 four-way interaction. Setting max_interaction = 2 result estimating main effects two-way interactions, excluding three- four- way interactions. attribute_structure Structural model specification. Must one \"unconstrained\" \"independent\". \"unconstrained\" makes assumptions relationships attributes, whereas \"independent\" assumes proficiency statuses attributes independent . method Estimation method. Options \"mcmc\", uses Stan's sampling method, \"optim\", uses Stan's optimizer. prior prior object. NULL, default priors used, specified dcmstan::default_dcm_priors(). backend Character string naming package use backend fitting Stan model. Options \"rstan\" (default) \"cmdstanr\". Can set globally current R session via \"measr.backend\" option (see options()). Details rstan cmdstanr packages available https://mc-stan.org/rstan/ https://mc-stan.org/cmdstanr/, respectively. file Either NULL (default) character string. character string, fitted model object saved .rds object using saveRDS() using supplied character string. .rds extension automatically added. specified file already exists, measr load previously saved model. Unless file_refit specified, model refit. file_refit Controls saved model refit. Options \"never\", \"always\", \"on_change\". Can set globally current R session via \"measr.file_refit\" option (see options()). \"never\" (default), fitted model always loaded file exists, model fitting skipped. \"always\", model always refitted, regardless whether file exists. \"on_change\", model refit data, prior, method specified different saved file. ... Additional arguments passed Stan. backend = \"rstan\", arguments passed rstan::sampling() rstan::optimizing(). backend = \"cmdstanr\", arguments passed sample optimize methods CmdStanModel class.","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"measrdcm object.","code":""},{"path":"https://measr.info/dev/reference/measr_dcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Bayesian diagnostic classification models — measr_dcm","text":"","code":"rstn_mdm_lcdm <- measr_dcm(   data = mdm_data, missing = NA, qmatrix = mdm_qmatrix,   resp_id = \"respondent\", item_id = \"item\", type = \"lcdm\",   method = \"optim\", seed = 63277, backend = \"rstan\" ) #> Warning: `measr_dcm()` was deprecated in measr 2.0.0. #> ℹ This is a limited version of dcm_estimate(); use it instead. #> Error: object 'mdm_qmatrix' not found"},{"path":"https://measr.info/dev/reference/measr_examples.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine if code is executed interactively or in pkgdown — measr_examples","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"Used determining examples run CRAN, can run pkgdown website.","code":""},{"path":"https://measr.info/dev/reference/measr_examples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"","code":"measr_examples()"},{"path":"https://measr.info/dev/reference/measr_examples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"logical value indicating whether examples run.","code":""},{"path":"https://measr.info/dev/reference/measr_examples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine if code is executed interactively or in pkgdown — measr_examples","text":"","code":"measr_examples() #> [1] TRUE"},{"path":"https://measr.info/dev/reference/measr_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract components of a measrfit object — measr_extract","title":"Extract components of a measrfit object — measr_extract","text":"Extract model metadata, parameter estimates, model evaluation results.","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract components of a measrfit object — measr_extract","text":"","code":"measr_extract(model, what, ...)"},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract components of a measrfit object — measr_extract","text":"model estimated extract information . Character string. information extracted. See details available options. ... Additional arguments passed extract method. ppmc_interval: = \"odds_ratio_flags\" = \"conditional_prob_flags\", compatibility interval used determining model fit flags return. example, ppmc_interval 0.95 (default) return PPMCs posterior predictive p-value (ppp) less 0.025 greater 0.975. agreement: = \"classification_reliability\", additional measures agreement include. default, classification accuracy consistency metrics defined Johnson & Sinharay (2018) returned. Additional metrics can specified agreement Goodman & Kruskal's lambda (lambda), Cohen's kappa (kappa), Youden's statistic (youden), tetrachoric correlation (tetra), true positive rate (tp), true negative rate (tn). = \"probability_reliability\", additional measures agreement include. default, informational reliability index defined Johnson & Sinharay (2020) returned. Additional metrics can specified agreement point biserial reliability index (bs), parallel forms reliability index (pf), tetrachoric reliability index (tb), originally defined Templin & Bradshaw (2013).","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract components of a measrfit object — measr_extract","text":"extracted information. specific structure vary depending extracted, usually returned object tibble requested information.","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract components of a measrfit object — measr_extract","text":"diagnostic classification models, can extract following information:","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"model-metadata","dir":"Reference","previous_headings":"","what":"Model metadata","title":"Extract components of a measrfit object — measr_extract","text":"prior: priors used estimating model. classes: possible classes profile patterns. show class label (.e., pattern proficiency) attributes included class.","code":""},{"path":[]},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model parameters","title":"Extract components of a measrfit object — measr_extract","text":"item_param: estimated item parameters. shows name parameter, class parameter, estimated value. strc_param: estimated structural parameters. base rate membership class. shows class pattern estimated proportion respondents class. pi_matrix: model estimated probability respondent given class provides correct response item. output shows item (rows), class (columns), estimated p-values. exp_pvalues: Model expected p-values item. equivalent pi_matrix, also includes \"overall\" variable, represents expected p-value item (.e., average class-specific p-values, weighted prevalence class).","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"respondent-results","dir":"Reference","previous_headings":"","what":"Respondent results","title":"Extract components of a measrfit object — measr_extract","text":"class_prob: probability respondent belongs class (.e., given pattern proficiency). attribute_prob: proficiency probability respondent attribute.","code":""},{"path":[]},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"absolute-model-fit","dir":"Reference","previous_headings":"","what":"Absolute model fit","title":"Extract components of a measrfit object — measr_extract","text":"m2: M2 fit statistic. See fit_m2() details. Model fit information must first added model using add_fit(). rmsea: root mean square error approximation (RMSEA) fit statistic associated confidence interval. See fit_m2() details. Model fit information must first added model using add_fit(). srmsr: standardized root mean square residual (SRMSR) fit statistic. See fit_m2() details. Model fit information must first added model using add_fit(). ppmc_raw_score: observed posterior predicted chi-square statistic raw score distribution. See fit_ppmc() details. Model fit information must first added model using add_fit(). ppmc_conditional_prob: observed posterior predicted conditional probabilities class providing correct response item. See fit_ppmc() details. Model fit information must first added model using add_fit(). ppmc_conditional_prob_flags: subset PPMC conditional probabilities ppp outside specified ppmc_interval. ppmc_odds_ratio: observed posterior predicted odds ratios item pair. See fit_ppmc() details. Model fit information must first added model using add_fit(). ppmc_odds_ratio_flags: subset PPMC odds ratios ppp outside specified ppmc_interval. ppmc_pvalue: observed posterior predicted proportion correct responses item. See fit_ppmc() details. ppmc_pvalue_flags: subset PPMC proportion correct values ppp outside specified ppmc_interval.","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"relative-model-fit","dir":"Reference","previous_headings":"","what":"Relative model fit","title":"Extract components of a measrfit object — measr_extract","text":"loo: leave-one-cross validation results. See loo::loo() details. information criterion must first added model using add_criterion(). waic: widely applicable information criterion results. See loo::waic() details. information criterion must first added model using add_criterion(). aic: Akaike information criterion results. See aic() details. information criterion must first added model using add_criterion(). bic: Bayesian information criterion results. See bic() details. information criterion must first added model using add_criterion().","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"reliability","dir":"Reference","previous_headings":"","what":"Reliability","title":"Extract components of a measrfit object — measr_extract","text":"pattern_reliability: accuracy consistency overall attribute profile classification, described Cui et al. (2012). Reliability information must first added model using add_reliability(). classification_reliability: classification accuracy consistency attribute, using metrics described Johnson & Sinharay (2018). Reliability information must first added model using add_reliability(). probability_reliability: Reliability estimates probability proficiency attribute, described Johnson & Sinharay (2020). Reliability information must first added model using add_reliability().","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract components of a measrfit object — measr_extract","text":"Cui, Y., Gierl, M. J., & Chang, H.-H. (2012). Estimating classification consistency accuracy cognitive diagnostic assessment. Journal Educational Measurement, 49(1), 19-38. doi:10.1111/j.1745-3984.2011.00158.x Johnson, M. S., & Sinharay, S. (2018). Measures agreement assess attribute-level classification accuracy consistency cognitive diagnostic assessments. Journal Educational Measurement, 55(4), 635-664. doi:10.1111/jedm.12196 Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Behavioral Statistics, 45(1), 5-31. doi:10.3102/1076998619864550 Templin, J., & Bradshaw, L. (2013). Measuring reliability diagnostic classification model examinee estimates. Journal Classification, 30(2), 251-275. doi:10.1007/s00357-013-9129-4","code":""},{"path":"https://measr.info/dev/reference/measr_extract.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract components of a measrfit object — measr_extract","text":"","code":"rstn_mdm_lcdm <- dcm_estimate(   dcm_specify(dcmdata::mdm_qmatrix, identifier = \"item\"),   data = dcmdata::mdm_data, missing = NA, identifier = \"respondent\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  measr_extract(rstn_mdm_lcdm, \"strc_param\") #> # A tibble: 2 × 2 #>   class estimate #>   <chr>    <dbl> #> 1 [0]      0.488 #> 2 [1]      0.512"},{"path":"https://measr.info/dev/reference/measrdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"S7 class for measrdcm objects — measrdcm","title":"S7 class for measrdcm objects — measrdcm","text":"measrdcm constructor exported facilitate conversion model objects (e.g., stanfit) measrdcm objects. expect recommend calling function directly, unless creating method converting measrdcm. Rather, create measrdcm object, one use dcm_estimate().","code":""},{"path":"https://measr.info/dev/reference/measrdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S7 class for measrdcm objects — measrdcm","text":"","code":"measrdcm(   model_spec = NULL,   data = list(),   stancode = character(0),   method = stanmethod(),   algorithm = character(0),   backend = stanbackend(),   model = list(),   respondent_estimates = list(),   fit = list(),   criteria = list(),   reliability = list(),   file = character(0),   version = list() )"},{"path":"https://measr.info/dev/reference/measrdcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S7 class for measrdcm objects — measrdcm","text":"model_spec model specification used estimate model. data data used estimate model. stancode model code Stan language. method method used fit model. algorithm name algorithm used fit model. backend name backend used fit model. model fitted Stan model. object class rstan::stanfit backend = \"rstan\" CmdStanMCMC backend = \"cmdstanr\" specified fitting model. respondent_estimates empty list adding estimated person parameters fitting model. fit empty list adding model fit information fitting model. criteria empty list adding information criteria fitting model. reliability empty list adding reliability information fitting model. file Optional name file model objects saved loaded . version versions measr, Stan, rstan cmdstanr used fit model.","code":""},{"path":"https://measr.info/dev/reference/measrdcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S7 class for measrdcm objects — measrdcm","text":"measrdcm object.","code":""},{"path":[]},{"path":"https://measr.info/dev/reference/measrdcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"S7 class for measrdcm objects — measrdcm","text":"","code":"qmatrix <- tibble::tibble(   att1 = sample(0:1, size = 15, replace = TRUE),   att2 = sample(0:1, size = 15, replace = TRUE),   att3 = sample(0:1, size = 15, replace = TRUE),   att4 = sample(0:1, size = 15, replace = TRUE) )  spec <- dcm_specify(qmatrix = qmatrix)  measrdcm(spec) #> <measr::measrdcm> #>  @ model_spec          : <dcmstan::dcm_specification> #>  .. @ qmatrix          : tibble [15 × 4] (S3: tbl_df/tbl/data.frame) #>  $ att1: int [1:15] 0 1 1 1 0 1 1 1 1 1 ... #>  $ att2: int [1:15] 1 1 1 0 1 0 1 0 1 0 ... #>  $ att3: int [1:15] 1 0 1 1 1 0 1 1 1 1 ... #>  $ att4: int [1:15] 0 0 0 0 1 1 1 0 0 1 ... #>  .. @ qmatrix_meta     :List of 3 #>  .. .. $ attribute_names: Named chr [1:4] \"att1\" \"att2\" \"att3\" \"att4\" #>  .. ..  ..- attr(*, \"names\")= chr [1:4] \"att1\" \"att2\" \"att3\" \"att4\" #>  .. .. $ item_identifier: NULL #>  .. .. $ item_names     : Named int [1:15] 1 2 3 4 5 6 7 8 9 10 ... #>  .. ..  ..- attr(*, \"names\")= chr [1:15] \"1\" \"2\" \"3\" \"4\" ... #>  .. @ measurement_model: <dcmstan::LCDM> #>  .. .. @ model     : chr \"lcdm\" #>  .. .. @ model_args:List of 1 #>  .. .. .. $ max_interaction: num Inf #>  .. @ structural_model : <dcmstan::UNCONSTRAINED> #>  .. .. @ model     : chr \"unconstrained\" #>  .. .. @ model_args: list() #>  .. @ priors           : <dcmstan::dcmprior> #>  .. .. @ distribution: chr [1:4] \"normal(0, 2)\" \"lognormal(0, 1)\" ... #>  .. .. @ type        : chr [1:4] \"intercept\" \"maineffect\" \"interaction\" ... #>  .. .. @ coefficient : chr [1:4] NA NA NA \"Vc\" #>  .. .. @ lower_bound : num [1:4] NA NA NA NA #>  .. .. @ upper_bound : num [1:4] NA NA NA NA #>  .. .. @ prior       : chr [1:4] \"normal(0, 2)\" \"lognormal(0, 1)\" ... #>  @ data                : list() #>  @ stancode            : chr(0)  #>  @ method              : <measr::stanmethod> #>  @ algorithm           : chr(0)  #>  @ backend             : <measr::stanbackend> #>  @ model               : list() #>  @ respondent_estimates: list() #>  @ fit                 : list() #>  @ criteria            : list() #>  @ reliability         : list() #>  @ file                : chr(0)  #>  @ version             : list()"},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":null,"dir":"Reference","previous_headings":"","what":"Add model evaluation metrics model objects — model_evaluation","title":"Add model evaluation metrics model objects — model_evaluation","text":"Add model evaluation metrics fitted model objects. functions wrappers around functions compute metrics. benefit using wrappers model evaluation metrics saved part model object time-intensive calculations need repeated. See Details specifics.","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add model evaluation metrics model objects — model_evaluation","text":"","code":"add_criterion(   x,   criterion = c(\"loo\", \"waic\", \"log_mll\", \"aic\", \"bic\"),   overwrite = FALSE,   save = TRUE,   ...,   r_eff = NA )  add_reliability(x, overwrite = FALSE, save = TRUE, ...)  add_fit(   x,   method = c(\"m2\", \"ppmc\"),   overwrite = FALSE,   save = TRUE,   ...,   ci = 0.9 )  add_respondent_estimates(   x,   probs = c(0.025, 0.975),   overwrite = FALSE,   save = TRUE )"},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add model evaluation metrics model objects — model_evaluation","text":"x measrdcm object. criterion vector information criteria calculate add model object. Must \"loo\", \"waic\", \"log_mll\" models estimated MCMC, \"aic\" \"bic\" models estimated optimizer. overwrite Logical. Indicates whether specified elements already added estimated model overwritten. Default FALSE. save Logical. relevant file specified measrdcm object passed x. TRUE (default), model re-saved specified file new criteria added R object. FALSE, new criteria added R object, saved file updated. ... Arguments passed fit_ppmc model_fit posterior predictive model checks compute evaluation model-level fit. NULL, model-level checks computed. See details. item_fit posterior predictive model checks compute evaluation item-level fit. NULL, item-level checks computed. See details. r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalized importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper functions help computing r_eff. method vector model fit methods evaluate add model object. ci confidence interval RMSEA, computed M2 probs percentiles computed stats::quantile() function. relevant model estimated method = \"mcmc\". used summary TRUE.","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add model evaluation metrics model objects — model_evaluation","text":"modified measrdcm object corresponding slot populated specified information.","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add model evaluation metrics model objects — model_evaluation","text":"add_respondent_estimates(), estimated person parameters added $respondent_estimates element fitted model. add_fit(), model item fit information added $fit element fitted model. function wraps fit_m2() calculate M2 statistic (Hansen et al., 2016; Liu et al., 2016) /fit_ppmc() calculate posterior predictive model checks (Park et al., 2015; Sinharay & Almond, 2007; Sinharay et al., 2006; Thompson, 2019), depending methods specified. add_criterion(), relative fit criteria added $criteria element fitted model. models estimated MCMC, function wraps loo() waic() calculate LOO-CV (Vehtari et al., 2017) WAIC (Watanabe, 2010), respectively, log_mll() calculate log marginal likelihood, used calculating Bayes factors. models estimated optimizer, wraps aic() bic() estimate AIC (Akaike, 1973) BIC (Schwarz, 1978), respectively. add_reliability(), reliability information added $reliability element fitted model. Pattern level reliability described Cui et al. (2012). Classification reliability posterior probability reliability described Johnson & Sinharay (2018, 2020), respectively. function wraps reliability(). Arguments supplied ... passed reliability().","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add model evaluation metrics model objects — model_evaluation","text":"Akaike, H. (1973). Information theory extension maximum likelihood principle. B. N. Petrov & F. Csáki (Eds.), Proceedings Second International Symposium Information Theory (pp. 267-281). Akademiai Kiado. Cui, Y., Gierl, M. J., & Chang, H.-H. (2012). Estimating classification consistency accuracy cognitive diagnostic assessment. Journal Educational Measurement, 49(1), 19-38. doi:10.1111/j.1745-3984.2011.00158.x Hansen, M., Cai, L., Monroe, S., & Li, Z. (2016). Limited-information goodness--fit testing diagnostic classification item response models. British Journal Mathematical Statistical Psychology, 69(3), 225-252. doi:10.1111/bmsp.12074 Johnson, M. S., & Sinharay, S. (2018). Measures agreement assess attribute-level classification accuracy consistency cognitive diagnostic assessments. Journal Educational Measurement, 55(4), 635-664. doi:10.1111/jedm.12196 Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Behavioral Statistics, 45(1), 5-31. doi:10.3102/1076998619864550 Liu, Y., Tian, W., & Xin, T. (2016). application M2 statistic evaluate fit cognitive diagnostic models. Journal Educational Behavioral Statistics, 41(1), 3-26. doi:10.3102/1076998615621293 Park, J. Y., Johnson, M. S., Lee, Y-S. (2015). Posterior predictive model checks cognitive diagnostic models. International Journal Quantitative Research Education, 2(3-4), 244-264. doi:10.1504/IJQRE.2015.071738 Schwarz, G. (1978). Estimating dimension model. Annals Statistics, 6(2), 461–464. doi:10.1214/aos/1176344136 Sinharay, S., & Almond, R. G. (2007). Assessing fit cognitive diagnostic models. Educational Psychological Measurement, 67(2), 239-257. doi:10.1177/0013164406292025 Sinharay, S., Johnson, M. S., & Stern, H. S. (2006). Posterior predictive assessment item response theory models. Applied Psychological Measurement, 30(4), 298-321. doi:10.1177/0146621605285517 Thompson, W. J. (2019). Bayesian psychometrics diagnostic assessments: proof concept (Research Report . 19-01). University Kansas; Accessible Teaching, Learning, Assessment Systems. doi:10.35542/osf.io/jzqs8 Vehtari, ., Gelman, ., & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing, 27(5), 1413-1432. doi:10.1007/s11222-016-9696-4 Watanabe, S. (2010). Asymptotic equivalence Bayes cross validation widely applicable information criterion singular learning theory. Journal Machine Learning Research, 11(116), 3571-3594. https://jmlr.org/papers/v11/watanabe10a.html","code":""},{"path":"https://measr.info/dev/reference/model_evaluation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add model evaluation metrics model objects — model_evaluation","text":"","code":"cmds_mdm_dina <- dcm_estimate(   dcm_specify(dcmdata::mdm_qmatrix, identifier = \"item\",               measurement_model = dina(),               priors = c(prior(beta(5, 17), type = \"slip\"),                          prior(beta(5, 17), type = \"guess\"))),   data = dcmdata::mdm_data, missing = NA, identifier = \"respondent\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  cmds_mdm_dina <- add_reliability(cmds_mdm_dina) cmds_mdm_dina <- add_fit(cmds_mdm_dina, method = \"m2\") cmds_mdm_dina <- add_respondent_estimates(cmds_mdm_dina)"},{"path":"https://measr.info/dev/reference/qmatrix_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"Q-matrix validation — qmatrix_validation","title":"Q-matrix validation — qmatrix_validation","text":"Calculate Q-matrix validation metrics fitted model objects using methods described de la Torre Chiu (2016). See details additional information.","code":""},{"path":"https://measr.info/dev/reference/qmatrix_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Q-matrix validation — qmatrix_validation","text":"","code":"qmatrix_validation(x, ..., pvaf_threshold = 0.95)"},{"path":"https://measr.info/dev/reference/qmatrix_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Q-matrix validation — qmatrix_validation","text":"x measrdcm object. ... Unused. pvaf_threshold threshold proportion variance accounted flag items appropriate empirical specifications. default .95 implemented de la Torre Chiu (2016).","code":""},{"path":"https://measr.info/dev/reference/qmatrix_validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Q-matrix validation — qmatrix_validation","text":"tibble containing Q-matrix validation results. one row per item 5 columns: item identifier, specified Q-matrix  used estimate model. original_specification: original Q-matrix entry item. original_pvaf: proportion variance accounted original specification, compared specification item measures attributes. empirical_specification: Q-matrix specification measures fewest attributes proportion variance accounted specified pvaf_threshold threshold. original specification optimal, empirical_specification NA. empirical_pvaf: proportion variance accounted empirical specification, compared specification item measures attributes. original specification optimal, emprirical_pvaf NA.","code":""},{"path":"https://measr.info/dev/reference/qmatrix_validation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Q-matrix validation — qmatrix_validation","text":"Q-matrix validation conducted evaluating proportion variance accounted different Q-matrix specifications. Following method described de la Torre Chiu (2016), use following steps item: Calculate total variance explained item measured possible attributes. possible Q-matrix entry, calculate variance explained item measured given attributes. Calculate proportion variance explained (PVAF) variance explained current Q-matrix entry divided variance explained saturated entry (Step 1). computing PVAF possible Q-matrix entries, filter PVAF greater specified pvaf_threshold threshold. Filter remaining Q-matrix entries measure fewest number attributes (.e., prefer parsimonious model). one Q-matrix entry remaining, select entry highest PVAF.","code":""},{"path":"https://measr.info/dev/reference/qmatrix_validation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Q-matrix validation — qmatrix_validation","text":"de la Torre, J., & Chiu, C.-Y. (2016). general method empirical Q-matrix validation. Psychometrika, 81(2), 253-273. doi:10.1007/s11336-015-9467-8","code":""},{"path":"https://measr.info/dev/reference/qmatrix_validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Q-matrix validation — qmatrix_validation","text":"","code":"mod_spec <- dcm_specify(   qmatrix = dcmdata::ecpe_qmatrix,   identifier = \"item_id\",   measurement_model = dcmstan::lcdm(),   structural_model = dcmstan::hdcm(     hierarchy = \"lexical -> cohesive -> morphosyntactic\"   ) ) rstn_ecpe <- dcm_estimate(   mod_spec,   data = dcmdata::ecpe_data,   identifier = \"resp_id\",   backend = \"rstan\",   method = \"optim\" )  q_matrix_validation <- qmatrix_validation(rstn_ecpe)"},{"path":"https://measr.info/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. dcm2 fit_m2 dcmstan create_profiles, crum, dcm_specify, default_dcm_priors, dina, dino, get_parameters, hdcm, independent, lcdm, ncrum, nida, nido, prior, unconstrained loo loo, loo_compare, waic posterior as_draws, E, Pr, rvar_mad, rvar_max, rvar_mean, rvar_median, rvar_min, rvar_prod, rvar_sd, rvar_sum, rvar_var","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the reliability of a diagnostic classification model — reliability","title":"Estimate the reliability of a diagnostic classification model — reliability","text":"diagnostic classification models, reliability can estimated pattern attribute level. Pattern-level reliability represents classification consistency accuracy placing students overall mastery profile. Rather overall profile, attributes can also scored individually. case, classification consistency accuracy evaluated individual attribute, rather overall profile. referred maximum posteriori (MAP) reliability. Finally, may desirable report results probability proficiency mastery attribute instead proficient/proficient classification. case, reliability posterior probability reported. expected posteriori (EAP) reliability.","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the reliability of a diagnostic classification model — reliability","text":"","code":"reliability(x, ..., threshold = 0.5, force = FALSE)"},{"path":"https://measr.info/dev/reference/reliability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the reliability of a diagnostic classification model — reliability","text":"x estimated model evaluated. ... Unused. future extensions. threshold map_reliability, threshold applied attribute-level probabilities determining binary attribute classifications. numeric vector length 1 (threshold applied attributes), length equal number attributes. named vector supplied, names match attribute names Q-matrix used estimate model. unnamed, thresholds order attributes defined Q-matrix. force reliability information already added model object add_reliability(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the reliability of a diagnostic classification model — reliability","text":"class measrdcm, list 3 elements: pattern_reliability: pattern-level accuracy (p_a) consistency (p_c) described Cui et al. (2012). map_reliability: list 2 elements: accuracy consistency, include attribute-level classification reliability statistics described Johnson & Sinharay (2018). eap_reliability: attribute-level posterior probability reliability statistics described Johnson & Sinharay (2020).","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate the reliability of a diagnostic classification model — reliability","text":"pattern-level reliability (pattern_reliability) statistics described Cui et al. (2012). Attribute-level classification reliability statistics (map_reliability) described Johnson & Sinharay (2018). Reliability statistics posterior mean skill indicators (.e., mastery proficiency probabilities; eap_reliability) described Johnson & Sinharay (2019).","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate the reliability of a diagnostic classification model — reliability","text":"Cui, Y., Gierl, M. J., & Chang, H.-H. (2012). Estimating classification consistency accuracy cognitive diagnostic assessment. Journal Educational Measurement, 49(1), 19-38. doi:10.1111/j.1745-3984.2011.00158.x Johnson, M. S., & Sinharay, S. (2018). Measures agreement assess attribute-level classification accuracy consistency cognitive diagnostic assessments. Journal Educational Measurement, 55(4), 635-664. doi:10.1111/jedm.12196 Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Behavioral Statistics, 45(1), 5-31. doi:10.3102/1076998619864550","code":""},{"path":"https://measr.info/dev/reference/reliability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the reliability of a diagnostic classification model — reliability","text":"","code":"rstn_mdm_lcdm <- dcm_estimate(   dcm_specify(dcmdata::mdm_qmatrix, identifier = \"item\"),   data = dcmdata::mdm_data, missing = NA, identifier = \"respondent\",   method = \"optim\", seed = 63277, backend = \"rstan\" )  reliability(rstn_mdm_lcdm) #> $pattern_reliability #>       p_a       p_c  #> 0.9122250 0.8401031  #>  #> $map_reliability #> $map_reliability$accuracy #> # A tibble: 1 × 8 #>   attribute        acc lambda_a kappa_a youden_a tetra_a  tp_a  tn_a #>   <chr>          <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> #> 1 multiplication 0.912    0.820   0.823    0.824   0.962 0.923 0.901 #>  #> $map_reliability$consistency #> # A tibble: 1 × 10 #>   attribute   consist lambda_c kappa_c youden_c tetra_c  tp_c  tn_c gammak #>   <chr>         <dbl>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 multiplica…   0.840    0.666   0.821    0.680   0.876 0.847 0.833  0.870 #> # ℹ 1 more variable: pc_prime <dbl> #>  #>  #> $eap_reliability #> # A tibble: 1 × 5 #>   attribute      rho_pf rho_bs rho_i rho_tb #>   <chr>           <dbl>  <dbl> <dbl>  <dbl> #> 1 multiplication  0.740  0.740 0.613  0.918 #>"},{"path":"https://measr.info/dev/reference/score.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior draws of respondent proficiency — score","title":"Posterior draws of respondent proficiency — score","text":"Calculate posterior draws respondent proficiency. Optionally retain posterior draws return summaries distribution respondent.","code":""},{"path":"https://measr.info/dev/reference/score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior draws of respondent proficiency — score","text":"","code":"score(   x,   newdata = NULL,   missing = NA,   identifier = NULL,   summary = TRUE,   probs = c(0.025, 0.975),   force = FALSE )"},{"path":"https://measr.info/dev/reference/score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior draws of respondent proficiency — score","text":"x estimated model (e.g., dcm_estimate(). newdata Optional new data. provided, data used estimate model scored. provided, newdata data frame 1 row per respondent 1 column per item. items appear newdata appear data used estimate x. missing R expression specifying missing data data coded (e.g., NA, \".\", -99, etc.). default NA. identifier Optional. Variable name column newdata contains respondent identifiers. NULL (default) indicates identifiers present data, row numbers used identifiers. newdata specified data used estimate model scored, resp_id taken original data. summary summary statistics returned instead raw posterior draws? relevant model estimated method = \"mcmc\". Default FALSE. probs percentiles computed stats::quantile() function. relevant model estimated method = \"mcmc\". used summary TRUE. force respondent estimates already added model object add_respondent_estimates(), recalculated. Default FALSE.","code":""},{"path":"https://measr.info/dev/reference/score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior draws of respondent proficiency — score","text":"list two elements: class_probabilities attribute_probabilities. summary FALSE, element tibble one row per respondent. columns include respondent identifier, one column probabilities possible classes attributes (posterior::rvar() objects). summary TRUE, element tibble one row per respondent class attribute. columns include respondent identifier, class attribute, mean, one column every value specified probs.","code":""},{"path":"https://measr.info/dev/reference/stan-classes.html","id":null,"dir":"Reference","previous_headings":"","what":"S7 classes for estimation specifications — stan-classes","title":"S7 classes for estimation specifications — stan-classes","text":"constructors Stan back-ends methods exported support extensions measr, example converting models measrfit objects. expect recommend calling functions directly unless converting objects, creating new methods measrfit objects.","code":""},{"path":"https://measr.info/dev/reference/stan-classes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S7 classes for estimation specifications — stan-classes","text":"","code":"rstan()  cmdstanr()  mcmc()  optim()  gqs()"},{"path":"https://measr.info/dev/reference/stan-classes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S7 classes for estimation specifications — stan-classes","text":"S7 object corresponding class.","code":""},{"path":[]},{"path":"https://measr.info/dev/reference/stan-classes.html","id":"back-end-classes","dir":"Reference","previous_headings":"","what":"Back-end classes","title":"S7 classes for estimation specifications — stan-classes","text":"two classes estimation backends, define package used, used, estimate model. rstan() class indicates use {rstan}, whereas cmdstanr() indicates use {cmdstanr}. classes inherit measr::stanbackend.","code":""},{"path":"https://measr.info/dev/reference/stan-classes.html","id":"method-classes","dir":"Reference","previous_headings":"","what":"Method classes","title":"S7 classes for estimation specifications — stan-classes","text":"method classes define estimation method used, used, model. mcmc() class indicates use Markov chain Monte Carlo via rstan::sampling() using {rstan} $sample() method CmdStanModel class using {cmdstanr}. optim() class indicates use maximum-likelihood via rstan::optimizing() using {rstan} $optimize() method CmdStanModel class using {cmdstanr}. Finally, gqs() class use model previously estimated interested calculating generated quantities (e.g., score(), loglik_array()). gqs() class indicates use rstan::gqs() using {rstan} $generate_quantities() method CmdStanModel class using {cmdstanr}. method classes inherit measr::stanmethod.","code":""},{"path":"https://measr.info/dev/reference/stan-classes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"S7 classes for estimation specifications — stan-classes","text":"","code":"rstan() #> <measr::rstan>  mcmc() #> <measr::mcmc>"},{"path":"https://measr.info/dev/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way.   enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions).   simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data placeholder object represents current slice data. variable name string, use .data placeholder subset variable [[.   Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround.   Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually :   Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data |>     group_by(...) |>     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data |>     group_by(!!!dots) |>     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars |> summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data |>     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data |>     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"},{"path":"https://measr.info/dev/reference/tidyeval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy eval helpers — tidyeval","text":"See documentation specific functions rlang.","code":""},{"path":"https://measr.info/dev/reference/yens_q3.html","id":null,"dir":"Reference","previous_headings":"","what":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","title":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","text":"Calculate \\(Q_3\\) statistic evaluate assumption independent items.","code":""},{"path":"https://measr.info/dev/reference/yens_q3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","text":"","code":"yens_q3(x, ..., crit_value = 0.2, summary = NULL)"},{"path":"https://measr.info/dev/reference/yens_q3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","text":"x measrdcm object. ... Unused. crit_value critical value threshold flagging residual correlation given item pair. default 0.2, described Chen Thissen (1997). summary summary statistic returned. Must one \"q3max\" \"q3star\" (see Details). NULL (default), summary statistic return, residual correlations returned.","code":""},{"path":"https://measr.info/dev/reference/yens_q3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","text":"summary = NULL, tibble residual correlation flags item pairs. Otherwise, numeric value representing requested summary statistic.","code":""},{"path":"https://measr.info/dev/reference/yens_q3.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","text":"Psychometric models assume items independent , conditional latent trait. \\(Q_3\\) statistic (Yen, 1984) used evaluate assumption. observed item response, calculate residual model predicted score observed score estimate correlations residuals across items. residual correlation \\(Q_3\\) statistic. Often, critical values used flag residual correlation given threshold (e.g., Chen & Thissen, 1997). Alternatively, may use summary statistic maximum \\(Q_3\\) statistic (\\(Q_{3,max}\\); Christensen et al., 2017), defined $$Q_{3,max} = \\text{max}_{>j}\\left|Q_{3,ij}\\right|$$ mean-adjusted maximum \\(Q_3\\) statistic (\\(Q_{3,*}\\); Marais, 2013), defined $$   \\overline{Q}_3 = \\begin{pmatrix} \\\\\\ 2\\end{pmatrix}^{-1}   \\displaystyle\\sum_{>j}Q_{3,ij} \\\\  Q_{3,*} = Q_{3,max} - \\overline{Q}_3 $$","code":""},{"path":"https://measr.info/dev/reference/yens_q3.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","text":"Chen, W.-H., & Thissen, D. (1997). Local dependence indexes item pairs using item response theory. Journal Educational Behavioral Statistics, 22(3), 265-389. doi:10.3102/10769986022003265 Christensen, K. B., Makransky, G., & Horton, M. (2017). Critical values Yen's Q3: Identification local dependence Rasch model using residual correlations. Applied Psychological Measurement, 41(3), 178-194. doi:10.1177/0146621616677520 Marais, . (2013). Local dependence. K. B. Christensen, S. Kreiner, & M. Mesbah (Eds.), Rasch models health (pp. 111-130). Wiley. Yen, W. M. (1984). Effects local item dependence fit equating performance three-parameter logistic model. Applied Psychological Measurement, 8(2), 125-145. doi:10.1177/014662168400800201","code":""},{"path":"https://measr.info/dev/reference/yens_q3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Yen's \\(Q_3\\) statistic for local item dependence — yens_q3","text":"","code":"model_spec <- dcm_specify(qmatrix = dcmdata::mdm_qmatrix,                           identifier = \"item\") model <- dcm_estimate(dcm_spec = model_spec, data = dcmdata::mdm_data,                       identifier = \"respondent\", method = \"optim\",                       seed = 63277)  yens_q3(model) #> # A tibble: 6 × 4 #>   item_1 item_2 resid_corr flag  #>   <chr>  <chr>       <dbl> <lgl> #> 1 mdm1   mdm2      -0.132  FALSE #> 2 mdm1   mdm3      -0.0910 FALSE #> 3 mdm1   mdm4      -0.123  FALSE #> 4 mdm2   mdm3      -0.110  FALSE #> 5 mdm2   mdm4      -0.249  TRUE  #> 6 mdm3   mdm4      -0.0988 FALSE"},{"path":"https://measr.info/dev/news/index.html","id":"measr-development-version","dir":"Changelog","previous_headings":"","what":"measr (development version)","title":"measr (development version)","text":"Updated reliability functionality allow calculation accuracy consistency different thresholds determining attribute classifications. Added new measrfit() function creating measrfit objects Stan models originally created measr. Added aic() bic() functions calculating Akaike Bayesian information criteria, respectively, models estimated method = \"optim\". Refactored package use S7 objects instead S3. Functions generating Stan code relocated dcmstan. measr_dcm() deprecated favor dcm_estimate(). New functionality relative model fit comparisons (aic(), bic(), bayes_factor()). New functionality testing model assumptions (yens_q3()).","code":""},{"path":"https://measr.info/dev/news/index.html","id":"measr-100","dir":"Changelog","previous_headings":"","what":"measr 1.0.0","title":"measr 1.0.0","text":"CRAN release: 2024-01-30","code":""},{"path":"https://measr.info/dev/news/index.html","id":"new-documentation-1-0-0","dir":"Changelog","previous_headings":"","what":"New documentation","title":"measr 1.0.0","text":"new article model evaluation added project website (https://measr.info). model estimation article updated use (simulated) data set model evaluation article. detailed installation instructions added getting started vignette (#23). case study demonstrating full DCM-based analysis using data ECPE (?ecpe_data) added project website.","code":""},{"path":"https://measr.info/dev/news/index.html","id":"minor-improvements-and-fixes-1-0-0","dir":"Changelog","previous_headings":"","what":"Minor improvements and fixes","title":"measr 1.0.0","text":"Fixed bug LCDM specification constraints level-3 interaction terms. Functions evaluating estimated models (e.g., fit_ppmc(), reliability()) longer recalculate indices previously saved model object. behavior can overwritten force = TRUE. Updated Stan syntax compatible new array syntax (@andrjohns, #36) get_parameters() now preserves item identifiers default. Items can renamed numbers (e.g., 1, 2, 3, …) setting rename_item = TRUE. measr now reexports functions posterior conducting mathematical operations posterior::rvar() objects. Respondent estimates now returned posterior::rvar() objects summarized.","code":""},{"path":"https://measr.info/dev/news/index.html","id":"measr-031","dir":"Changelog","previous_headings":"","what":"measr 0.3.1","title":"measr 0.3.1","text":"CRAN release: 2023-05-27 Added NEWS.md file track changes package.","code":""},{"path":"https://measr.info/dev/news/index.html","id":"new-features-0-3-1","dir":"Changelog","previous_headings":"","what":"New features","title":"measr 0.3.1","text":"compensatory reparameterized unified model (C-RUM) can now estimated defining type = \"crum\" measr_dcm() function. Users can now drop higher order interactions loglinear cognitive diagnostic model (LCDM). new argument measr_dcm(), max_interaction, defines highest order interactions estimate. example, max_interaction = 2 estimate intercepts, main effects, two-way interactions. new argument measr_dcm(), attribute_structure allows users specified either “unconstrained” relationships attributes “independent” attributes. Users can now specify prior distribution structural parameters govern base rates class membership (#2). Safeguards added warn users specified prior defined chosen DCM sub-type. example, error generated prior defined slipping parameter, LCDM chosen type model estimated (#1).","code":""},{"path":"https://measr.info/dev/news/index.html","id":"minor-improvements-and-fixes-0-3-1","dir":"Changelog","previous_headings":"","what":"Minor improvements and fixes","title":"measr 0.3.1","text":"Fixed bug backend = \"rstan\" warmup iterations total iterations requested user warmup iterations also specified (#6). Additional specifications added measr_extract() extracting results estimated model.","code":""}]
